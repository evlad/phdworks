% Глава 2 - Стохастическое оптимальное управление

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Вариант плана
%\section{Причины выбора стохастических методов в качестве полигона
%для применения ИНС (сравнить с другими работами где sin}

%\section{Постановка задачи в стационарном случае}

%\section{Изучение Винеровской и Калмановской фильтрации на предмет
%выявления рационального зерна}

%\section{Сама идея и еј аргументация схемы НОР}

%\section{Реализация НОР подобно Винеровскому оптимальному управлению
%--- эксперимент}

% Вопрос устойчивости системы с НОР
% НОР дискретный, а как в непрерывном времени?

%\section{Реализация НОР по произвольному ПИД --- эксперимент}

%\section{Обсуждение полученных результатов --- важность фазовой
%плоскости $u-e$.  Гипотеза о независимости от спектра уставки}

%\section{Проверка гипотезы --- равномерное распределение при обучении НОР
%--- эксперимент}

%\section{Сравнение эффективности НОР с оптимальным управление по
%Калману--Белману --- эксперимент}

%\section{Результаты моделирования для разнообразных
%детерминированных сигналов --- эксперимент}

%\section{Вопросы выбора структуры ИНС-О и ИНС-Р}

%\section{Обсуждение возможности применения архитектуры ИНС-О с ОС}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Линейная стационарная система автоматического управления
в стохастических условиях}

Рассмотрим линейную систему управления с обратной связью,
изображенную на \figref{fig:ctrlloop}. Будем считать, что
состояние объекта непосредственно измеряется на выходе, однако в
канале наблюдения присутствует аддитивная помеха с некоторыми
постоянными корреляционными свойствами. Параметры объекта
управления также постоянны во времени.  В системе имеется
регулятор, поддерживающий состояние объекта близким к заданной
траектории $r(t)$.  Траектория уставки $r(t)$ рассматривается как
стационарный случайный процесс с некоторыми корреляционными
параметрами.

Рассмотрим задачу синтеза нейросетевого регулятора для замены
имеющегося в описанной системе.  Целью замены зададим улучшение
качества управления в смысле уменьшения среднеквадратичной ошибки.
Критерий минимума среднеквадратичной ошибки является достаточно
удобным и эффективным в линейной теории стохастического
оптимального управления и поэтому широко используется.

%Кроме того, классический алгоритм обучения нейронных сетей
%перцептронного типа основан на этом же критерии оптимизации, что
%упрощает применение нейросетей в данном случае.

\begin{figure}[h]
  \centering
  \input ctrlloop.lp
  \caption{Исходная система управления.}
  \label{fig:ctrlloop}
\end{figure}

В качестве дополнительного ограничения примем, что синтез должен
осуществляться на реально действующем объекте в условиях,
максимально близких к штатным эксплуатационным.  Это условие можно
раскрыть в следующих требованиях к методике проведения работ:

\begin{enumerate}\label{realcond}
  \item При замене имеющегося регулятора нейросетевым последний
  сразу же должен обеспечивать устойчивость системы и качество
  управления не хуже исходного.

  \item Рассматривая действующую систему управления (в
  противоположность проектируемой), следует учитывать возможный
  уже случившийся дрейф параметров объекта управления в процессе
  эксплуатации относительно проектных.

  \item Корреляционные свойства помехи наблюдения должны считаться
  априорно неизвестными в силу зависимости от множества трудно
  учитываемых факторов.
\end{enumerate}

\subsection{Классический подход.}

Если параметры объекта управления и помехи известны, данная задача
решается расчетом Винеровского оптимального линейного фильтра и
построением соответствующего регулятора
\cite{tsipkin58}\cite{solod60}\cite{medv82}. Однако хорошо
известные недостатки данного подхода (необязательная физическая
осуществимость регулятора, неробастность), а также потребность в
предварительной идентификации параметров объекта управления и помехи
делают проведение синтеза оптимального линейного регулятора делом
достаточно сложным и требующим в каждом случае индивидуального подхода
с использованием аналитических расчетов.

\subsection{Нейросетевой подход.}

Одним из достоинств аппарата искусственных нейронных сетей
является неявное выделение знаний из имеющихся данных. Это значит,
что имеются методики построения алгоритма, осуществляющего без
участия человека настройку параметров нейросети на решение
поставленной задачи.

Рассмотрим задачу синтеза квазиоптимального нейросетевого
регулятора, опираясь в основном на данные, получаемые в результате
функционирования целевой системы управления.

Наличие шумов в исходных данных не должно являться принципиальным
ограничением применения нейросетей, так как известно, что
нейронные сети устойчивы к помехам.  Более того, иногда в
обучающие данные специально вводят небольшой шум, так как это
улучшает обобщающую способность нейросети.

С другой стороны, применение нейронных сетей в рамках данной
задачи требует специального рассмотрения в силу их нелинейности и
специфики алгоритмов настройки.  Поэтому для оценки качества
синтезированного регулятора целесообразно провести сравнительный
анализ с линейным оптимальным решением и выявить особенности
обоих.

Синтез нейросетевого регулятора будем проводить в дискретном
времени.  Данное условие диктуется широким применением средств
цифровой вычислительной техники для моделирования и обучения
искусственных нейронных сетей.

Рассмотрение в дискретном времени не является принципиальным
ограничением, присущим нейронным сетям, поскольку их применение
возможно и в непрерывном времени.  Однако континуальные сети
являются нетрадиционными в общем русле исследований по применению
нейронных сетей.  Существенно также, что моделирование
континуальных нейронных сетей и их применение требует
использования дорогостоящей специальной аппаратуры.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Общая схема и проблемы синтеза нейрорегулятора}

\subsection{Архитектура нейросети}\label{nnarch}

В качестве базовой архитектуры для синтезируемого регулятора
выберем многослойную искусственную нейронную сеть прямого
распространения с гиперболическим тангенсом в качестве функции
активации нейронов.  Эта сеть является классической и еј свойства
широко исследовались на протяжении ряда лет как в теоретическом
плане, так и в различных прикладных задачах.

%Имеются многочисленные варианты усовершенствовани

Для описания параметров многослойных нейронных сетей будем
использовать обозначение $\NN_{n_0,n_1,\ldots,n_{m-1},n_m}$, где $n_0$
--- число входов первого (входного) слоя сети, $n_1,\ldots,n_{m-1}$
--- число нейронов в последовательно расположенных скрытых слоях,
$n_m$ --- число нейронов (и выходов) последнего, выходного слоя.
Всего в нейронной сети имеется $m$ последовательных слоев, полностью
соединенных друг с другом.  Например, сеть, изображенная на
\figref{fig:mlann}, обозначается как $\NN_{4,3,4,2}$.

\begin{figure}[h]
  \centering
  \input mlann.lp
  \caption{Многослойная нейронная сеть.}\label{fig:mlann}
\end{figure}

Выход каждого из нейронов вычисляется по формуле

$$y=s(\sum_{j=1}^nw_j x_j)$$

\noindent где $y\in{\mathbb R}$ --- выход нейрона, $x_j\in{\mathbb
R}$ --- $n$ входов нейрона, $w_j\in{\mathbb R}$ --- весовые
коэффициенты на входах, $s$ --- дифференцируемая монотонно
возрастающая функция активации с областью определения ${\mathbb
R}$.  График функции гиперболического тангенса, часто используемой
в качестве функции активации нейронов, приводится на
\figref{fig:tanh}.  Использование нелинейной функции активации,
как известно~\cite{wasser92}, придает многослойной нейронной сети
свойство аппроксимации любых, в том числе, нелинейных,
зависимостей.

%$$ s(x)=\tanh x=\frac{2}{1+e^{-x}}-1 $$

\begin{figure}[h]
  \centering
  \input tanh.pic
  \caption{Гиперболический тангенс.}
  \label{fig:tanh}
\end{figure}

Следует особо отметить, что выходы нейронной сети однозначно
определяются еј входами в заданный момент времени.  Состояние или
память входных значений в предыдущие моменты времени в нейросети
представленной архитектуры отсутствует.  Таким образом, нейросеть
не является реальной динамической системой в понимании теории
управления: в ней отсутствует задержка реакции на входное
возмущение и, соответственно, переходный процесс как следствие
инерционности реакции.  Эквивалентом представленной архитектуры
является идеальное (безынерционное) звено с коэффициентом
усиления, зависящим от величины входного возмущающего воздействия.

Для этой архитектуры разработаны многочисленные методики обучения,
в основном базирующиеся на алгоритме обратного распространения
ошибки.  Свойства алгоритмов обучения и самой нейросети хорошо
изучены.  Данная архитектура нашла применение в самом широком
спектре задач, в том числе, в задачах идентификации и управления.

Поскольку гиперболический тангенс функция обладает ограниченной
областью значений, для представления чисел требуемого диапазона
можно применить один из следующих методов:

\begin{enumerate}
  \item Масштабирование выходных значений нейросети в желаемый
  диапазон.
  \item Использование линейной функции активации нейронов
  выходного слоя.  В этом случае для обеспечения необходимой
  представительной мощности нейросеть должна иметь не менее двух
  скрытых слоев с нелинейными функциями активации.
\end{enumerate}

Первый метод гарантирует ограниченность выходных значений
нейросети внутри заданного диапазона.  Это может оказаться
полезным при решении задач управления с физическими ограничениями
на диапазон управляющих воздействий.

Если постановка задачи обучения нейросети не предусматривает
ограничений, то второй метод расширения диапазона выходных
значений более предпочтителен.  Он обеспечивает возможность в
процессе настройки нейронной сети автоматически выбрать нужный
коэффициент масштабирования.

\subsection{Проблема эталона при обучении нейрорегулятора}

% Проблема обучения --- нужна инверсная модель
Как уже отмечалось, к наиболее распространенным методам обучения
нейронных сетей относится семейство методов обратного
распространения ошибки ({\em backpropagation of error}). Это так
называемые методы обучения с учителем ({\em supervised learning}),
то есть, нейросеть обучается на эталонных парах {\em вход--выход.}
Получение эталонной пары в рассматриваемой задаче представляет
определенную проблему.

По условию задачи исходный регулятор не является оптимальным, а
значит, пара {\em вход--выход}, измеренная на регуляторе, не может
являться эталоном при настройке квазиоптимального нейросетевого
регулятора.  Эталонная (то есть, ведущая к оптимальному закону
управления) обучающая пара известна лишь для всей системы --- это
уставка как вход системы и одновременно как еј целевой выход.
Очевидно, что условие $y(t) = r(t)$ является идеалом управления
системой и оно удовлетворяет условию минимума среднеквадратичной
ошибки управления.

Таким образом, для обучения нейросетевого регулятора (НС--Р)
возникает задача получения целевого сигнала управления $u^*(t)$ по
эталонному выходу объекта $y^*(t) \equiv r(t)$. Покажем, что это
достигается построением инверсной функции объекта управления.

Запишем зависимость выхода объекта управления от его входа как
$$y=f(u)$$

Тогда оптимальное управляющее воздействие даст желаемый выход

$$y^*=f(u^*)$$

Желаемый выход объекта (уставка) известен, следовательно для
вычисления оптимального управляющего воздействия $u^*$ достаточно
найти $f^{-1}(.)$ --- инверсную функцию объекта
управления.\footnote{Конечно, данная задача может рассматриваться
только в том случае, когда $f^{-1}(.)$ однозначная.}  Тогда

$$u^* = f^{-1}(y^*) \equiv f^{-1}(r)$$

Поскольку реальный объект управления в любом случае не допускает
решения данной задачи, то необходима его инверсная модель.

В качестве инверсной модели можно использовать нейросетевую модель
объекта управления, работающую в обратном направлении в режиме
распространения ошибки с выхода на вход без обучения (коррекции
весовых коэффициентов). Эта нейронная сеть должна быть
предварительно обучена функционировать подобно объекту управления.
В отличие от нейросетевого регулятора она по завершении его
настройки может быть отключена, так как в рабочем режиме и
стационарных условиях нейросетевой регулятор может функционировать
без инверсной модели.


\subsection{Принцип обучения нейрорегулятора с использованием инверсной
модели}

\label{nnc_optimal_training} Рассмотрим алгоритм обучения НС--Р с
использованием уже построенной нейросетевой модели объекта
$\NN^o$ (НС--О). Для простоты возьмем одномерный объект
управления.  Пока будем считать, что выход объекта полностью
определяется его входом в настоящий момент времени. Положим, что
помехи и прочие возмущающие воздействия в системе отсутствуют.
Нейронная сеть регулятора имеет архитектуру
$\NN^p_{1,\ldots,1}$ с $m_p$ слоями. Тогда движение системы в
пространстве состояний из момента времени $t_k$ в следующий момент
$t_{k+1}$ будет описываться следующими уравнениями:

$$ \left\{\begin{array}{rcl}
  e_k & = & y_k-r_k \\
  u_k & = & \NN^p(e_k) \\
  y_{k+1} & = & f(u_k)
\end{array}\right. $$

Кроме того, параллельно с объектом управления включена его
нейросетевая модель, реализуемая сетью с архитектурой
$\NN^o_{1,\ldots,1}$ ($m_o$ слоев) и осуществляющая
прогноз выхода объекта:

\begin{equation}\label{eq:nno-principle}
  \hat{y}_{k+1} = \NN^o(u_k)
\end{equation}


\subsubsection{Приведение ошибки с выхода НС--О на выход НС--Р}

Для удобства изложения перегруппируем блоки в контуре управления
так, чтобы НС--Р и НС--О располагались последовательно
(\figref{fig:nnplearn}).  Тогда обе нейронных сети можно
рассматривать как одну с $m=m_p+m_o$ слоями и архитектурой
$\NN_{1,\ldots,1,\ldots,1} = \NN^p_{1,\ldots,1}
\cdot \NN^o_{1,\ldots,1}$, Причем с выхода слоя $m_p$
снимается сигнал $u$ и подается на вход объекта. Данная
конструкция на \figref{fig:nnplearn} обведена пунктиром.

\begin{figure}[h]
  \centering
  \input nnplearn.lp
  \caption{Обучение нейросетевого регулятора с помощью инвертирования
  модели объекта.}\label{fig:nnplearn}
\end{figure}

Распространение информации в прямом направлении через слой $d$
нейросети происходит по алгоритму, определяемому следующими
формулами:

$$ \begin{array}{rcl}
  z^d_i & = & \sum\limits_j w^d_{ij}q^{d-1}_j \\
  q^d_i & = & s(z^d_i),
\end{array} $$ где $q^{d-1}_j$ и $q^d_i$ --- вход и выход слоя
соответственно; $w^d_{ij}$ обозначает весовой коэффициент $j$-го
входа $i$-го нейрона; $s(.)$ --- функция активации нейрона. Для
комбинированной сети вход $q^0_1=e_k$, промежуточный выход
$u_k=q^{m_p}_1$ и выход $\hat{y}_{k+1}=q^{m}_1$.

Прогнозируемая ошибка управления равна
$\hat{e}_{k+1}=\hat{y}_{k+1}-r_{k+1}$.  Еј можно рассматривать как
ошибку воспроизведения комбинированной нейросети $\NN$.
Для уменьшения этой ошибки может быть сделан шаг алгоритма
обучения.  По условию считаем, что НС--О повторяет выход объекта
$\hat{y}_{k+1}=y_{k+1}$, следовательно прогнозируемая и реальная
ошибки управления совпадают: $e_{k+1}=\hat{e}_{k+1}$.  То есть,
настройка управляющей части $\NN^p$ комбинированной
нейросети с целью уменьшить ошибку прогноза приведет к уменьшению
ошибки управления реальным объектом.  Итак, эталонной обучающей
парой комбинированной нейросети является $e_k$ (вход НС--Р) и
$r_{k+1}$ (желаемый выход НС--О).

Определим суммарную среднеквадратичную ошибку воспроизведения по
заданной исходной выборке $r$ как

$$ \hatMSE\DEF\frac{1}{2}\sum_k\hat{e}_k^2 =
\frac{1}{2}\sum_k(\hat{y}_k-r_k)^2 $$

Задача обучения нейросети $\NN$ ставится как минимизация
$\hatMSE$ путем подбора весовых коэффициентов $w^d_{ij}$. Поскольку
по условию $\NN^o$ уже обучена, следовательно ошибка
управления может быть устранена только соответствующей настройкой
$\NN^p$.  Поэтому весовые коэффициенты должны
корректироваться только в части $\NN^p$, а именно, в слоях
$1\le d\le m_p$.

В соответствии с алгоритмом обратного распространения на $k$-ом
шаге весовой коэффициент нейрона комбинированной нейросети может
корректироваться по правилу:

\begin{equation}\label{eq:weightchange}
  w^d_{ij}(k+1)=w^d_{ij}(k)-\eta\delta^d_i q^{d-1}_j
\end{equation}

Величина $\delta^d_i$ называется обобщенной ошибкой $i$-го
нейрона; $\eta$ --- коэффициент скорости обучения.

Обобщенная ошибка распространяется от выхода к входу обратно
прямому распространению информации в нейросети и может вычисляться
без коррекции весовых коэффициентов. Еј расчет различается для
выходного и скрытых слоев:

\begin{equation}\label{eq:deltaprop}
  \delta^d_i=\left\{\begin{array}{ll}
    s'(z^d_i)\sum\limits_h\delta^{d+1}_h w^{d+1}_{hi} & 1\le d<m \\
    s'(z^d_i)(\hat{y}_{k+1}-r_{k+1}) & d=m \\
  \end{array}\right.
\end{equation}

Выход слоя $m_p$ используется как управляющее воздействие
$u_k=q^{m_p}_1$. В том случае, если этот слой рассматривать как
выходной у НС--Р, то вычисление обобщенной ошибки для него
формально определялось бы уравнением

\begin{equation}\label{eq:deltapropp-out}
  \delta^{m_p}_i=s'(z^{m_p}_i)(u_k-u^*_k),
\end{equation} где $u^*_k$ --- некоторое целевое значение управляющего
воздействия.  Но в рамках комбинированной нейросети обобщенная
ошибка равна

\begin{equation}\label{eq:deltapropp-hid}
  \delta^{m_p}_i=s'(z^{m_p}_i)\sum_h\delta^{m_p+1}_h
  w^{m_p+1}_{hi}
\end{equation}

Здесь слой $m_p+1$ является входным у НС--О.  Сопоставляя
\eqref{eq:deltapropp-out} и \eqref{eq:deltapropp-hid} выводим, что
для уменьшения ошибки воспроизведения данной эталонной пары {\em
вход--выход} комбинированной нейросетью выход слоя $m_p$ (то есть,
управляющее воздействие $u_k$) следовало бы сделать равным

\begin{equation}\label{eq:desired-u}
  u^*_k=u_k-\sum_h\delta^{m_p+1}_h w^{m_p+1}_{hi}
\end{equation}

Данное выражение вместе с уравнениями~\eqref{eq:deltaprop}
определяет способ вычисления ошибки на выходе нейросетевого
регулятора по ошибке на выходе нейросетевой модели объекта
управления.

\subsubsection{Инверсная модель объекта управления}

Можно обобщить уравнения \eqref{eq:deltaprop} и
\eqref{eq:desired-u} в единой функциональной зависимости,
реализующей метод обратного распространения ошибки в нейросетевой
модели объекта управления без коррекции весовых коэффициентов:

\begin{equation}\label{eq:invobj}
  u^*_k=\mathcal{B}^o(u_k, \hat{y}_{k+1}, r_{k+1})
\end{equation}

В том случае, если НС--О функционирует абсолютно подобно объекту
управления, то есть, $f\equiv \NN^o$, следует ожидать, что
$f^{-1}\equiv {\NN^o}^{-1}=\mathcal{B}^o$.

Другими словами, метод обратного распространения ошибки может
использоваться как вычислительная процедура для инвертирования
функции:

\begin{equation}
  \mathcal{B}^o: r_{k+1} \rightarrow u^*_k
\end{equation}

В случае непрерывного времени идеальная континуальная нейросетевая
модель объекта будет инвертировать желаемый выход объекта в
требуемое управляющее воздействие без задержки, то есть:

$$ \mathcal{B}^o: r(t) \rightarrow u^*(t) $$

Исследуем свойства полученной инверсии.  Поскольку прямая
$\NN^o$ и обратная $\mathcal{B}^o$ функции реализуются с
помощью одного и того же набора параметров $w^d_{ij}$, качество
прогноза выхода объекта напрямую связано с качеством инверсии.

В качестве параметров функции $\mathcal{B}^o$ выступают также
$u_k$ и $\hat{y}_{k+1}$.  Их наличие вызвано тем, что обратное
распространение опирается на информацию, полученную в время
прямого распространения, то есть, более корректно следует записать

\begin{equation}\label{eq:invobj2}
  u^*_k=\mathcal{B}^o(u_k, \NN^o(u_k), r_{k+1})
\end{equation}

Данное представление функции $\mathcal{B}^o$ можно интерпретировать
как инверсию уставки $r_{k+1}$ в некоторой окрестности управляющего
воздействия $u_k$.  То есть, инвертирование объекта управления с
помощью НС--О осуществляется не во всей области определения, а в
некоторой локальной окрестности опорного управляющего воздействия.

%
%{\bf На рисунке приводится пример инверсии функции sin().}

\subsubsection{Обучение нейрорегулятора по инверсной модели}

Будем считать, что НС--О объекта управления абсолютно точно
имитирует его поведение.  Считаем также, что помехи в системе
управления отсутствуют.  Тогда прогноз и наблюдаемый выход объекта
совпадут $y_{k+1}=\hat{y}_{k+1}$.  В этом случае справедлива
формула~\eqref{eq:invobj} инверсии уставки в целевое управляющее
воздействие.

Вычисление функции $\mathcal{B}^o$ осуществляется обратным
распространением фактической ошибки управления
$e_{k+1}=y_{k+1}-r_{k+1}$ вместо прогнозируемой
$\hat{e}_{k+1}=\hat{y}_{k+1}-r_{k+1}$ \eqref{eq:deltaprop} через
НС--О без коррекции весовых коэффициентов нейросети.  Далее
полученное целевое значение $u^*_k$ применяется для настройки
весовых коэффициентов НС--Р с помощью обычной процедуры обратного
распространения, описанной уравнениями \eqref{eq:weightchange},
\eqref{eq:deltaprop}.

Вопрос сходимости алгоритма обучения с обратным распространением
ошибки к оптимальному решению теоретически решается выбором
бесконечно малого шага $\eta$ при отсутствии локальных минимумов в
процессе обучения.  На практике проблема локальных минимумов не
решена ни для одного из градиентных методов оптимизации, поэтому
обычно удовлетворяются первым же достаточно подходящим минимумом,
а неподходящих минимумов избегают с помощью различных
эвристических подходов \cite{wasser92}~\cite{gibb96}. Мера того,
является ли решение (набор весовых коэффициентов сети) подходящим,
определяется значением ошибки регулирования, получаемым на
контрольной выборке.

Коэффициент скорости обучения в классическом алгоритме обратного
распространения обычно подбирается эвристически, хотя и может быть
строго рассчитан~\cite[с.82--97]{terehov99}.  Для улучшения
сходимости широко применяются градиентные методы второго порядка,
развитые на основе алгоритма обратного
распространения~\cite{gibb96}.

\subsection{Выбор начального приближения}\label{init-approach}

Обучение нейросети методом обратного распространения подобно
градиентному методу оптимизации.  Как и в градиентных методах, при
обучении нейросетевого регулятора важен выбор начального
приближения.  Чем ближе он к минимуму функции ошибки, тем меньшее
количество шагов потребуется сделать и тем меньше вероятность
попадания в локальные минимумы.

В качестве начального приближения для НС--Р можно использовать
функцию, реализуемую имеющимся регулятором. Для этого по
достаточно длинной экспериментальной выборке, полученной на
функционирующей САУ с традиционным регулятором, нейросетевой
регулятор может быть обучен функционированию первого в режиме
следования эталону. Очевидно, в этом случае нейросетевой регулятор
не даст улучшения качества управления, однако полученная нейросеть
станет первым приближением в процедуре дальнейшего обучения.

Обучение начальному приближению может быть осуществлено вне
контура управления по временным рядам, полученным в процессе
штатного функционирования исходной системы управления.  Поскольку
вне контура управления можно не следовать достаточно жесткому
ограничению (см. требование~\ref{realcond} на
с.~\pageref{realcond}), в качестве начального состояния весовых
коэффициентов нейросети можно использовать любое из известных
эвристических правил~\cite{gibb96}.

После успешного обучения начальному приближению нейросетевой
регулятор может использоваться в контуре управления вместо
исходного.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Методика синтеза}

Рассмотрим подробно этапы методики синтеза нейросетевого
квазиоптимального регулятора.  Структура САУ и накладываемые на
методику синтеза ограничения изложены в начале главы.

\subsection{Выбор структуры нейросетевой модели объекта}

Как уже отмечалось, выбранная базовая архитектура нейронной сети
не обладает свойством сохранения состояния, а потому нейросеть,
реализующая зависимость $\hat{y}_{k+1}=\NN^o(u_k)$
непосредственно не позволит создавать модели, адекватные
динамическим объектам.

Рассмотрим задачу построения нейросетевой модели некоторого
одномерного линейного динамического объекта управления.  В
дискретном времени в терминах пространства состояний объект
управления можно представить следующей системой разностных
уравнений:

\begin{equation}\label{eq:siso}
\left\{\begin{array}{rcl}
  \mathbf{x}_{k+1} & = & F \mathbf{x}_k + G u_k \\
  y_k & = & H \mathbf{x}_k
\end{array}\right.
\end{equation} где $y_k$ и $u_k$ --- скаляры, а $\mathbf{x}$ --- вектор
состояния.

Статическая нейросеть описанной в разделе~\ref{nnarch}
архитектуры, реализующая функцию $\hat{y}_{k+1} =
\NN^o(u_k)$, принципиально не может решить задачу имитации
поведения динамического объекта \eqref{eq:siso}, так как
нейросеть не обладает состоянием: в любой момент выход нейронной
сети прямого распространения полностью определяется еј актуальными
входами и не зависит от состояния нейросети в предыдущие моменты
времени, а также от прошлых входов.

Для построения адекватной динамической модели следует снабдить
нейросеть информацией о прошлых состояниях.  Можно предложить
несколько способов решения этой проблемы.  Наиболее очевидный
способ состоит в добавлении внешних обратных связей к базовой
нейросети.  Другой вариант предполагает непосредственное
повторение нескольких прошлых наблюдений с целью ``напомнить''
нейросети о состоянии моделируемого объекта в предыдущие моменты
времени.

\subsubsection{Внешние обратные связи}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:nno-feedback}
% Рисунок с обратной связью %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Нейросетевая модель объекта в рамках данного подхода оснащается
дополнительными входами, на которые подается выход модели,
полученный в предыдущий момент времени:

$$ \hat{y}_{k+1}=\NN^o(u_k, \hat{y}_k) $$

Задержанный сигнал обратной связи $\hat{y}_k$ имеет смысл памяти
состояния.

Для обучения нейронных сетей с внешними обратными связями
используется метод обратного распространения в времени ({\em
backpropagation through time ---
BPTT})~\cite{gibb96}~\cite{sigom00}.

Применительно к рассматриваемой задаче данный подход имеет то
преимущество, что для обучения НС--О требуется только выборка
обучающих пар $(u_k, y_{k+1})$, записанных при управлении объектом
в замкнутом контуре.  Сам объект при обучении и при
функционировании модели не используется.  То есть, время и методы
настройки и проверки модели ничем не ограничены.  Нейросетевая
модель объекта в данном случае является полностью автономной.

%Однако в случае непредсказуемой ситуации, не учтенной в обучающих
%данным (например, сильная пиковая помеха), могут сказаться
%нелинейные свойства объекта и его состояние по сравнению с
%нейросетевой моделью

Однако BPTT, наиболее универсальный и мощный метод обучения
многослойных нейронных сетей с внешними обратными связями,
обладает существенным недостатком.  Это так называемый эффект
исчезающего градиента ({\em vanishing gradient}), проявляющийся в
том, что нейросеть выявляет короткие зависимости в обучающей
последовательности, но не может научиться длинным в силу
многократного ослабления информации о зависимости в обратной
связи~\cite{linetal}.

Применительно к задаче нейросетевой имитации объекта управления
проблема исчезающего градиента будет возникать в двух случаях:
\begin{itemize}
  \item значительное чистое запаздывание в динамике объекта
  управления;
  \item шаг квантования времени слишком мал по сравнению с
  характерным временем наступления установившегося режима.
\end{itemize}

Поскольку оба случая представляются достаточно распространенными,
решено отказаться от применения данного подхода к моделированию
объекта управления.  В противном случае, разрабатываемый метод
синтеза квазиоптимального нейрорегулятора имел бы более узкую
область применения.

\subsubsection{Повторение прошлых состояний}

% repeated past state
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:nno-past-states}
% Рисунок с прошлыми состояниями %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Обратной связи вокруг НС--О можно избежать, если использовать для
нейросетевого моделирования динамики объекта несколько прошлых его
состояний, которые непосредственно наблюдались в предыдущие
моменты времени.  В этом случае прогноз выхода объекта нейросетью
каждый раз строится только на основе реальной информации из
контура управления:

\begin{equation}\label{eq:past-states}
  \hat{y}_{k+1}=\NN^o(u_k, u_{k-1},\ldots,u_{k-D_u}, y_k,
                              y_{k-1},\ldots, y_{k-D_y})
\end{equation}

Эта модель с точки зрения входов--выходов является аналогом
авторегрессии--скользящего среднего (АРСС), однако не линейной, а
нейросетевой.  Еј обучение осуществляется вне контура управления на
некоторой тестовой выборке, включающей временные ряды $u_k$ и
$y_{k+1}$.  Нейронная сеть $\NN^o$ обучает делать прогноз
состояния объекта максимально близко к реально наблюдавшемуся
значению.

После сеанса обучения настроенная нейросеть может использоваться в
контуре управления для предсказания выхода объекта и для настройки
нейрорегулятора.

Такая модель не является автономной.  Она требует наличия объекта,
функционирующего в контуре управления.  Это утверждение было проверено
на вычислительном эксперименте, в котором настроенная по прошлым
состояниям модель была включена с обратными связями,
подобно~\figref{fig:nno-feedback}:

\begin{equation}\label{eq:bad-past-states}
  \hat{y}_{k+1}=\NN^o(u_k, u_{k-1},\ldots,u_{k-D_u}, \hat{y}_k,
                              \hat{y}_{k-1},\ldots, \hat{y}_{k-D_y})
\end{equation}

В эксперименте на вход линейной модели объекта управления подавалось
управляющее воздействие, представлявшее собой окрашенный случайный
временной ряд.  Параллельно с объектом была включена по формуле
\eqref{eq:bad-past-states} модель, обученная по схеме с повторением
прошлых состояний.  Эксперимент показал, что модель
\eqref{eq:bad-past-states} сразу ``уходит'' с траектории выхода
объекта управления и выход модели нисколько не повторяет ожидаемую
траекторию.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:bad-past-states}
% График с результатами неправильного использования модели rps %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Как видно, нейросетевая модель объекта управления с повторением
прошлых состояний опирается на информацию об истинном, а не
предсказанном на предыдущих шагах состоянии объекта.

%Постоянная связь с объектом управления, имеющая место в данной
%нейросетевой модели, в некоторых случаях может оказаться полезной.
%В частности, в том случае,

\subsubsection{Инвертирование модели повторения прошлых состояний}

В целом, результаты, полученные в разделе \ref{nnc_optimal_training},
сохраняют свою силу.  Однако следует уточнить \eqref{eq:invobj2} в
соответствии с \eqref{eq:past-states}:

\begin{equation}\label{eq:invobj3}
  u^*_k=\mathcal{B}^o(u_k, \NN^o(u_k,\ldots,u_{k-D_u}, y_k,
                                         \ldots, y_{k-D_y}), r_{k+1})
\end{equation}

Видим, что следствием неавтономности модели является использование
наблюдаемых состояний объекта управления для его инвертирования и,
значит, для обучения нейрорегулятора.  Иными словами, обучение
нейросетевого регулятора должно осуществляться в контуре управления в
режиме рабочего функционирования.

\subsection{Уточнение структуры модели повторения прошлых состояний}

Общая структура нейросетевой модели объекта управления представлена на
\figref{fig:nno-past-states} и описывается уравнением
\eqref{eq:past-states}.  Очевидно, имеет место задача выбора интервала
прошлых наблюдений, используемых для построения модели, а также,
конкретизация числа слоев и нейронов, необходимых для решения задачи
имитации конкретного объекта управления.

\subsubsection{Структура и число входов НС--О}

Поскольку в рамках данной главы рассматриваются стационарные линейные
объекты управления, предлагается методика расчета числа входов
нейросетевой модели, основанная на предположении о линейности объекта.

%Это не означает, что рассматриваемый метод ограничен сугубо линейным

Линейный объект управления полностью характеризуется имульсной
переходной характеристикой.  Пример отклика приведен на
\figref{step-response}.  Времена $T_{delay}$ и $T_{perehod}$
характеризуют чистое запаздывание и длительность переходного процесса.

Выбор числа входов для НС--О должен делаться на основе свойства
отсутствия памяти состояния в нейросети.  Поэтому нейросеть должна
быть обеспечена всей необходимой информацией для имитации объекта.

В случае наличия в объекте чистого запаздывания информация о
воздействии, породившем отклик объекта, должна иметься у нейронной
сети к моменту появления этого отклика на выходе объекта.  То есть,
достаточное число повторов управляющего воздействия на входе НС--О
должно быть не больше $1+T_{delay}/\Delta T$, где $\Delta T$ --- шаг
квантования времени в системе.

Переходный процесс является характерным проявлением динамических
свойств объекта управления.  Время его завершения является мерой
инерционности объекта и оно должно имитироваться нейросетевой моделью.
Для описания инерционности объекта статической нейросетью требуется не
больше чем $1+T_{perehod}/\Delta T$ повторений прошлых состояний
объекта управления.

Таким образом, получены верхние оценки необходимого числа входов для
нейросетевой модели объекта управления:

\begin{equation}\label{eq:nno-inputs-number}
\begin{array}{rcl}
  D_u & = & T_{delay}/\Delta T \\
  D_y & = & T_{perehod}/\Delta T
\end{array}
\end{equation}

%Поскольку
%этап подгонки модели соответствует процессу обучения НС--О, для выбора
%структуры входов нейросетевой модели достаточно воспользоваться
%методами, основанными на построении выборочной взаимной корреляционной
%функции, описанными в литературе~\cite{ostrem73}\cite{boxjenk74}.



\subsection{Выбор структуры нейрорегулятора}


\subsubsection{Следствия неавтономности нейросетевой модели}

Неавтономность используемой нейросетевой модели объекта управления
является важной особенностью предлагаемого метода, поскольку из неј
следуют серьезные ограничения при работе с реальным объектом
управления:

\begin{enumerate}

  \item\label{stability-cond} В процессе настройки нейросетевого
  регулятора должна обеспечиваться устойчивость замкнутого контура САУ
  и объекта управления (если он в разомкнутом состоянии неустойчив).

  \item\label{force-limits} Величины управляющих воздействий не должны
  превышать пределов, накладываемых конструктивными особенностями
  исполняющих органов.

  \item\label{real-time} Время обучения нейросетевого регулятора
  становится реальным, то есть, квант времени алгоритма обучения
  оказывается связан с физическим временем системы управления.

\end{enumerate}

Ограничение \ref{stability-cond} на начальных порах настройки НС--Р в
замкнутом контуре должно обеспечиваться с помощью выбора подходящего
начального приближения.  Наиболее очевидный вариант выбора описан в
разделе \ref{init-approach}.  Поддержание устойчивости в процессе
дообучения НС--Р с помощью инверсной нейросетевой модели должно быть
организовано {\bf специальной процедурой, описанной в ????}

%, отключающей НС--Р от управления объектом в

Для гарантированного выполнения ограничения \ref{force-limits}
предлагается пользоваться масштабированием выходных значений НС--Р в
желаемый диапазон, описанным в разделе \ref{nnarch}.

В том случае, когда существенно ограничение по времени обучения
квазиоптимального нейросетевого регулятора, предлагается осуществлять
настройку НС--Р вне контура управления по физической модели объекта
управления, используемой вместо него самого.


%Синтез нейросетевого регулятора состоит из трех этапов. Первый
%этап включает в себя предварительную настройку НС-Р, на втором
%этапе настраивается модель объекта (НС-О), на третьем этапе НС-Р
%осуществляется окончательная настройка НС-Р.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Результаты имитационного регулирования}

\subsection{Сравнение НОР с линейным оптимальным регулятором}

\subsection{Особенности НОР по сравнению с традиционным
регулятором}

%Рассмотрение важности плос

% Конец Главы 2
