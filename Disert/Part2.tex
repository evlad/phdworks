% Глава 2 - Стохастическое оптимальное управление

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Вариант плана
%\section{Причины выбора стохастических методов в качестве полигона
%для применения ИНС (сравнить с другими работами где sin}

%\section{Постановка задачи в стационарном случае}

%\section{Изучение Винеровской и Калмановской фильтрации на предмет
%выявления рационального зерна}

%\section{Сама идея и е\"е аргументация схемы НОР}

%\section{Реализация НОР подобно Винеровскому оптимальному управлению
%--- эксперимент}

% Вопрос устойчивости системы с НОР
% НОР дискретный, а как в непрерывном времени?

%\section{Реализация НОР по произвольному ПИД --- эксперимент}

%\section{Обсуждение полученных результатов --- важность фазовой
%плоскости $u-e$.  Гипотеза о независимости от спектра уставки}

%\section{Проверка гипотезы --- равномерное распределение при обучении НОР
%--- эксперимент}

%\section{Сравнение эффективности НОР с оптимальным управление по
%Калману--Белману --- эксперимент}

%\section{Результаты моделирования для разнообразных
%детерминированных сигналов --- эксперимент}

%\section{Вопросы выбора структуры ИНС-О и ИНС-Р}

%\section{Обсуждение возможности применения архитектуры ИНС-О с ОС}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{noc-method}
\section{Линейная стационарная система автоматического управления
в стохастических условиях}

Рассмотрим линейную систему управления с обратной связью,
изображенную на \figref{fig:ctrlloop}. Будем считать, что
состояние объекта непосредственно измеряется на выходе, однако в
канале наблюдения присутствует аддитивная помеха с некоторыми
постоянными корреляционными свойствами. Параметры объекта
управления также постоянны во времени.  В системе имеется
регулятор, поддерживающий состояние объекта близким к заданной
траектории $r(t)$.  Траектория уставки $r(t)$ рассматривается как
стационарный случайный процесс с некоторыми корреляционными
параметрами.

Рассмотрим задачу синтеза нейросетевого регулятора для замены
имеющегося в описанной системе.  Целью замены зададим улучшение
качества управления в смысле уменьшения среднеквадратичной ошибки
(СО).  Критерий минимума СО является достаточно удобным и эффективным
в линейной теории стохастического оптимального управления и поэтому
широко используется.

%Кроме того, классический алгоритм обучения нейронных сетей
%персептронного типа основан на этом же критерии оптимизации, что
%упрощает применение нейросетей в данном случае.

%\begin{figure}[h]
%  \centering
%  \input ctrlloop.lp
%  \caption{Исходная система управления.}
%  \label{fig:ctrlloop}
%\end{figure}

\begin{figure}[h]
  \centering
  \input rawctrlloop.pic
  \caption{Исходная система управления.}
  \label{fig:ctrlloop}
\end{figure}

В качестве дополнительного ограничения примем, что синтез должен
осуществляться на реально действующем объекте в условиях,
максимально близких к штатным эксплуатационным.  Это условие можно
раскрыть в следующих требованиях к методике проведения работ:

\begin{enumerate}\label{realcond}
  \item При замене имеющегося регулятора нейросетевым последний
  сразу же должен обеспечивать устойчивость системы и качество
  управления не хуже исходного.

  \item Рассматривая действующую систему управления (в
  противоположность проектируемой), следует учитывать возможный
  уже случившийся дрейф параметров объекта управления в процессе
  эксплуатации относительно проектных.

  \item Корреляционные свойства помехи наблюдения должны считаться
  априорно неизвестными в силу зависимости от множества трудно
  учитываемых факторов.
\end{enumerate}

\subsection{Классический подход.}

Если параметры объекта управления и помехи известны, данная задача
решается расчетом Винеровского оптимального линейного фильтра и
построением соответствующего регулятора
\cite{tsipkin58}\cite{solod60}\cite{medv82}. Однако, хорошо
известные недостатки данного подхода (необязательная физическая
осуществимость регулятора, неробастность), а также потребность в
предварительной идентификации параметров объекта управления и
помехи делают проведение синтеза оптимального линейного регулятора
делом достаточно сложным и требующим в каждом случае
индивидуального подхода с использованием аналитических расчетов.

\subsection{Нейросетевой подход.}

Одним из достоинств аппарата искусственных нейронных сетей
является неявное выделение знаний из имеющихся данных. Это значит,
что имеются методики построения алгоритма, осуществляющего без
участия человека настройку параметров нейросети на решение
поставленной задачи.

Рассмотрим задачу синтеза квазиоптимального нейросетевого
регулятора, опираясь в основном на данные, получаемые в результате
функционирования целевой системы управления.

Наличие шумов в исходных данных не должно являться принципиальным
ограничением применения нейросетей, так как известно, что
нейронные сети устойчивы к помехам.  Более того, иногда в
обучающие данные специально вводят небольшой шум, так как это
улучшает обобщающую способность нейросети.

С другой стороны, применение нейронных сетей в рамках данной
задачи требует специального рассмотрения в силу их нелинейности и
специфики алгоритмов настройки.  Поэтому для оценки качества
синтезированного регулятора целесообразно провести сравнительный
анализ с линейным оптимальным решением и выявить особенности
обоих.

Синтез нейросетевого регулятора будем проводить в дискретном
времени.  Данное условие диктуется широким применением средств
цифровой вычислительной техники для моделирования и обучения
искусственных нейронных сетей.

Рассмотрение в дискретном времени не является принципиальным
ограничением, присущим нейронным сетям, поскольку их применение
возможно и в непрерывном времени.  Однако континуальные сети
являются нетрадиционными в общем русле исследований по применению
нейронных сетей.  Существенно также, что моделирование
континуальных нейронных сетей и их применение требует
использования дорогостоящей специальной аппаратуры.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Общая схема и проблемы синтеза нейрорегулятора}

\subsection{Архитектура нейросети}\label{nnarch}

В качестве базовой архитектуры для синтезируемого регулятора
выберем многослойную искусственную нейронную сеть прямого
распространения с гиперболическим тангенсом в качестве функции
активации нейронов.  Эта сеть является классической и е\"е свойства
широко исследовались на протяжении ряда лет как в теоретическом
плане, так и в различных прикладных задачах.

%Имеются многочисленные варианты усовершенствовани

Для описания параметров многослойных нейронных сетей будем
использовать обозначение
$\mathcal{N}_{n_0,n_1,\ldots,n_{m-1},n_m}$, где $n_0$ --- число
входов первого (входного) слоя сети, $n_1,\ldots,n_{m-1}$ ---
число нейронов в последовательно расположенных скрытых слоях,
$n_m$ --- число нейронов (и выходов) последнего, выходного слоя.
Всего в нейронной сети имеется $m$ последовательных слоев,
полностью соединенных друг с другом.  Например, сеть, изображенная
на \figref{fig:mlann}, обозначается как $\mathcal{N}_{4,3,4,2}$.

\begin{figure}[h]
  \centering
  \input mlann.lp
  \caption{Многослойная нейронная сеть.}\label{fig:mlann}
\end{figure}

Выход каждого из нейронов вычисляется по формуле

$$y=s(\sum_{j=1}^nw_j x_j)$$

\noindent где $y\in{\mathbb R}$ --- выход нейрона, $x_j\in{\mathbb
R}$ --- $n$ входов нейрона, $w_j\in{\mathbb R}$ --- весовые
коэффициенты на входах, $s$ --- дифференцируемая монотонно
возрастающая функция активации с областью определения ${\mathbb
R}$.  График функции гиперболического тангенса, часто используемой
в качестве функции активации нейронов, приводится на
\figref{fig:tanh}.  Использование нелинейной функции активации,
как известно~\cite{wasser92}, придает многослойной нейронной сети
свойство аппроксимации любых, в том числе, нелинейных,
зависимостей.

%$$ s(x)=\tanh x=\frac{2}{1+e^{-x}}-1 $$

\begin{figure}[h]
  \centering
  \input tanh.pic
  \caption{Гиперболический тангенс.}
  \label{fig:tanh}
\end{figure}

Следует особо отметить, что выходы нейронной сети однозначно
определяются е\"е входами в заданный момент времени.  Состояние или
память входных значений в предыдущие моменты времени в нейросети
представленной архитектуры отсутствует.  Таким образом, нейросеть
не является реальной динамической системой в понимании теории
управления: в ней отсутствует задержка реакции на входное
возмущение и, соответственно, переходный процесс как следствие
инерционности реакции.  Эквивалентом представленной архитектуры
является идеальное (безынерционное) звено с коэффициентом
усиления, зависящим от величины входного возмущающего воздействия.

Для этой архитектуры разработаны многочисленные методики обучения,
в основном базирующиеся на алгоритме обратного распространения
ошибки.  Свойства алгоритмов обучения и самой нейросети хорошо
изучены.  Данная архитектура нашла применение в самом широком
спектре задач, в том числе, в задачах идентификации и управления.

Поскольку гиперболический тангенс функция обладает ограниченной
областью значений, для представления чисел требуемого диапазона
можно применить один из следующих методов:

\begin{enumerate}
  \item Масштабирование выходных значений нейросети в желаемый
  диапазон.
  \item Использование линейной функции активации нейронов
  выходного слоя.  В этом случае для обеспечения необходимой
  представительной мощности нейросеть должна иметь не менее двух
  скрытых слоев с нелинейными функциями активации.
\end{enumerate}

Первый метод гарантирует ограниченность выходных значений
нейросети внутри заданного диапазона.  Это может оказаться
полезным при решении задач управления с физическими ограничениями
на диапазон управляющих воздействий.

Если постановка задачи обучения нейросети не предусматривает
ограничений, то второй метод расширения диапазона выходных
значений более предпочтителен.  Он обеспечивает возможность в
процессе настройки нейронной сети автоматически выбрать нужный
коэффициент масштабирования.

\subsection{Проблема эталона при обучении нейрорегулятора}

% Проблема обучения --- нужна инверсная модель
Как уже отмечалось, к наиболее распространенным методам обучения
нейронных сетей относится семейство методов обратного
распространения ошибки ({\em backpropagation of error}). Это так
называемые методы обучения с учителем ({\em supervised learning}),
то есть, нейросеть обучается на эталонных парах {\em вход--выход.}
Получение эталонной пары в рассматриваемой задаче представляет
определенную проблему.

По условию задачи исходный регулятор не является оптимальным, а
значит, пара {\em вход--выход}, измеренная на регуляторе, не может
являться эталоном при настройке квазиоптимального нейросетевого
регулятора.  Эталонная (то есть, ведущая к оптимальному закону
управления) обучающая пара известна лишь для всей системы --- это
уставка как вход системы и одновременно как е\"е целевой выход.
Очевидно, что условие $y(t) = r(t)$ является идеалом управления
системой и оно удовлетворяет условию минимума среднеквадратичной
ошибки управления.

Таким образом, для обучения нейросетевого регулятора (НС--Р)
возникает задача получения целевого сигнала управления $u^*(t)$ по
эталонному выходу объекта $y^*(t) \equiv r(t)$. Покажем, что это
достигается построением инверсной функции объекта управления.

Запишем зависимость выхода объекта управления от его входа как
$$y=f(u)$$

Тогда оптимальное управляющее воздействие даст желаемый выход

$$y^*=f(u^*)$$

Желаемый выход объекта (уставка) известен, следовательно для
вычисления оптимального управляющего воздействия $u^*$ достаточно
найти $f^{-1}(.)$ --- инверсную функцию объекта
управления.\footnote{Конечно, данная задача может рассматриваться
только в том случае, когда $f^{-1}(.)$ однозначная.}  Тогда

$$u^* = f^{-1}(y^*) \equiv f^{-1}(r)$$

Поскольку реальный объект управления в любом случае не допускает
решения данной задачи, то необходима его инверсная модель.

В качестве инверсной модели можно использовать нейросетевую модель
объекта управления, работающую в обратном направлении в режиме
распространения ошибки с выхода на вход без обучения (коррекции
весовых коэффициентов). Эта нейронная сеть должна быть
предварительно обучена функционировать подобно объекту управления.
В отличие от нейросетевого регулятора она по завершении его
настройки может быть отключена, так как в рабочем режиме и
стационарных условиях нейросетевой регулятор может функционировать
без инверсной модели.


\subsection{Принцип обучения нейрорегулятора с использованием инверсной
модели}

\label{nnplearning} Рассмотрим алгоритм обучения НС--Р с
использованием уже построенной нейросетевой модели объекта
$\mathcal{N}^o$ (НС--О). Для простоты возьмем одномерный объект
управления.  Пока будем считать, что выход объекта полностью
определяется его входом в настоящий момент времени. Положим, что
помехи и прочие возмущающие воздействия в системе отсутствуют.
Нейронная сеть регулятора имеет архитектуру
$\mathcal{N}^p_{1,\ldots,1}$ с $m_p$ слоями. Тогда движение
системы в пространстве состояний из момента времени $t_k$ в
следующий момент $t_{k+1}$ будет описываться следующими
уравнениями:

$$ \left\{\begin{array}{rcl}
  e_k & = & y_k-r_k \\
  u_k & = & \mathcal{N}^p(e_k) \\
  y_{k+1} & = & f(u_k)
\end{array}\right. $$

Кроме того, параллельно с объектом управления включена его
нейросетевая модель, реализуемая сетью с архитектурой
$\mathcal{N}^o_{1,\ldots,1}$ ($m_o$ слоев) и осуществляющая
прогноз выхода объекта:

\begin{equation}\label{eq:nno-principle}
  \hat{y}_{k+1} = \mathcal{N}^o(u_k)
\end{equation}


\subsubsection{Приведение ошибки с выхода НС--О на выход НС--Р}

Для удобства изложения перегруппируем блоки в контуре управления
так, чтобы НС--Р и НС--О располагались последовательно
(\figref{fig:nnplearn}).  Тогда обе нейронных сети можно
рассматривать как одну с $m=m_p+m_o$ слоями и архитектурой
$\mathcal{N}_{1,\ldots,1,\ldots,1} = \mathcal{N}^p_{1,\ldots,1}
\cdot \mathcal{N}^o_{1,\ldots,1}$, Причем с выхода слоя $m_p$
снимается сигнал $u$ и подается на вход объекта. Данная
конструкция на \figref{fig:nnplearn} обведена пунктиром.

\begin{figure}[h]
  \centering
  \input nnplearn.lp
  \caption{Обучение нейросетевого регулятора с помощью инвертирования
  модели объекта.}\label{fig:nnplearn}
\end{figure}

Распространение информации в прямом направлении через слой $d$
нейросети происходит по алгоритму, определяемому следующими
формулами:

$$ \begin{array}{rcl}
  z^d_i & = & \sum\limits_j w^d_{ij}q^{d-1}_j \\
  q^d_i & = & s(z^d_i),
\end{array} $$ где $q^{d-1}_j$ и $q^d_i$ --- вход и выход слоя
соответственно; $w^d_{ij}$ обозначает весовой коэффициент $j$-го
входа $i$-го нейрона; $s(.)$ --- функция активации нейрона. Для
комбинированной сети вход $q^0_1=e_k$, промежуточный выход
$u_k=q^{m_p}_1$ и выход $\hat{y}_{k+1}=q^{m}_1$.

Прогнозируемая ошибка управления равна
$\hat{e}_{k+1}=\hat{y}_{k+1}-r_{k+1}$.  Е\"е можно рассматривать как
ошибку воспроизведения комбинированной нейросети $\mathcal{N}$.
Для уменьшения этой ошибки может быть сделан шаг алгоритма
обучения.  По условию считаем, что НС--О повторяет выход объекта
$\hat{y}_{k+1}=y_{k+1}$, следовательно прогнозируемая и реальная
ошибки управления совпадают: $e_{k+1}=\hat{e}_{k+1}$.  То есть,
настройка управляющей части $\mathcal{N}^p$ комбинированной
нейросети с целью уменьшить ошибку прогноза приведет к уменьшению
ошибки управления реальным объектом.  Итак, эталонной обучающей
парой комбинированной нейросети является $e_k$ (вход НС--Р) и
$r_{k+1}$ (желаемый выход НС--О).

Определим суммарную среднеквадратичную ошибку воспроизведения по
заданной исходной выборке $r$ как

$$ \hatSE\DEF\frac{1}{2}\sum_k\hat{e}_k^2 =
\frac{1}{2}\sum_k(\hat{y}_k-r_k)^2 $$

Задача обучения нейросети $\mathcal{N}$ ставится как минимизация
$\hatSE$ путем подбора весовых коэффициентов $w^d_{ij}$. Поскольку
по условию $\mathcal{N}^o$ уже обучена, следовательно ошибка
управления может быть устранена только соответствующей настройкой
$\mathcal{N}^p$.  Поэтому весовые коэффициенты должны
корректироваться только в части $\mathcal{N}^p$, а именно, в слоях
$1\le d\le m_p$.

В соответствии с алгоритмом обратного распространения на $k$-ом
шаге весовой коэффициент нейрона комбинированной нейросети может
корректироваться по правилу:

\begin{equation}\label{eq:weightchange}
  w^d_{ij}(k+1)=w^d_{ij}(k)-\eta\delta^d_i q^{d-1}_j
\end{equation}

Величина $\delta^d_i$ называется обобщенной ошибкой $i$-го
нейрона; $\eta$ --- коэффициент скорости обучения.

Обобщенная ошибка распространяется от выхода к входу обратно
прямому распространению информации в нейросети и может вычисляться
без коррекции весовых коэффициентов. Е\"е расчет различается для
выходного и скрытых слоев:

\begin{equation}\label{eq:deltaprop}
  \delta^d_i=\left\{\begin{array}{ll}
    s'(z^d_i)\sum\limits_h\delta^{d+1}_h w^{d+1}_{hi} & 1\le d<m \\
    s'(z^d_i)(\hat{y}_{k+1}-r_{k+1}) & d=m \\
  \end{array}\right.
\end{equation}

Выход слоя $m_p$ используется как управляющее воздействие
$u_k=q^{m_p}_1$. В том случае, если этот слой рассматривать как
выходной у НС--Р, то вычисление обобщенной ошибки для него
формально определялось бы уравнением

\begin{equation}\label{eq:deltapropp-out}
  \delta^{m_p}_i=s'(z^{m_p}_i)(u_k-u^*_k),
\end{equation} где $u^*_k$ --- некоторое целевое значение управляющего
воздействия.  Но в рамках комбинированной нейросети обобщенная
ошибка равна

\begin{equation}\label{eq:deltapropp-hid}
  \delta^{m_p}_i=s'(z^{m_p}_i)\sum_h\delta^{m_p+1}_h
  w^{m_p+1}_{hi}
\end{equation}

Здесь слой $m_p+1$ является входным у НС--О.  Сопоставляя
\eqref{eq:deltapropp-out} и \eqref{eq:deltapropp-hid} выводим, что
для уменьшения ошибки воспроизведения данной эталонной пары {\em
вход--выход} комбинированной нейросетью выход слоя $m_p$ (то есть,
управляющее воздействие $u_k$) следовало бы сделать равным

\begin{equation}\label{eq:desired-u}
  u^*_k=u_k-\sum_h\delta^{m_p+1}_h w^{m_p+1}_{hi}
\end{equation}

Данное выражение вместе с уравнениями~\eqref{eq:deltaprop}
определяет способ вычисления ошибки на выходе нейросетевого
регулятора по ошибке на выходе нейросетевой модели объекта
управления.

\subsubsection{Инверсная модель объекта управления}

Можно обобщить уравнения \eqref{eq:deltaprop} и
\eqref{eq:desired-u} в единой функциональной зависимости,
реализующей метод обратного распространения ошибки в нейросетевой
модели объекта управления без коррекции весовых коэффициентов:

\begin{equation}\label{eq:invobj}
  u^*_k=\mathcal{B}^o(u_k, \hat{y}_{k+1}, r_{k+1})
\end{equation}

В том случае, если НС--О функционирует абсолютно подобно объекту
управления, то есть, $f\equiv \mathcal{N}^o$, следует ожидать, что
$f^{-1}\equiv {\mathcal{N}^o}^{-1}=\mathcal{B}^o$.

Другими словами, метод обратного распространения ошибки может
использоваться как вычислительная процедура для инвертирования
функции, то есть:

\begin{equation}
  \mathcal{B}^o: r_{k+1} \rightarrow u^*_k
\end{equation}

В случае непрерывного времени идеальная континуальная нейросетевая
модель объекта будет инвертировать желаемый выход объекта в
требуемое управляющее воздействие без задержки, то есть:

$$ \mathcal{B}^o: r(t) \rightarrow u^*(t) $$

Исследуем свойства полученной инверсии.  Поскольку прямая
$\mathcal{N}^o$ и обратная $\mathcal{B}^o$ функции реализуются с
помощью одного и того же набора параметров $w^d_{ij}$, качество
прогноза выхода объекта напрямую связано с качеством инверсии.

В качестве параметров функции $\mathcal{B}^o$ выступают также
$u_k$ и $\hat{y}_{k+1}$.  Их нфазового аличие вызвано тем, что обратное
распространение опирается на информацию, полученную во время
прямого распространения, то есть, более корректно следует записать

\begin{equation}\label{eq:invobj2}
  u^*_k=\mathcal{B}^o(u_k, \mathcal{N}^o(u_k), r_{k+1})
\end{equation}

Данное представление функции $\mathcal{B}^o$ можно интерпретировать
как инверсию уставки $r_{k+1}$ в некоторой окрестности управляющего
воздействия $u_k$.  То есть, инвертирование объекта управления с
помощью НС--О осуществляется не во всей области определения, а в
некоторой локальной окрестности опорного управляющего воздействия,
задающего оценку состояния объекта управления..

\paragraph{Связь нейросетевой инверсии и якобиана объекта управления}
Якобиан --- матрица скалярных частных производных переменных состояния
по входам --- является мерой реакции объекта на изменение управляющих
воздействий в заданной точке пространства состояний.  Для простого
объекта с одним управляющим входом и одной переменной состояния,
наблюдаемого на выходе, якобиан упрощается до обычной производной:

\begin{equation}\label{eq:jacobian}
  J(t)=\Biggl(\frac{\partial y_i}
		   {\partial u_j}\Biggr)_{i,j}=\frac{d y(t)}{d u}
\end{equation}

Линейную оценку якобиана~\eqref{eq:jacobian} в окрестности номинальной
траектории можно рассчитать по формуле
$$
  J_k=\frac{\Delta y_{k+1}}{\Delta u_{k}}
$$ откуда следует, что для получения желаемого состояния объекта
$y_{k+1}=r_{k+1}$ следует приложить управление $u^*_k$:
$$
  r_{k+1}=y_k+J_k(u^*_k}-u_{k-1})
$$ следовательно
\begin{equation}\label{eq:jacobinv}
  u^*_k=u_{k-1}+(r_{k+1}-y_k)/J_k
\end{equation}

Очевидна аналогия между формулами \eqref{eq:jacobinv} и
\eqref{eq:invobj2}.  Таким образом, нейросетевая функция
$\mathcal{B}^o$ включает в себя оценку якобиана объекта управления.

%
%{\bf На рисунке приводится пример инверсии функции sin().}

\subsubsection{Обучение нейрорегулятора по инверсной модели}

Будем считать, что НС--О объекта управления абсолютно точно
имитирует его поведение.  Считаем также, что помехи в системе
управления отсутствуют.  Тогда прогноз и наблюдаемый выход объекта
совпадут $y_{k+1}=\hat{y}_{k+1}$.  В этом случае справедлива
формула~\eqref{eq:invobj} инверсии уставки в целевое управляющее
воздействие.

Вычисление функции $\mathcal{B}^o$ осуществляется обратным
распространением фактической ошибки управления
$e_{k+1}=y_{k+1}-r_{k+1}$ вместо прогнозируемой
$\hat{e}_{k+1}=\hat{y}_{k+1}-r_{k+1}$ \eqref{eq:deltaprop} через
НС--О без коррекции весовых коэффициентов нейросети.  Далее
полученное целевое значение $u^*_k$ применяется для настройки
весовых коэффициентов НС--Р с помощью обычной процедуры обратного
распространения, описанной уравнениями \eqref{eq:weightchange},
\eqref{eq:deltaprop}.

Вопрос сходимости алгоритма обучения с обратным распространением
ошибки к оптимальному решению теоретически решается выбором
бесконечно малого шага $\eta$ при отсутствии локальных минимумов в
процессе обучения.  На практике проблема локальных минимумов не
решена ни для одного из градиентных методов оптимизации, поэтому
обычно удовлетворяются первым же достаточно подходящим минимумом,
а неподходящих минимумов избегают с помощью различных
эвристических подходов \cite{wasser92}~\cite{gibb96}. Мера того,
является ли решение (набор весовых коэффициентов сети) подходящим,
определяется значением ошибки регулирования, получаемым на
контрольной выборке.

Коэффициент скорости обучения в классическом алгоритме обратного
распространения обычно подбирается эвристически, хотя и может быть
строго рассчитан~\cite[с.82--97]{terehov99}.  Для улучшения
сходимости широко применяются градиентные методы второго порядка,
развитые на основе алгоритма обратного
распространения~\cite{gibb96}.

\subsection{Выбор начального приближения НС--Р}\label{init-approach}

Обучение нейросети методом обратного распространения подобно
градиентному методу оптимизации.  Как и в градиентных методах, при
обучении нейросетевого регулятора важен выбор начального
приближения.  Чем ближе он к минимуму функции ошибки, тем меньшее
количество шагов потребуется сделать и тем меньше вероятность
попадания в локальные минимумы.

В качестве начального приближения для НС--Р можно использовать
функцию, реализуемую имеющимся регулятором. Для этого по
достаточно длинной экспериментальной выборке, полученной на
функционирующей САУ с традиционным регулятором, нейросетевой
регулятор может быть обучен функционированию первого в режиме
следования эталону. Очевидно, в этом случае нейросетевой регулятор
не даст улучшения качества управления, однако полученная нейросеть
станет первым приближением в процедуре дальнейшего обучения.

Обучение начальному приближению может быть осуществлено вне
контура управления по временным рядам, полученным в процессе
штатного функционирования исходной системы управления.  Поскольку
вне контура управления можно не следовать достаточно жесткому
ограничению (см. требование~\ref{realcond} на
с.~\pageref{realcond}), в качестве начального состояния весовых
коэффициентов нейросети можно использовать любое из известных
эвристических правил~\cite{gibb96}.

После успешного обучения начальному приближению нейросетевой
регулятор может использоваться в контуре управления вместо
исходного.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Методика синтеза}

Рассмотрим подробно этапы методики синтеза нейросетевого
квазиоптимального регулятора.  Структура САУ и накладываемые на
методику синтеза ограничения изложены в начале главы.

\subsection{Синтез нейросетевой модели объекта управления}

При построении нейросетевой модели реального объекта управления
возникает задача конкретизации архитектуры нейросети и условий её
настройки.  Очевидно, этот этап синтеза нейрорегулятора существенно
зависит от условий: объекта управления, свойств помехи, длины и
корреляционных свойств имеющихся экспериментальных выборок.
Исследование этих зависимостей представляет существенный интерес и
должно послужить более ясному представлению о применимости нейросетей
в системах управления.

\subsubsection{Структура входов нейросети}

Как уже отмечалось, выбранная базовая архитектура нейронной сети
не обладает свойством сохранения состояния, а потому нейросеть,
реализующая зависимость $\hat{y}_{k+1}=\mathcal{N}^o(u_k)$
непосредственно не позволит создавать модели, адекватные
динамическим объектам.

Рассмотрим задачу построения нейросетевой модели некоторого
одномерного линейного динамического объекта управления.  В
дискретном времени в терминах пространства состояний объект
управления можно представить следующей системой разностных
уравнений:

\begin{equation}\label{eq:1d-ss}
\left\{\begin{array}{rcl}
  \mathbf{x}_{k+1} & = & F \mathbf{x}_k + G u_k \\
  y_k & = & H \mathbf{x}_k
\end{array}\right.
\end{equation} где $y_k$ и $u_k$ --- скаляры, а $\mathbf{x}$ --- вектор
состояния.

Статическая нейросеть описанной в разделе~\ref{nnarch}
архитектуры, реализующая функцию $\hat{y}_{k+1} =
\mathcal{N}^o(u_k)$, принципиально не может решить задачу имитации
поведения динамического объекта \eqref{eq:1d-ss}, так как
нейросеть не обладает состоянием: в любой момент выход нейронной
сети прямого распространения полностью определяется е\"е актуальными
входами и не зависит от состояния нейросети в предыдущие моменты
времени, а также от прошлых входов.

Для построения адекватной динамической модели следует снабдить
нейросеть информацией о прошлых состояниях.  Можно предложить
несколько способов решения этой проблемы.  Наиболее очевидный
способ состоит в добавлении внешних обратных связей к базовой
нейросети.  Другой вариант предполагает непосредственное
повторение нескольких прошлых наблюдений с целью ``напомнить''
нейросети о состоянии моделируемого объекта в предыдущие моменты
времени.

\paragraph{Внешние обратные связи}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:nno-feedback}
% Рисунок с обратной связью %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h]
  \centering
  \input nno_feedback.pic
  \caption{Модель с внешней обратной связью.}
  \label{fig:nno-feedback}
\end{figure}

Нейросетевая модель объекта в рамках данного подхода оснащается
дополнительным входом, на который подается выход модели,
полученный в предыдущий момент времени:

$$ \hat{y}_{k+1}=\mathcal{N}^o(u_k, \hat{y}_k) $$

Задержанный сигнал обратной связи $\hat{y}_k$ имеет смысл памяти
состояния.  Схема модели приводится на~\figref{fig:nno-feedback}.

Для обучения нейронных сетей с внешними обратными связями можно
использовать метод обратного распространения в времени ({\em
backpropagation through time --- BPTT})~\cite{gibb96}~\cite{sigom00}.

Применительно к рассматриваемой задаче данный подход имеет то
преимущество, что для обучения НС--О требуется только выборка
обучающих пар $(u_k, y_k)$, записанных при управлении объектом в
замкнутом контуре.  Сам объект при обучении и при функционировании
модели не используется.  То есть, время и методы настройки и проверки
модели ничем не ограничены.  Нейросетевая модель объекта в данном
случае является полностью автономной.  Эта нейросетевая модель
имитирует {\it поведение }объекта.

%Однако в случае непредсказуемой ситуации, не учтенной в обучающих
%данным (например, сильная пиковая помеха), могут сказаться
%нелинейные свойства объекта и его состояние по сравнению с
%нейросетевой моделью

Однако BPTT, наиболее универсальный и мощный метод обучения
многослойных нейронных сетей с внешними обратными связями,
обладает существенным недостатком.  Это так называемый эффект
исчезающего градиента ({\em vanishing gradient}), проявляющийся в
том, что нейросеть выявляет короткие зависимости в обучающей
последовательности, но не может научиться длинным в силу
многократного ослабления информации о зависимости в обратной
связи в процессе обратного распространения ошибки~\cite{linetal}.

Применительно к задаче нейросетевой имитации объекта управления
проблема исчезающего градиента будет возникать в двух случаях:
\begin{itemize}\label{simple-feedback-defects}
  \item значительное чистое запаздывание в динамике объекта
  управления;
  \item шаг квантования времени слишком мал по сравнению с
  характерным временем наступления установившегося режима.
\end{itemize}

Поскольку оба случая представляются достаточно распространенными,
решено отказаться от применения данного подхода к моделированию
объекта управления.  В противном случае, разрабатываемый метод
синтеза квазиоптимального нейрорегулятора имел бы более узкую
область применения.

\paragraph{Повторение прошлых состояний}

% repeated past state
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:nno-past-states}
% Рисунок с прошлыми состояниями %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h]
  \centering
  \input nno_paststates.pic
  \caption{Пример модели с повторением прошлых состояний
  $\hat{y}_{k+1}=\mathcal{N}^o(u_k, y_k, y_{k-1})$.}
  \label{fig:nno-past-states}
\end{figure}

Обратной связи вокруг НС--О можно избежать, если использовать для
нейросетевого моделирования динамики объекта несколько прошлых его
состояний, которые непосредственно наблюдались в предыдущие
моменты времени.  В этом случае прогноз выхода объекта нейросетью
каждый раз строится только на основе реальной информации из
контура управления:

\begin{equation}\label{eq:past-states}
  \hat{y}_{k+1}=\mathcal{N}^o(u_k, u_{k-1},\ldots,u_{k-D_u}, y_k,
                              y_{k-1},\ldots, y_{k-D_y})
\end{equation}

Схема одной из возможных моделей с повторением прошлых состояний
приводится на~\figref{fig:nno-past-states}.

Эта модель с точки зрения входов--выходов аналогична модели
авторегрессии--скользящего среднего (АРСС), однако не линейной, а
нейросетевой.  Е\"е обучение осуществляется вне контура управления на
некоторой тестовой выборке, включающей временные ряды $u_k$ и $y_k$.
Нейронная сеть $\mathcal{N}^o$ обучается делать прогноз состояния
объекта максимально близко к реально наблюдавшемуся значению.
Поскольку в данной схеме обратная связь отсутствует, возможно
использование любого из методов обучения статических нейронных сетей,
например, стандартного метода обратного распространения.

После сеанса обучения настроенная нейросеть может использоваться в
контуре управления для предсказания выхода объекта и для настройки
нейрорегулятора.

Такая модель не является автономной.  Она будет функционировать только
вместе с объектом.  Это утверждение было проверено на вычислительном
эксперименте, в котором настроенная по прошлым состояниям модель была
включена с обратными связями, подобно~\figref{fig:nno-feedback}:

\begin{equation}\label{eq:bad-past-states}
  \hat{y}_{k+1}=\mathcal{N}^o(u_k, u_{k-1},\ldots,u_{k-D_u}, \hat{y}_k,
                              \hat{y}_{k-1},\ldots, \hat{y}_{k-D_y})
\end{equation}

В эксперименте на вход линейной модели объекта управления подавалось
управляющее воздействие, представлявшее собой окрашенный случайный
временной ряд.  Параллельно с объектом была включена по схеме
\eqref{eq:bad-past-states} модель, обученная по схеме с повторением
прошлых состояний.  Эксперимент показал, что модель
\eqref{eq:bad-past-states} сразу ``уходит'' с траектории выхода
объекта управления и выход модели нисколько не повторяет ожидаемую
траекторию.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:bad-past-states}
% График с результатами неправильного использования модели rps %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Как видно, нейросетевая модель объекта управления с повторением
прошлых состояний опирается на информацию об истинном, а не
предсказанном на предыдущих шагах состоянии объекта.  Иными словами,
это модель {\it предсказания }выхода объекта управления.

%Постоянная связь с объектом управления, имеющая место в данной
%нейросетевой модели, в некоторых случаях может оказаться полезной.
%В частности, в том случае,

Изложенный подход к построению нейросетевой модели объекта управления
требует решения вспомогательной задачи --- определения, с какой
задержкой и в каком количестве будут подаваться на входы НС--О
значения $u_k, u_{k-1},\ldots,u_{k-D_u}$ и $y_k, \hat{y}_{k-1},\ldots,
\hat{y}_{k-D_y}$.  Очевидно, величина задержки зависит от динамических
свойств объекта управления.  Далее вопрос выбора задержки будет
подробно исследован ({\bf ?  ссылка на раздел?}).

\paragraph{Инвертирование модели повторения прошлых состояний}

В целом, результаты, полученные в разделе \ref{nnplearning}, сохраняют
свою силу.  Однако следует уточнить \eqref{eq:invobj2} в соответствии
с \eqref{eq:past-states}:

\begin{equation}\label{eq:invobj3}
  u^*_k=\mathcal{B}^o(u_k,
                      \mathcal{N}^o(u_k,\ldots,u_{k-D_u},
                                    y_k,\ldots,y_{k-D_y}),
                      r_{k+1})
\end{equation}

Видим, что следствием неавтономности модели предсказания является
использование наблюдаемых состояний объекта управления для его
инвертирования и, значит, для обучения нейрорегулятора.  Иными
словами, обучение нейросетевого регулятора должно осуществляться в
контуре управления в режиме рабочего функционирования.

\paragraph{Гибридная модель}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:nno-hybrid}
% Рисунок гибридной модели %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h]
  \centering
  \input nno_hybrid.pic
  \caption{Пример гибридной модели
  $\hat{y}_{k+1}=\mathcal{N}^o(u_k, \hat{y}_k, \hat{y}_{k-1})$.}
  \label{fig:nno-hybrid}
\end{figure}

Следует отметить, что возможно объединение обеих моделей в рамках
единого гибридного подхода, схема которого представлена
на~\figref{fig:nno-hybrid}.  То есть, в модели реализуется функция:

\begin{equation}\label{eq:nno-hybrid}
  \hat{y}_{k+1}=\mathcal{N}^o(u_k, u_{k-1},\ldots,u_{k-D_u}, \hat{y}_k,
                              \hat{y}_{k-1},\ldots, \hat{y}_{k-D_y})
\end{equation}

Для обучения нейросети необходимо использовать усложненный алгоритм
обратного распространения во времени, учитывающий задержки.

В данной модели ослаблено влияние недостатков модели с внешними
обратными связями (см.~с.~\pageref{simple-feedback-defects}).  В
частности, задержанные на величину чистого запаздывания входы
регулирующего воздействия должны помочь преодолеть первый недостаток,
а обратная связь с повторением нескольких задержанных выходов НС--О
--- второй.

По сравнению с моделью повторения прошлых состояний объекта управления
гибридная модель, во-первых, является автономной, во-вторых, нейросеть
становится более гибкой в части обучения динамике объекта.

Однако, в ряде случаев, когда динамические свойства объекта управления
приблизительно известны и имеется возможность реализовать обучение
нейрорегулятора в темпе реального времени в системе, вполне достаточно
ограничиться простой моделью повторения прошлых состояний.  В
дальнейшем будем использовать именно эту модель объекта управления..


\subsubsection{Влияние выбора начальной точки в пространстве весовых
               коэффициентов}

Известно, что процесс настройки нейронной сети аналогичен градиентному
методу оптимизации.  В том случае, если оптимизируемый функционал
имеет сложную поверхность с локальными минимумами, успех отыскания
глобального с помощью градиентного спуска зависит от выбора начальной
точки.  Если точка выбрана ``неправильно'', то классический
градиентный метод привед\"ет в локальный минимум.  Выбор начальной
точки также сказывается на скорости сходимости.

В случае с обучением нейросетевой модели объекта управления
пространство настраиваемых параметров образуется весовыми
коэффициентами нейронов.  Традиционно их начальное значение задается
случайно с равномерным распределением в окрестности нуля.
Представляется важным выяснить чувствительность процедуры обучения
НС--О к выбору начальной точки.  Поскольку оптимизируемый функционал
включает в себя данные обучающей выборки, а его вид определяется
архитектурой нейронной сети, исследование целесообразно провести для
различных реализаций обучающих данных и различных архитектур сети.

Для выяснения зависимости сходимости алгоритма обучения от выбора
начальной точки был проведен вычислительный эксперимент, в рамках
которого при заданной обучающей выборке и архитектуре нейросети
варьировались начальные значения весовых коэффициентов.

Были зафиксированы:

\begin{itemize}
  \item Объект управления: $G(z)=\frac{0.25z}{z-0.75}$
  \item Помеха: белый шум с параметрами $\{0, 0.1\}$
  \item Регулирующее воздействие: белый шум с параметрами $\{0, 1\}$
  \item Длина обучающей выборки: 250
  \item Длина тестовой выборки: 500
  \item Число и номенклатура входов нейронной сети:
  $\mathcal{N}^o(u_k, y_k, y_{k-1}, y_{k-2})$
\end{itemize}

В ходе эксперимента проводились сеансы обучения НС--О с различными
случайно выбранными в диапазоне $(-\Delta, \Delta)$ начальными
значениями весовых коэффициентов.  Для каждого значения $\Delta$
проводилось 10 сеансов обучения.  Были проведены серии сеансов
обучения со значениями $\Delta$: 0.05, 0.1, 0.2, 0.3, 0.4, 0.5.

В эксперименте участвовали нейронные сети с различной внутренней
архитектурой, а именно, однослойная $\mathcal{N}^o_{1+3,1}$,
двухслойная $\mathcal{N}^o_{1+3,4,1}$, трехслойная
$\mathcal{N}^o_{1+3,7,4,1}$.  Длительность сеанса обучения была
выбрана равной 400 эпохам.

В эксперименте исследовалось поведение траектории среднеквадратичной
ошибки в процессе обучения на тестовой выборке, причем в качестве
объекта измерения были взяты СО в начальный и конечный момент времени.
Для каждой архитектуры нейросети и значения $\Delta$ по результатам 10
сеансов обучения определялось среднее значение СО и разброс (среднее
квадратическое отклонение).  Если СО на тестовой выборке начинала
возрастать, то сеанс обучения прекращался и траектория выбывала из
финального расчета для конечного момента времени.

Результаты эксперимента представлены на \figref{fig:initial-weights} в
виде графиков, причем диаграммы (а) и (б) демонстрируют зависимость
среднего значения СО от диапазона разброса весов в начальный и
конечный моменты времени, а (в) и (г) демонстрируют зависимость
среднеквадратического отклонения СО соответственно.

\begin{figure}
\begin{tabular}{p{0.46\textwidth}p{0.46\textwidth}}
\psfig{figure=T5_mse_mean_t0.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T5_mse_mean_t400.ps,angle=270,width=0.46\textwidth}\\[0pt]
а) среднее значение СО в начале обучения &
б) среднее значение СО в конце обучения\\[16pt]
\psfig{figure=T5_mse_stddev_t0.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T5_mse_stddev_t400.ps,angle=270,width=0.46\textwidth}\\[0pt]
в) разброс СО в начале обучения &
г) разброс СО в конце обучения\\[16pt]
\end{tabular}
\caption{Чувствительность процедуры обучения НС--О к выбору начальной
         точки в пространстве весовых коэффициентов}\label{fig:initial-weights}
\end{figure}

Результаты эксперимента дают основание следующим обобщениям:

\begin{enumerate}
  \item Б\'ольший диапазон разброса значений начальных весов в среднем
        приводит к более хорошим результатам в обучении независимо от
        сложности архитектуры нейросети.  Однако для сложных
        архитектур это приводит к относительно б\'ольшему разбросу
        результатов обучения.
  \item Ограничение диапазона распределения начальных весов может
        привести к проблеме переобучения НС, то есть, уменьшение СО на
        обучающей выборке сопровождается увеличением СО на тестовой.
        Это явление зависит от сложности архитектуры сети.  В
        частности, оно совсем не наблюдалось на однослойной сети, на
        двухслойной сети оно имело место при $\Delta=0.05$ и
        $\Delta=0.1$, на трехслойной сети переобучение наблюдалось при
        всех значениях $\Delta$.
\end{enumerate}

\subsubsection{Требования к обучающей и тестовой выборкам}

По предполагаемой методике обучение нейросетевого имитатора объекта
управления должно осуществляться вне контура управления на выборке,
полученной экспериментальным путем.  Очевидно, встает вопрос о
необходимых требованиях к обучающей и тестовой выборкам для
предсказуемого получения модели ожидаемого качества.

Рассмотрим влияние следующих характеристик экспериментальной выборки
$\{u_k, y_k\}_N$ на процесс настройки нейросетевой модели объекта:

\begin{itemize}
  \item Реализация выборки.
  \item Длина выборки.
  \item Корреляционные свойства выборки регулирующего воздействия $u_k$.
%  \item Корреляционные свойства помехи в наблюдаемых данных $y_k$.
\end{itemize}

Для исследования влияния перечисленных факторов на обучение нейросети
с различной внутренней архитектурой были проведены вычислительные
эксперименты, в ходе которых варьировались исследуемые параметры
обучающей и тестовой выборок, а процесс обучения оценивался по графику
среднеквадратичной ошибки (СО) тестовой выборки.

Эксперименты проводились на НС трех архитектур: однослойной
$\mathcal{N}^o_{1+3,1}$ (один нейрон), двухслойной
$\mathcal{N}^o_{1+3,4,1}$ и трехслойной $\mathcal{N}^o_{1+3,7,3,1}$.
Как видно, на вход НС--О в каждом случае подавались задержанные в
течение трех тактов сигналы с выхода объекта управления $y_k, y_{k-1},
y_{k-2}$ и текущий сигнал управляющего воздействия $u_k$.

В качестве объекта управления было взято инерционное звено с
дискретной передаточной функцией $G(z)=\frac{0.25z}{z-0.75}$.

\paragraph{Влияние реализации выборки на обучение НС--О}

В экспериментах были взяты 10 различных реализаций выборки
управляющего воздействия и помехи.  Выборка управляющего воздействия
представляла собой гауссовский белый шум с параметрами $\{0,1\}$.
Выборка помехи тоже являлась гауссовким белым шумом с параметрами
$\{0,0.1\}$.

Каждая из представленных нейросетей обучалась в течение 400 эпох.  Для
оценки влияния реализации на обучение нейросетевой модели объекта
управления рассматривались траектории СО на тестовой выборке в
процессе обучения.  Длина обучающей и тестовой выборки была взята
равной 500.  Данный объем выборок значительно превышает необходимый
для решения задачи оценивания параметров процесса АРСС и по
соображениям аналогии может считаться достаточным для обучения НС--О.
Равенство длин обучающей и тестовой выборок, а также значительное
превышение их объема над числом настраиваемых параметров нейросети
(весовых коэффициентов) позволяет быть уверенным в отсутствии эффекта
переобучения.

\begin{figure}[h]
\centerline{\hbox{\psfig{figure=T6_mse_1+3_1.eps,%
angle=270,width=0.8\textwidth,height=0.25\textheight}}}
\centerline{а)}
\centerline{\hbox{\psfig{figure=T6_mse_1+3_41.eps,%
angle=270,width=0.8\textwidth,height=0.25\textheight}}}
\centerline{б)}
\centerline{\hbox{\psfig{figure=T6_mse_1+3_731.eps,%
angle=270,width=0.8\textwidth,height=0.25\textheight}}}
\centerline{в)}
\caption{Графики траекторий СО 10 сеансов обучения НС--О с архитектурой
$\mathcal{N}^o_{1+3,1}$ (а), $\mathcal{N}^o_{1+3,4,1}$ (б) и
$\mathcal{N}^o_{1+3,7,3,1}$ (в).}\label{fig:case_influence_nnp}
\end{figure}

Результаты эксперимента представлены на
\figref{fig:case_influence_nnp}.  Графики наглядно демонстрируют
слабую зависимость процесса обучения НС--О от реализации выборок.
Полученные результаты позволяют сделать следующие эмпирические
заключения:

\begin{enumerate}
  \item Форма графика СО (число и положение точек перегиба) не
  зависит от реализации выборки, а зависит от архитектуры НС--О.

  \item С увеличением числа слоев НС--О форма графика СО усложняется
  и влияние реализации выборки на процесс обучения увеличивается.

  \item В худшем случае (трехслойная сеть) отличие минимальной СО от
  максимальной на траектории обучения не превышает 5 раз.  В случае
  монотонного уменьшения СО (при отсутствии эффекта переобучения) эта
  разница может быть устранена более продолжительным обучением.
\end{enumerate}

\paragraph{Влияние длины выборки на обучение НС--О}

%Известно, что решение задачи интерполяции по конечному числу точек
%всегда сопряжено с опасностью настройки параметров модели на эти точки
%в ущерб обобщающей способности модели, то есть, ``правильному''
%поведению модели между точками.  Ухудшение обобщающей способности при
%улучшении результата на исходных точках для искусственных нейронных
%сетей называется проблемой переобучения.  Для контроля над обобщающей
%способностью в процессе настройки модели используются тестовые точки и
%оценка качества настройки проводится именно по ним.

Известная проблема переобучения нейросети вызвана комплеском
взаимосвязанных факторов.  В их числе количество весовых коэффициентов
нейросети, е\"е архитектура, длина обучающей и тестовой выборок.
Исследуем на примере нескольких нейросетевых архитектур влияние длины
обучающей выборки на качество обучения НС--О.  Для этого проведем
вычислительный эксперимент при следующих условиях:

\begin{itemize}
  \item Длина тестовой выборки: 500
  \item Продолжительность обучения: 400 эпох
  \item Реализация управляющего воздействия: белый шум с параметрами
        $\{0,1\}$
  \itemРеализация помехи: белый шум с параметрами $\{0,0.1\}$
\end{itemize}

В процессе эксперимента будем обучать НС--О заданной архитектуры с
помощью ряда $(u_k, y_k)$ заданной длины, при этом обучение
контролируется по завершении каждой эпохи на тестовой выборке
фиксированной длины.  Эта длина выбрана заведомо больше необходимой
для проверки модели типа АРСС если бы оценка параметров процесса
проводилась бы линейными методами анализа временных рядов.

Длина обучающей выборки, напротив, выбиралась от самых малых значений
до длины тестовой выборки.  Эксперимент проводился для следующих длин
выборок: 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 60, 70, 80, 90,
100, 250, 300, 400, 500.  При каждой длине выборки проводилось 5
сессий обучения по различным реализациям обучающей выборки.

Результаты эксперимента для трех нейросетевых архитектур приводятся на
\figref{fig:length_influence_nnp}.  Графики наглядно демонстрируют
следующие зависимости:

\begin{enumerate}

  \item Начиная с некоторого порога, зависящего от сложности
        архитектуры НС--О, процесс обучения становится монотонным, что
        позволяет при обучающей выборке фиксированной длины добиваться
        уменьшения СО путем увеличения продолжительности обучения.

  \item Увеличение длины обучающей выборки ускоряет процесс обучения.

\end{enumerate}


{\bf графики}

%\begin{figure}
%\centerline{\hbox{\psfig{figure=T6_mse_1+3_1_n50.eps,width=0.7\textwidth}}}
%\caption{График}\label{fig:T6}
%\end{figure}


\subsubsection{Статистическая устойчивость процесса обучения}
\subsubsection{Чувствительность к длине обучающей выборки}
\subsubsection{Чувствительность к архитектуре нейронной сети}
\subsubsection{Чувствительность к спектру регулирующего воздействия}

%\begin{figure}[h]
%  \centering

%\input T6_mse_1+3_1_n500.pic

%\input T6_mse_1+3_41_n500.ps

%\input T6_mse_1+3_41_n500.pic

%\input T6_mse_1+3_731_n500.pic
%  \caption{НС--О}
%\end{figure}

%  \label{fig:}
% $\mathcal{N}_{1+3,1}^o(u_k, \hat{y}_k, \hat{y}_{k-1},
%  \hat{y}_{k-2})$

\subsubsection{Конкретизация структуры входов нейросети}

В предыдущем параграфе рассматривалась общая структура входов
нейросетевой модели объекта управления.  Она представлена на
\figref{fig:nno-past-states} и описывается уравнением
\eqref{eq:past-states}.  Очевидно, имеет место задача выбора интервала
прошлых наблюдений управляющего воздействия и объекта управления,
используемых для построения модели.

Рассмотрим методику, обеспечивающую решение данной задачи при
линейности и стационарности объекта управления и аддитивности помехи в
канале наблюдения.  При проведении вычислительных экспериментов в
данном параграфе будем считать, что внутренняя структура нейросети и
используемые выборки достаточны для настройки НС--О.

\paragraph{Входы управляющего воздействия $u_k,\ldots,u_{k-D_u}$}


\paragraph{Входы прошлых наблюдений объекта $y_k,\ldots,y_{k-D_y}$}

\paragraph{Вычислительные эксперименты}


\subsubsection{Структура и число входов НС--О}

Поскольку в рамках данной главы рассматриваются стационарные линейные
объекты управления, предлагается методика расчета числа входов
нейросетевой модели, основанная на предположении о линейности объекта.

%Это не означает, что рассматриваемый метод ограничен сугубо линейным

Линейный объект управления полностью характеризуется имульсной
переходной характеристикой.  Пример отклика приведен на
\figref{step-response}.  Времена $T_{delay}$ и $T_{perehod}$
характеризуют чистое запаздывание и длительность переходного процесса.

Выбор числа входов для НС--О должен делаться на основе свойства
отсутствия памяти состояния в нейросети.  Поэтому нейросеть должна
быть обеспечена всей необходимой информацией для имитации объекта.

В случае наличия в объекте чистого запаздывания информация о
воздействии, породившем отклик объекта, должна иметься у нейронной
сети к моменту появления этого отклика на выходе объекта.  То есть,
достаточное число повторов управляющего воздействия на входе НС--О
должно быть не больше $1+T_{delay}/\Delta T$, где $\Delta T$ --- шаг
квантования времени в системе.

Переходный процесс является характерным проявлением динамических
свойств объекта управления.  Время его завершения является мерой
инерционности объекта и оно должно имитироваться нейросетевой моделью.
Для описания инерционности объекта статической нейросетью требуется не
больше чем $1+T_{perehod}/\Delta T$ повторений прошлых состояний
объекта управления.

Таким образом, получены верхние оценки необходимого числа входов для
нейросетевой модели объекта управления:

\begin{equation}\label{eq:nno-inputs-number}
\begin{array}{rcl}
  D_u & = & T_{delay}/\Delta T \\
  D_y & = & T_{perehod}/\Delta T
\end{array}
\end{equation}

%Поскольку
%этап подгонки модели соответствует процессу обучения НС--О, для выбора
%структуры входов нейросетевой модели достаточно воспользоваться
%методами, основанными на построении выборочной взаимной корреляционной
%функции, описанными в литературе~\cite{ostrem73}\cite{boxjenk74}.



\subsection{Выбор структуры нейрорегулятора}

\subsubsection{Следствия неавтономности нейросетевой модели}

Неавтономность используемой нейросетевой модели объекта управления
является важной особенностью предлагаемого метода, поскольку из не\"е
следуют серьезные ограничения при работе с реальным объектом
управления:

\begin{enumerate}

  \item\label{stability-cond} В процессе настройки нейросетевого
  регулятора должна обеспечиваться устойчивость замкнутого контура САУ
  и объекта управления (если он в разомкнутом состоянии неустойчив).

  \item\label{force-limits} Величины управляющих воздействий не должны
  превышать пределов, накладываемых конструктивными особенностями
  исполняющих органов.

  \item\label{real-time} Время обучения нейросетевого регулятора
  становится реальным, то есть, квант времени алгоритма обучения
  оказывается связан с физическим временем системы управления.

\end{enumerate}

Ограничение \ref{stability-cond} на начальных порах настройки НС--Р в
замкнутом контуре должно обеспечиваться с помощью выбора подходящего
начального приближения.  Наиболее очевидный вариант выбора описан в
разделе \ref{init-approach}.  Поддержание устойчивости в процессе
дообучения НС--Р с помощью инверсной нейросетевой модели должно быть
организовано {\bf специальной процедурой, описанной в ????}

%, отключающей НС--Р от управления объектом в

Для гарантированного выполнения ограничения \ref{force-limits}
предлагается пользоваться масштабированием выходных значений НС--Р в
желаемый диапазон, описанным в разделе \ref{nnarch}.

В том случае, когда существенно ограничение по времени обучения
квазиоптимального нейросетевого регулятора, предлагается осуществлять
настройку НС--Р вне контура управления по физической модели объекта
управления, используемой вместо него самого.


%Синтез нейросетевого регулятора состоит из трех этапов. Первый
%этап включает в себя предварительную настройку НС-Р, на втором
%этапе настраивается модель объекта (НС-О), на третьем этапе НС-Р
%осуществляется окончательная настройка НС-Р.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Результаты имитационного регулирования}

\subsection{Сравнение НОР с линейным оптимальным регулятором}

\subsection{Особенности НОР по сравнению с традиционным
регулятором}

%Рассмотрение важности плос

% Конец Главы 2
