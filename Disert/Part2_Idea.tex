% $Id: Part2_Idea.tex,v 1.2 2001-11-04 15:03:55 vlad Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Общая схема и проблемы синтеза нейрорегулятора}

\subsection{Архитектура нейросети}\label{nnarch}

В качестве базовой архитектуры для синтезируемого регулятора выберем
многослойную искусственную нейронную сеть прямого распространения с
гиперболическим тангенсом в качестве функции активации нейронов.  Эта
сеть является классической и е\"е свойства широко исследовались на
протяжении ряда лет как в теоретическом плане, так и в различных
прикладных задачах.  

%Имеются многочисленные варианты усовершенствовани

Для описания параметров многослойных нейронных сетей будем
использовать обозначение $\mathcal{N}_{n_0,n_1,\ldots,n_{m-1},n_m}$,
где $n_0$ --- число входов первого (входного) слоя сети,
$n_1,\ldots,n_{m-1}$ --- число нейронов в последовательно
расположенных скрытых слоях, $n_m$ --- число нейронов (и выходов)
последнего, выходного слоя.  Всего в нейронной сети имеется $m$
последовательных слоев, полностью соединенных друг с другом
(\figref{fig:mlann}).

\begin{figure}[h]
  \centering
  \input nn_arch.pic
  \caption{Многослойная нейронная сеть.}\label{fig:mlann}
\end{figure}

%\begin{figure}[h]
%  \centering
%  \input mlann.lp
%  \caption{Многослойная нейронная сеть.}\label{fig:mlann}
%\end{figure}

Выход каждого из нейронов вычисляется по формуле
$$y=\fa(\sum_{j=1}^nw_j x_j+w_0)$$

\noindent где $y\in{\mathbb R}$ --- выход нейрона, $x_j\in{\mathbb
R}$ --- $n$ входов нейрона, $w_j\in{\mathbb R}, 1\le j\le n$ ---
весовые коэффициенты на входах, $w_0$ --- свободный член или порог
({\it bias, threshold}), $\fa$ --- дифференцируемая монотонно
возрастающая функция активации с областью определения ${\mathbb R}$.
График функции гиперболического тангенса, часто используемой в
качестве $\fa$, приводится на \figref{fig:tanh}.  Использование
нелинейной функции активации, как известно~\cite{wasser92}, придает
многослойной нейронной сети свойство интерполяции любых, в том числе,
нелинейных, зависимостей.

%$$ \fa(x)=\tanh x=\frac{2}{1+e^{-x}}-1 $$

\begin{figure}[h]
  \centerline{\hbox{\psfig{figure=tanh.ps,%
angle=270,width=0.8\textwidth,height=0.25\textheight}}}
  \caption{Гиперболический тангенс.}
  \label{fig:tanh}
\end{figure}

%\begin{figure}[h]
%  \centering
%  \input tanh.pic
%  \caption{Гиперболический тангенс.}
%  \label{fig:tanh}
%\end{figure}

Следует особо отметить, что выходы нейронной сети однозначно
определяются е\"е входами в заданный момент времени.  Состояние или
память входных значений в предыдущие моменты времени в нейросети
представленной архитектуры отсутствует.  Таким образом, нейросеть не
является динамической системой в понимании теории управления: в ней
отсутствует задержка реакции на входное возмущение и, соответственно,
переходный процесс как следствие инерционности реакции.  Эквивалентом
представленной архитектуры является идеальное (безынерционное) звено с
коэффициентом усиления, зависящим от величины входного возмущающего
воздействия.

Для этой архитектуры разработаны многочисленные методики обучения,
в основном базирующиеся на алгоритме обратного распространения
ошибки.  Свойства алгоритмов обучения и самой нейросети хорошо
изучены.  Данная архитектура нашла применение в самом широком
спектре задач, в том числе, в задачах идентификации и управления.

\subsection{Масштабирование входных и выходных значений}

Функция гиперболического тангенса обладает ограниченной областью
значений, поэтому для представления чисел требуемого диапазона можно
применить один из следующих методов:

\begin{enumerate}
  \item Масштабирование выходных значений нейросети в желаемый
  диапазон.
  \item Использование линейной функции активации нейронов
  выходного слоя.  В этом случае для обеспечения необходимой
  представительной мощности нейросеть должна иметь не менее двух
  скрытых слоев с нелинейными функциями активации.
\end{enumerate}

Первый метод гарантирует ограниченность выходных значений
нейросети внутри заданного диапазона.  Это может оказаться
полезным при решении задач управления с физическими ограничениями
на диапазон управляющих воздействий.

Если постановка задачи обучения нейросети не предусматривает
ограничений, то второй метод расширения диапазона выходных значений
более предпочтителен.  Он обеспечивает возможность в процессе
настройки нейронной сети более гибко выбирать нужный коэффициент
масштабирования.

Гиперболический тангенс принимает значения в диапазоне $-1\ldots 1$.
Масштабирование выходного значения $y$ нейрона из этого диапазона в
желаемый $\tilde{y}_{min}\ldots\tilde{y}_{max}$ будем обозначать
$(-1,1)\to(\tilde{y}_{min},\tilde{y}_{max})$, имея в виду, что

$$
\tilde{y}=y\frac{\tilde{y}_{max}-\tilde{y}_{min}}{2}
          +\frac{\tilde{y}_{max}+\tilde{y}_{min}}{2}
$$

Данное обозначение и формулу будем использовать также для
масштабирования выходных значений нейронов с линейной функцией
активации, если в этом будет необходимость.  Исходный диапазон
$-1\ldots 1$ в этом случае не более чем условность.

Значения, подаваемые на вход нейросети, могут иметь произвольный
диапазон.  Однако для лучшей сходимости алгоритма обучения желательно
иметь входные значения, распределенные около нуля и относительно
небольшие по модулю.  Поэтому для входных значений также будем
применять масштабирование.

Операцию масштабирования из некоторого априорно заданного диапазона
$\tilde{x}_{min}\ldots\tilde{x}_{max}$ в желаемый $-1\ldots 1$
обозначим $(\tilde{x}_{min},\tilde{x}_{max})\to(-1,1)$.
Преобразование в этом случае проводится по формуле

$$
\tilde{x}=x\frac{2}{\tilde{x}_{max}-\tilde{x}_{min}}
          -\frac{\tilde{x}_{max}+\tilde{x}_{min}}
                {\tilde{x}_{max}-\tilde{x}_{min}}
$$


\subsection{Проблема эталона при обучении нейрорегулятора}\label{nnc-problem}

% Проблема обучения --- нужна инверсная модель
Как уже отмечалось, к наиболее распространенным методам обучения
нейронных сетей относится семейство методов обратного распространения
ошибки ({\em backpropagation of error}). Это так называемые методы
обучения с учителем ({\em supervised learning}), то есть, нейросеть
обучается на эталонных парах {\em вход--выход.}  Получение эталонной
пары в рассматриваемой задаче представляет определенную проблему.

По условию задачи исходный регулятор не является оптимальным, а
значит, пара {\em вход--выход}, измеренная на регуляторе, не может
являться эталоном при настройке квазиоптимального нейросетевого
регулятора.  Эталонная (то есть, ведущая к оптимальному закону
управления) обучающая пара известна лишь для всей системы --- это
уставка как вход системы и одновременно как е\"е целевой выход.
Очевидно, что условие $y(t) = r(t)$ является идеалом управления
системой и оно удовлетворяет условию минимума среднеквадратичной
ошибки управления.

Таким образом, для обучения нейросетевого регулятора (НС--Р)
возникает задача получения целевого сигнала управления $u^*(t)$ по
эталонному выходу объекта $y^*(t) \equiv r(t)$. Покажем, что это
достигается построением инверсной функции объекта управления.

Запишем зависимость выхода объекта управления от его входа как
$$y=f(u)$$

Тогда оптимальное управляющее воздействие даст желаемый выход
$$y^*=f(u^*)$$

Желаемый выход объекта (уставка) известен, следовательно для
вычисления оптимального управляющего воздействия $u^*$ достаточно
найти $f^{-1}(.)$ --- инверсную функцию объекта
управления.\footnote{Конечно, данная задача может рассматриваться
только в том случае, когда $f^{-1}(.)$ однозначная.}  Тогда
$$u^* = f^{-1}(y^*) \equiv f^{-1}(r)$$

Поскольку реальный объект управления в любом случае не допускает
решения данной задачи, то необходима его инверсная модель.

В качестве инверсной модели можно использовать нейросетевую модель
объекта управления, работающую в обратном направлении в режиме
распространения ошибки с выхода на вход без обучения (коррекции
весовых коэффициентов). Эта нейронная сеть должна быть
предварительно обучена функционировать подобно объекту управления.
В отличие от нейросетевого регулятора она по завершении его
настройки может быть отключена, так как в рабочем режиме и
стационарных условиях нейросетевой регулятор может функционировать
без инверсной модели.


\subsection{Принцип обучения нейрорегулятора с использованием инверсной
модели}

\label{nnplearning} Рассмотрим алгоритм обучения НС--Р с
использованием уже построенной нейросетевой модели объекта
$\mathcal{N}^o$ (НС--О). Для простоты возьмем одномерный объект
управления.  Пока будем считать, что выход объекта полностью
определяется его входом в настоящий момент времени (в
п.~\ref{nnp_inputs} данное ограничение будет снято).  Положим, что
помехи и прочие возмущающие воздействия в системе отсутствуют.
Нейронная сеть регулятора имеет архитектуру
$\mathcal{N}^p_{1,\ldots,1}$ с $m_p$ слоями. Тогда движение системы в
пространстве состояний из момента времени $t_k$ в следующий момент
$t_{k+1}$ будет описываться следующими уравнениями:
$$ \left\{\begin{array}{rcl}
  e_k & = & y_k-r_k \\
  u_k & = & \mathcal{N}^p(e_k) \\
  y_{k+1} & = & f(u_k)
\end{array}\right. $$

Кроме того, параллельно с объектом управления включена его
нейросетевая модель, реализуемая сетью с архитектурой
$\mathcal{N}^o_{1,\ldots,1}$ ($m_o$ слоев) и осуществляющая
прогноз выхода объекта:
\begin{equation}\label{eq:nnp-principle}
  \hat{y}_{k+1} = \mathcal{N}^o(u_k)
\end{equation}


\subsubsection{Приведение ошибки с выхода НС--О на выход НС--Р}

Для удобства изложения перегруппируем блоки в контуре управления
так, чтобы НС--Р и НС--О располагались последовательно
(\figref{fig:nnplearn}).  Тогда обе нейронных сети можно
рассматривать как одну с $m=m_p+m_o$ слоями и архитектурой
$\mathcal{N}_{1,\ldots,1,\ldots,1} = \mathcal{N}^p_{1,\ldots,1}
\cdot \mathcal{N}^o_{1,\ldots,1}$, Причем с выхода слоя $m_p$
снимается сигнал $u$ и подается на вход объекта. Данная
конструкция на \figref{fig:nnplearn} обведена пунктиром.

\begin{figure}[h]
  \centering
  \input nnplearn.lp
  \caption{Обучение нейросетевого регулятора с помощью инвертирования
  модели объекта.}\label{fig:nnplearn}
\end{figure}

Распространение информации в прямом направлении через слой $d$
нейросети происходит по алгоритму, определяемому следующими
формулами:
$$ \begin{array}{rcl}
  z^d_i & = & \sum\limits_j w^d_{ij}q^{d-1}_j \\
  q^d_i & = & s(z^d_i),
\end{array} $$ где $q^{d-1}_j$ и $q^d_i$ --- вход и выход слоя
соответственно; $w^d_{ij}$ обозначает весовой коэффициент $j$-го
входа $i$-го нейрона; $s(.)$ --- функция активации нейрона. Для
комбинированной сети вход $q^0_1=e_k$, промежуточный выход
$u_k=q^{m_p}_1$ и выход $\hat{y}_{k+1}=q^{m}_1$.

Прогнозируемая ошибка управления равна
$\hat{e}_{k+1}=\hat{y}_{k+1}-r_{k+1}$.  Е\"е можно рассматривать как
ошибку воспроизведения комбинированной нейросети $\mathcal{N}$.
Для уменьшения этой ошибки может быть сделан шаг алгоритма
обучения.  По условию считаем, что НС--О повторяет выход объекта
$\hat{y}_{k+1}=y_{k+1}$, следовательно прогнозируемая и реальная
ошибки управления совпадают: $e_{k+1}=\hat{e}_{k+1}$.  То есть,
настройка управляющей части $\mathcal{N}^p$ комбинированной
нейросети с целью уменьшить ошибку прогноза приведет к уменьшению
ошибки управления реальным объектом.  Итак, эталонной обучающей
парой комбинированной нейросети является $e_k$ (вход НС--Р) и
$r_{k+1}$ (желаемый выход НС--О).

Определим суммарную среднеквадратичную ошибку воспроизведения по
заданной исходной выборке $r$ как
$$ \hatSE\DEF\frac{1}{2}\sum_k\hat{e}_k^2 =
\frac{1}{2}\sum_k(\hat{y}_k-r_k)^2 $$

Задача обучения нейросети $\mathcal{N}$ ставится как минимизация
$\hatSE$ путем подбора весовых коэффициентов $w^d_{ij}$. Поскольку
по условию $\mathcal{N}^o$ уже обучена, следовательно ошибка
управления может быть устранена только соответствующей настройкой
$\mathcal{N}^p$.  Поэтому весовые коэффициенты должны
корректироваться только в части $\mathcal{N}^p$, а именно, в слоях
$1\le d\le m_p$.

В соответствии с алгоритмом обратного распространения на $k$-ом
шаге весовой коэффициент нейрона комбинированной нейросети может
корректироваться по правилу:
\begin{equation}\label{eq:weightchange}
  w^d_{ij}(k+1)=w^d_{ij}(k)-\eta\delta^d_i q^{d-1}_j
\end{equation}

Величина $\delta^d_i$ называется обобщенной ошибкой $i$-го
нейрона; $\eta$ --- коэффициент скорости обучения.

Обобщенная ошибка распространяется от выхода к входу обратно
прямому распространению информации в нейросети и может вычисляться
без коррекции весовых коэффициентов. Е\"е расчет различается для
выходного и скрытых слоев:
\begin{equation}\label{eq:deltaprop}
  \delta^d_i=\left\{\begin{array}{ll}
    \fa'(z^d_i)\sum\limits_h\delta^{d+1}_h w^{d+1}_{hi} & 1\le d<m \\
    \fa'(z^d_i)(\hat{y}_{k+1}-r_{k+1}) & d=m \\
  \end{array}\right.
\end{equation}

Выход слоя $m_p$ используется как управляющее воздействие
$u_k=q^{m_p}_1$. В том случае, если этот слой рассматривать как
выходной у НС--Р, то вычисление обобщенной ошибки для него
формально определялось бы уравнением
\begin{equation}\label{eq:deltapropp-out}
  \delta^{m_p}_i=\fa'(z^{m_p}_i)(u_k-u^*_k),
\end{equation} где $u^*_k$ --- некоторое целевое значение управляющего
воздействия.  Но в рамках комбинированной нейросети обобщенная
ошибка равна
\begin{equation}\label{eq:deltapropp-hid}
  \delta^{m_p}_i=\fa'(z^{m_p}_i)\sum_h\delta^{m_p+1}_h
  w^{m_p+1}_{hi}
\end{equation}

Здесь слой $m_p+1$ является входным у НС--О.  Сопоставляя
\eqref{eq:deltapropp-out} и \eqref{eq:deltapropp-hid} выводим, что
для уменьшения ошибки воспроизведения данной эталонной пары {\em
вход--выход} комбинированной нейросетью выход слоя $m_p$ (то есть,
управляющее воздействие $u_k$) следовало бы сделать равным
\begin{equation}\label{eq:desired-u}
  u^*_k=u_k-\sum_h\delta^{m_p+1}_h w^{m_p+1}_{hi}
\end{equation}

Данное выражение вместе с уравнениями~\eqref{eq:deltaprop}
определяет способ вычисления ошибки на выходе нейросетевого
регулятора по ошибке на выходе нейросетевой модели объекта
управления.

\subsubsection{Инверсная модель объекта управления}

Можно обобщить уравнения \eqref{eq:deltaprop} и
\eqref{eq:desired-u} в единой функциональной зависимости,
реализующей метод обратного распространения ошибки в нейросетевой
модели объекта управления без коррекции весовых коэффициентов:
\begin{equation}\label{eq:invobj}
  u^*_k=\mathcal{B}^o(u_k, \hat{y}_{k+1}, r_{k+1})
\end{equation}

В том случае, если НС--О функционирует абсолютно подобно объекту
управления, то есть, $f\equiv \mathcal{N}^o$, следует ожидать, что
$f^{-1}\equiv {\mathcal{N}^o}^{-1}=\mathcal{B}^o$.

Другими словами, метод обратного распространения ошибки может
использоваться как вычислительная процедура для инвертирования
функции, то есть:
\begin{equation}
  \mathcal{B}^o: r_{k+1} \rightarrow u^*_k
\end{equation}

В случае непрерывного времени идеальная континуальная нейросетевая
модель объекта будет инвертировать желаемый выход объекта в
требуемое управляющее воздействие без задержки, то есть:
$$ \mathcal{B}^o: r(t) \rightarrow u^*(t) $$

Исследуем свойства полученной инверсии.  Поскольку прямая
$\mathcal{N}^o$ и обратная $\mathcal{B}^o$ функции реализуются с
помощью одного и того же набора параметров $w^d_{ij}$, качество
прогноза выхода объекта напрямую связано с качеством инверсии.

В качестве параметров функции $\mathcal{B}^o$ выступают также
$u_k$ и $\hat{y}_{k+1}$.  Их наличие вызвано тем, что обратное
распространение опирается на информацию, полученную во время
прямого распространения, то есть, более корректно следует записать
\begin{equation}\label{eq:invobj2}
  u^*_k=\mathcal{B}^o(u_k, \mathcal{N}^o(u_k), r_{k+1})
\end{equation}

Данное представление функции $\mathcal{B}^o$ можно интерпретировать
как инверсию уставки $r_{k+1}$ в некоторой окрестности управляющего
воздействия $u_k$.  То есть, инвертирование объекта управления с
помощью НС--О осуществляется не во всей области определения, а в
некоторой локальной окрестности опорного управляющего воздействия,
задающего оценку состояния объекта управления.  Локальность
осуществляемого обратного преобразования позволяет использовать ИНС
для отображения многозначных функций, однозначных на некоторых
интервалах.

Отметим связь нейросетевой инверсии и якобиана объекта управления.
Как известно, якобиан --- матрица скалярных частных производных
переменных состояния по входам --- является мерой реакции объекта на
изменение управляющих воздействий в заданной точке пространства
состояний.  Для простого объекта с одним управляющим входом и одной
переменной состояния, наблюдаемого на выходе, якобиан упрощается до
обычной производной:
\begin{equation}\label{eq:jacobian}
  J(t)=\Biggl(\frac{\partial y_i}
		   {\partial u_j}\Biggr)_{i,j}=\frac{d y(t)}{d u}
\end{equation}

Линейную оценку якобиана~\eqref{eq:jacobian} в окрестности номинальной
траектории можно рассчитать по формуле
$$
  J_k=\frac{\Delta y_{k+1}}{\Delta u_{k}}
$$ откуда следует, что для получения желаемого состояния объекта
$y_{k+1}=r_{k+1}$ следует приложить управление $u^*_k$:
$$
  r_{k+1}=y_k+J_k(u^*_k-u_{k-1})
$$ следовательно
\begin{equation}\label{eq:jacobinv}
  u^*_k=u_{k-1}+(r_{k+1}-y_k)/J_k
\end{equation}

Очевидна аналогия между формулами \eqref{eq:jacobinv} и
\eqref{eq:invobj2}.  Таким образом, нейросетевая функция
$\mathcal{B}^o$ включает в себя оценку якобиана объекта управления.

%
%{\bf На рисунке приводится пример инверсии функции sin().}

\subsubsection{Обучение нейрорегулятора по инверсной модели}

Будем считать, что НС--О объекта управления абсолютно точно
имитирует его поведение.  Считаем также, что помехи в системе
управления отсутствуют.  Тогда прогноз и наблюдаемый выход объекта
совпадут $y_{k+1}=\hat{y}_{k+1}$.  В этом случае справедлива
формула~\eqref{eq:invobj} инверсии уставки в целевое управляющее
воздействие.

Вычисление функции $\mathcal{B}^o$ осуществляется обратным
распространением фактической ошибки управления
$e_{k+1}=y_{k+1}-r_{k+1}$ вместо прогнозируемой
$\hat{e}_{k+1}=\hat{y}_{k+1}-r_{k+1}$ \eqref{eq:deltaprop} через
НС--О без коррекции весовых коэффициентов нейросети.  Далее
полученное целевое значение $u^*_k$ применяется для настройки
весовых коэффициентов НС--Р с помощью обычной процедуры обратного
распространения, описанной уравнениями \eqref{eq:weightchange},
\eqref{eq:deltaprop}.

Видим, что использование НС--О позволяет решить задачу настройки
нейросетевого регулятора путем инверсии объекта управления методом
обратного распространения ошибки.  Это снимает проблему,
сформулированную в п.~\ref{nnc-problem}.

Вопрос сходимости алгоритма обучения с обратным распространением
ошибки к оптимальному решению теоретически решается выбором
бесконечно малого шага $\eta$ при отсутствии локальных минимумов в
процессе обучения.  На практике проблема локальных минимумов не
решена ни для одного из градиентных методов оптимизации, поэтому
обычно удовлетворяются первым же достаточно подходящим минимумом,
а неподходящих минимумов избегают с помощью различных
эвристических подходов \cite{wasser92}~\cite{gibb96}. Мера того,
является ли решение (набор весовых коэффициентов сети) подходящим,
определяется значением ошибки регулирования, получаемым на
контрольной выборке.

Коэффициент скорости обучения в классическом алгоритме обратного
распространения обычно подбирается эвристически, хотя и может быть
строго рассчитан~\cite[с.82--97]{terehov99}.  Для улучшения
сходимости широко применяются градиентные методы второго порядка,
развитые на основе алгоритма обратного
распространения~\cite{gibb96}.

\subsection{Выбор начального приближения НС--Р}\label{init-approach}

Обучение нейросети методом обратного распространения подобно
градиентному методу оптимизации.  Как и в градиентных методах, при
обучении нейросетевого регулятора важен выбор начального
приближения.  Чем ближе он к минимуму функции ошибки, тем меньшее
количество шагов потребуется сделать и тем меньше вероятность
попадания в локальные минимумы.

В качестве начального приближения для НС--Р можно использовать
функцию, реализуемую имеющимся регулятором. Для этого по
достаточно длинной экспериментальной выборке, полученной на
функционирующей САУ с традиционным регулятором, нейросетевой
регулятор может быть обучен функционированию первого в режиме
следования эталону. Очевидно, в этом случае нейросетевой регулятор
не даст улучшения качества управления, однако полученная нейросеть
станет первым приближением в процедуре дальнейшего обучения.

Обучение начальному приближению может быть осуществлено вне
контура управления по временным рядам, полученным в процессе
штатного функционирования исходной системы управления.  Поскольку
вне контура управления можно не следовать достаточно жесткому
ограничению (см. требование~\ref{realcond} на
с.~\pageref{realcond}), в качестве начального состояния весовых
коэффициентов нейросети можно использовать любое из известных
эвристических правил~\cite{gibb96}.

После успешного обучения начальному приближению нейросетевой
регулятор может использоваться в контуре управления вместо
исходного.
