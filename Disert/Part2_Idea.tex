% $Id: Part2_Idea.tex,v 1.6 2002-11-19 10:35:34 vlad Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Общая схема и проблемы синтеза нейрорегулятора}

\subsection{Архитектура нейросети}\label{nnarch}

В качестве базовой архитектуры для синтезируемого регулятора выберем
многослойную искусственную нейронную сеть прямого распространения с
гиперболическим тангенсом в качестве функции активации нейронов.  Эта
сеть является классической и е\"е свойства широко исследовались на
протяжении ряда лет как в теоретическом плане, так и в различных
прикладных задачах.  

Для описания параметров многослойных нейронных сетей будем
пользоваться обозначением $\NN_{n_0,n_1,\ldots,n_{m-1},n_m}$,
где $n_0$ --- число входов первого (входного) слоя сети,
$n_1,\ldots,n_{m-1}$ --- число нейронов в последовательно
расположенных скрытых слоях, $n_m$ --- число нейронов (и выходов)
последнего, выходного слоя.  Всего в нейронной сети имеется $m$
последовательных слоев, полностью соединенных друг с другом
(\figref{fig:mlann}).

%\begin{figure}[h]
%  \centering
%  \input mlann.lp
%  \caption{Многослойная нейронная сеть.}\label{fig:mlann}
%\end{figure}

Выход каждого из нейронов вычисляется по формуле
\begin{equation}\label{eq:neuron_output}
y=\fa(\sum_{j=1}^nw_j x_j+w_0)
\end{equation}

\noindent где $y\in{\mathbb R}$ --- выход нейрона, $x_j\in{\mathbb
R}$ --- $n$ входов нейрона, $w_j\in{\mathbb R}, 1\le j\le n$ ---
весовые коэффициенты на входах, $w_0$ --- свободный член или порог
({\it bias, threshold}), $\fa$ --- дифференцируемая монотонно
возрастающая функция активации с областью определения ${\mathbb R}$.
График функции гиперболического тангенса, часто используемой в
качестве $\fa$, приводится на \figref{fig:act_func}а.  Использование
нелинейной функции активации, как известно~\cite{wasser92}, придает
многослойной нейронной сети свойство интерполяции любых, в том числе,
нелинейных, зависимостей.

%$$ \fa(x)=\tanh x=\frac{2}{1+e^{-x}}-1 $$

%\begin{figure}[h]
%  \centering
%  \input tanh.pic
%  \caption{Гиперболический тангенс.}
%  \label{fig:tanh}
%\end{figure}

Следует особо отметить, что выходы нейронной сети однозначно
определяются е\"е входами в заданный момент времени.  Состояние или
память входных значений в предыдущие моменты времени в нейросети
представленной архитектуры отсутствует.  Таким образом, нейросеть не
является динамической системой в понимании теории управления: в ней
отсутствует задержка реакции на входное возмущение и, соответственно,
переходный процесс как следствие инерционности реакции.  Эквивалентом
представленной архитектуры является идеальное (безынерционное) звено с
коэффициентом усиления, зависящим от величины входного возмущающего
воздействия.

Для этой архитектуры разработаны многочисленные методики обучения,
в основном базирующиеся на алгоритме обратного распространения
ошибки.  Свойства алгоритмов обучения и самой нейросети хорошо
изучены.  Данная архитектура нашла применение в самом широком
спектре задач, в том числе, в задачах идентификации и управления.

\subsection{Масштабирование входных и выходных значений}

Функция гиперболического тангенса обладает ограниченной областью
значений, поэтому для представления чисел требуемого диапазона можно
применить один из следующих методов:

\begin{enumerate}
  \item Масштабирование выходных значений нейросети в желаемый
  диапазон.
  \item Использование линейной функции активации нейронов
  выходного слоя.  В этом случае для обеспечения необходимой
  представительной мощности нейросеть должна иметь не менее двух
  скрытых слоев с нелинейными функциями активации.
\end{enumerate}

Первый метод гарантирует ограниченность выходных значений
нейросети внутри заданного диапазона.  Это может оказаться
полезным при решении задач управления с физическими ограничениями
на диапазон управляющих воздействий.

Если постановка задачи обучения нейросети не предусматривает
ограничений, то второй метод расширения диапазона выходных значений
более предпочтителен.  Он обеспечивает возможность в процессе
настройки нейронной сети более гибко выбирать нужный коэффициент
масштабирования.

Гиперболический тангенс принимает значения в диапазоне $-1\ldots 1$.
Масштабирование выходного значения $y$ нейрона из этого диапазона в
желаемый $\tilde{y}_{min}\ldots\tilde{y}_{max}$ будем обозначать
$(-1,1)\to(\tilde{y}_{min},\tilde{y}_{max})$, имея в виду, что

$$
\tilde{y}=y\frac{\tilde{y}_{max}-\tilde{y}_{min}}{2}
          +\frac{\tilde{y}_{max}+\tilde{y}_{min}}{2}
$$

Данное обозначение и формулу будем использовать также для
масштабирования выходных значений нейронов с линейной функцией
активации, если в этом будет необходимость.  Исходный диапазон
$-1\ldots 1$ в этом случае не более чем условность.

Значения, подаваемые на вход нейросети, могут иметь произвольный
диапазон.  Однако для лучшей сходимости алгоритма обучения желательно
иметь входные значения, распределенные около нуля и относительно
небольшие по модулю.  Поэтому для входных значений также будем
применять масштабирование.

Операцию масштабирования из некоторого априорно заданного диапазона
$\tilde{x}_{min}\ldots\tilde{x}_{max}$ в желаемый $-1\ldots 1$
обозначим $(\tilde{x}_{min},\tilde{x}_{max})\to(-1,1)$.
Преобразование в этом случае проводится по формуле

$$
\tilde{x}=x\frac{2}{\tilde{x}_{max}-\tilde{x}_{min}}
          -\frac{\tilde{x}_{max}+\tilde{x}_{min}}
                {\tilde{x}_{max}-\tilde{x}_{min}}
$$


\subsection{Проблема эталона при обучении нейрорегулятора}\label{nnc-problem}

% Проблема обучения --- нужна инверсная модель
Как уже отмечалось, к наиболее распространенным методам обучения
нейронных сетей относится семейство методов обратного распространения
ошибки ({\em backpropagation of error}). Это так называемые методы
обучения с учителем ({\em supervised learning}), то есть, нейросеть
обучается на эталонных парах {\em вход--выход.}  Получение эталонной
пары в рассматриваемой задаче представляет определенную проблему.

По условию задачи исходный регулятор не является оптимальным, а
значит, пара {\em вход--выход}, измеренная на регуляторе, не может
являться эталоном при настройке квазиоптимального нейросетевого
регулятора.  Эталонная (то есть, ведущая к оптимальному закону
управления) обучающая пара известна лишь для всей системы --- это
уставка как вход системы и одновременно как е\"е целевой выход.
Очевидно, что условие $y(t) = r(t)$ является идеалом управления
системой и оно удовлетворяет условию минимума среднеквадратичной
ошибки управления.

Таким образом, для обучения нейросетевого регулятора (НС--Р)
возникает задача получения целевого сигнала управления $u^*(t)$ по
эталонному выходу объекта $y^*(t) \equiv r(t)$. Покажем, что это
достигается построением инверсной функции объекта управления.

Запишем зависимость выхода объекта управления от его входа как
$$y=f(u)$$

Тогда оптимальное управляющее воздействие даст желаемый выход
$$y^*=f(u^*)$$

Желаемый выход объекта (уставка) известен, следовательно для
вычисления оптимального управляющего воздействия $u^*$ достаточно
найти $f^{-1}(.)$ --- инверсную функцию объекта
управления.\footnote{Конечно, данная задача может рассматриваться
только в том случае, когда $f^{-1}(.)$ однозначная.}  Тогда
$$u^* = f^{-1}(y^*) \equiv f^{-1}(r)$$

Поскольку реальный объект управления в любом случае не допускает
решения данной задачи, то необходима его инверсная модель.

В качестве инверсной модели можно использовать нейросетевую модель
объекта управления, работающую в обратном направлении в режиме
распространения ошибки с выхода на вход без обучения (коррекции
весовых коэффициентов). Эта нейронная сеть должна быть
предварительно обучена функционировать подобно объекту управления.
В отличие от нейросетевого регулятора она по завершении его
настройки может быть отключена, так как в рабочем режиме и
стационарных условиях нейросетевой регулятор может функционировать
без инверсной модели.


\subsection{Принцип обучения нейрорегулятора с использованием инверсной
модели}

\label{nnc_optimal_training} Рассмотрим алгоритм обучения НС--Р с
использованием уже построенной нейросетевой модели объекта
$\NN^o$ (НС--О). Для простоты возьмем одномерный объект
управления.  Пока будем считать, что выход объекта полностью
определяется его входом в настоящий момент времени (в
п.~\ref{nnp_inputs} данное ограничение будет снято).  Положим, что
помехи и прочие возмущающие воздействия в системе отсутствуют.
Нейронная сеть регулятора имеет архитектуру
$\NN^p_{1,\ldots,1}$ с $m_p$ слоями. Тогда движение системы в
пространстве состояний из момента времени $t_k$ в следующий момент
$t_{k+1}$ будет описываться следующими уравнениями:
$$ \left\{\begin{array}{rcl}
  e_k & = & y_k-r_k \\
  u_k & = & \NN^p(e_k) \\
  y_{k+1} & = & f(u_k)
\end{array}\right. $$

Кроме того, параллельно с объектом управления включена его
нейросетевая модель, реализуемая сетью с архитектурой
$\NN^o_{1,\ldots,1}$ ($m_o$ слоев) и осуществляющая
прогноз выхода объекта:
\begin{equation}\label{eq:nnp-principle}
  \hat{y}_{k+1} = \NN^o(u_k)
\end{equation}


\subsubsection{Приведение ошибки с выхода НС--О на выход НС--Р}

Для удобства изложения перегруппируем блоки в контуре управления
так, чтобы НС--Р и НС--О располагались последовательно
(\figref{fig:nnplearn}).  Тогда обе нейронных сети можно
рассматривать как одну с $m=m_p+m_o$ слоями и архитектурой
$\NN_{1,\ldots,1,\ldots,1} = \NN^p_{1,\ldots,1}
\cdot \NN^o_{1,\ldots,1}$, Причем с выхода слоя $m_p$
снимается сигнал $u$ и подается на вход объекта. Данная
конструкция на \figref{fig:nnplearn} обведена пунктиром.

\begin{figure}[h]
  \centering
  \input nnplearn.lp
  \caption{Обучение нейросетевого регулятора с помощью инвертирования
  модели объекта.}\label{fig:nnplearn}
\end{figure}

Распространение информации в прямом направлении через слой $d$
нейросети происходит по алгоритму, определяемому
формулами~\eqref{eq:sigm_neuron_output_parts}.  Для комбинированной
сети вход $q^0_1=e_k$, промежуточный выход $u_k=q^{m_p}_1$ и выход
$\hat{y}_{k+1}=q^{m}_1$.

Прогнозируемая ошибка управления равна
$\hat{e}_{k+1}=\hat{y}_{k+1}-r_{k+1}$.  Е\"е можно рассматривать как
ошибку воспроизведения комбинированной нейросети $\NN$.
Для уменьшения этой ошибки может быть сделан шаг алгоритма
обучения.  По условию считаем, что НС--О повторяет выход объекта
$\hat{y}_{k+1}=y_{k+1}$, следовательно прогнозируемая и реальная
ошибки управления совпадают: $e_{k+1}=\hat{e}_{k+1}$.  То есть,
настройка управляющей части $\NN^p$ комбинированной
нейросети с целью уменьшить ошибку прогноза приведет к уменьшению
ошибки управления реальным объектом.  Итак, эталонной обучающей
парой комбинированной нейросети является $e_k$ (вход НС--Р) и
$r_{k+1}$ (желаемый выход НС--О).

Определим суммарную среднеквадратичную ошибку воспроизведения по
заданной исходной выборке $r$ как
$$ \hatMSE\DEF\frac{1}{2}\sum_k\hat{e}_k^2 =
\frac{1}{2}\sum_k(\hat{y}_k-r_k)^2 $$

Задача обучения нейросети $\NN$ ставится как минимизация
$\hatMSE$ путем подбора весовых коэффициентов $w^d_{ij}$. Поскольку
по условию $\NN^o$ уже обучена, следовательно ошибка
управления может быть устранена только соответствующей настройкой
$\NN^p$.  Поэтому весовые коэффициенты должны
корректироваться только в части $\NN^p$, а именно, в слоях
$1\le d\le m_p$.

В соответствии с алгоритмом обратного распространения обобщенная
ошибка распространяется от выхода к входу обратно прямому
распространению информации в нейросети и может вычисляться без
коррекции весовых коэффициентов.  Е\"е расчет ведется по
формуле~\eqref{eq:deltaprop_dup} и различается для выходного и скрытых
слоев:

\begin{equation}\label{eq:deltaprop_dup}
  \delta^d_i=\left\{\begin{array}{ll}
    \fa'(z^d_i)\sum\limits_h\delta^{d+1}_h w^{d+1}_{hi} & 1\le d<m \\
    \fa'(z^d_i)(\hat{y}_{k+1}-r_{k+1}) & d=m \\
  \end{array}\right.
\end{equation}

Выход слоя $m_p$ используется как управляющее воздействие
$u_k=q^{m_p}_1$. В том случае, если этот слой рассматривать как
выходной у НС--Р, то вычисление обобщенной ошибки для него
формально определялось бы уравнением
\begin{equation}\label{eq:deltapropp-out}
  \delta^{m_p}_i=\fa'(z^{m_p}_i)(u_k-u^*_k),
\end{equation} где $u^*_k$ --- некоторое целевое значение управляющего
воздействия.  Но в рамках комбинированной нейросети обобщенная
ошибка равна
\begin{equation}\label{eq:deltapropp-hid}
  \delta^{m_p}_i=\fa'(z^{m_p}_i)\sum_h\delta^{m_p+1}_h
  w^{m_p+1}_{hi}
\end{equation}

Здесь слой $m_p+1$ является входным у НС--О.  Сопоставляя
\eqref{eq:deltapropp-out} и \eqref{eq:deltapropp-hid} выводим, что
для уменьшения ошибки воспроизведения данной эталонной пары {\em
вход--выход} комбинированной нейросетью выход слоя $m_p$ (то есть,
управляющее воздействие $u_k$) следовало бы сделать равным
\begin{equation}\label{eq:desired-u}
  u^*_k=u_k-\sum_h\delta^{m_p+1}_h w^{m_p+1}_{hi}
\end{equation}

Данное выражение вместе с уравнениями~\eqref{eq:deltaprop}
определяет способ вычисления ошибки на выходе нейросетевого
регулятора по ошибке на выходе нейросетевой модели объекта
управления.

\subsubsection{Инверсная модель объекта управления}

Можно обобщить уравнения \eqref{eq:deltaprop} и
\eqref{eq:desired-u} в единой функциональной зависимости,
реализующей метод обратного распространения ошибки в нейросетевой
модели объекта управления без коррекции весовых коэффициентов:
\begin{equation}\label{eq:invobj}
  u^*_k=\mathcal{B}^o(u_k, \hat{y}_{k+1}, r_{k+1})
\end{equation}

В том случае, если НС--О функционирует абсолютно подобно объекту
управления, то есть, $f\equiv \NN^o$, следует ожидать, что
$f^{-1}\equiv {\NN^o}^{-1}=\mathcal{B}^o$.

Другими словами, метод обратного распространения ошибки может
использоваться как вычислительная процедура для инвертирования
функции, то есть:
\begin{equation}
  \mathcal{B}^o: r_{k+1} \rightarrow u^*_k
\end{equation}

В случае непрерывного времени идеальная континуальная нейросетевая
модель объекта будет инвертировать желаемый выход объекта в
требуемое управляющее воздействие без задержки, то есть:
$$ \mathcal{B}^o: r(t) \rightarrow u^*(t) $$

Исследуем свойства полученной инверсии.  Поскольку прямая $\NN^o$ и
обратная $\mathcal{B}^o$ функции реализуются с помощью одного и того
же набора параметров $w^d_{ij}$, качество прогноза выхода объекта
напрямую связано с качеством инверсии.

В качестве параметров функции $\mathcal{B}^o$ выступают также $u_k$ и
$\hat{y}_{k+1}$.  Их наличие вызвано тем, что обратное распространение
опирается на информацию, полученную во время прямого распространения,
то есть, более корректно следует записать
\begin{equation}\label{eq:invobj2}
  u^*_k=\mathcal{B}^o(u_k, \NN^o(u_k), r_{k+1})
\end{equation}

Данное представление функции $\mathcal{B}^o$ можно интерпретировать
как инверсию уставки $r_{k+1}$ в некоторой окрестности управляющего
воздействия $u_k$.  То есть, инвертирование объекта управления с
помощью НС--О осуществляется не во всей области определения, а в
некоторой локальной окрестности опорного управляющего воздействия,
задающего оценку состояния объекта управления.  Локальность
осуществляемого обратного преобразования позволяет использовать ИНС
для отображения многозначных функций, однозначных на некоторых
интервалах.

Отметим связь нейросетевой инверсии и якобиана объекта управления.
Как известно, якобиан --- матрица скалярных частных производных
переменных состояния по входам --- является мерой реакции объекта на
изменение управляющих воздействий в заданной точке пространства
состояний.  Для простого объекта с одним управляющим входом и одной
переменной состояния, наблюдаемого на выходе, якобиан упрощается до
обычной производной:
\begin{equation}\label{eq:jacobian}
  J(t)=\Biggl(\frac{\partial y_i}
		   {\partial u_j}\Biggr)_{i,j}=\frac{d y(t)}{d u}
\end{equation}

Линейную оценку якобиана~\eqref{eq:jacobian} в окрестности номинальной
траектории можно рассчитать по формуле
$$
  J_k=\frac{\Delta y_{k+1}}{\Delta u_{k}}
$$ откуда следует, что для получения желаемого состояния объекта
$y_{k+1}=r_{k+1}$ следует приложить управление $u^*_k$:
$$
  r_{k+1}=y_k+J_k(u^*_k-u_{k-1})
$$ следовательно
\begin{equation}\label{eq:jacobinv}
  u^*_k=u_{k-1}+(r_{k+1}-y_k)/J_k
\end{equation}

Очевидна аналогия между формулами \eqref{eq:jacobinv} и
\eqref{eq:invobj2}.  Таким образом, нейросетевая функция
$\mathcal{B}^o$ включает в себя оценку якобиана объекта управления.

%
%{\bf На рисунке приводится пример инверсии функции sin().}

\subsubsection{Обучение нейрорегулятора по инверсной модели}

Будем считать, что НС--О объекта управления абсолютно точно
имитирует его поведение.  Считаем также, что помехи в системе
управления отсутствуют.  Тогда прогноз и наблюдаемый выход объекта
совпадут $y_{k+1}=\hat{y}_{k+1}$.  В этом случае справедлива
формула~\eqref{eq:invobj} инверсии уставки в целевое управляющее
воздействие.

Вычисление функции $\mathcal{B}^o$ осуществляется обратным
распространением фактической ошибки управления
$e_{k+1}=y_{k+1}-r_{k+1}$ вместо прогнозируемой
$\hat{e}_{k+1}=\hat{y}_{k+1}-r_{k+1}$ \eqref{eq:deltaprop} через
НС--О без коррекции весовых коэффициентов нейросети.  Далее
полученное целевое значение $u^*_k$ применяется для настройки
весовых коэффициентов НС--Р с помощью обычной процедуры обратного
распространения, описанной уравнениями \eqref{eq:weightchange},
\eqref{eq:deltaprop}.

Видим, что использование НС--О позволяет решить задачу настройки
нейросетевого регулятора путем инверсии объекта управления методом
обратного распространения ошибки.  Это решает проблему,
сформулированную в п.~\ref{nnc-problem}.

Вопрос сходимости алгоритма обучения с обратным распространением
ошибки к оптимальному решению теоретически решается выбором
бесконечно малого шага $\eta$ при отсутствии локальных минимумов в
процессе обучения.  На практике проблема локальных минимумов не
решена ни для одного из градиентных методов оптимизации, поэтому
обычно удовлетворяются первым же достаточно подходящим минимумом,
а неподходящих минимумов избегают с помощью различных
эвристических подходов \cite{wasser92}~\cite{gibb96}. Мера того,
является ли решение (набор весовых коэффициентов сети) подходящим,
определяется значением ошибки регулирования, получаемым на
контрольной выборке.

Для улучшения сходимости широко применяются градиентные методы второго
порядка, развитые на основе алгоритма обратного
распространения~\cite{gibb96}.

\subsubsection{Коэффициент скорости обучения}%
\label{batch_eta}

Коэффициент скорости обучения в классическом алгоритме обратного
распространения обычно подбирается эвристически, хотя и может быть
строго рассчитан~\cite[с.82--97]{terehov99}.  Следует отметить, что
часто применяемое пакетное обновление весовых коэффициентов ({\it
batch training}) требует иного значения коэффициента скорости
обучения, чем при обучении в тех же условиях, но классическим
алгоритмом обратного распространения (см. \pgref{eq:weightchange}).
При пакетном обновлении велич\'ины коррекции весовых коэффициентов

\begin{equation}\label{eq:weight-delta}
\Delta w^d_{ij}(k) = \eta\delta^d_i(k) q^{d-1}_j(k)
\end{equation}

\noindent рассчитываются на каждом шаге, но сами весовые коэффициенты
обновляются реже.  Шаг обновления называется эпохой ({\it epoch}).
Таким образом, при длительности эпохи $L$
уравнение~\eqref{eq:weightchange} будет выглядеть так:

\begin{equation}\label{eq:batch-weightchange}
w^d_{ij}(k+L)=w^d_{ij}(k)-\sum\limits_{p=1}^L \Delta w^d_{ij}(k+p-1)
\end{equation}

При постоянном в течение эпохи коэффициенте скорости обучения
куммулятивная коррекция весового коэффициента получается умножением
коэффициента скорости обучения на сумму произведений обобщенной ошибки
на выход нейрона:

$$
w^d_{ij}(k+L)=w^d_{ij}(k)-\eta\sum\limits_{p=1}^L
	\delta^d_i(k+p-1) q^{d-1}_j(k+p-1)
$$

Предположим, что коэффициент скорости обучения $\eta$ выбран
оптимально и что величины коррекции весовых коэффициентов на
протяжении эпохи постоянны: 

\begin{equation}\label{eq:equal-weights}
\Delta w^d_{ij}(k)=\Delta w^d_{ij}(k+1)=\ldots=\Delta w^d_{ij}(k+L-1)
\end{equation}

В этом случае выражение для куммулятивной величины коррекции
упрощается:

\begin{equation}\label{eq:product-weightchange}
w^d_{ij}(k+L)=w^d_{ij}(k)-\eta L \delta^d_i(k) q^{d-1}_j(k)
\end{equation}

Видно, что в этом случае коррекция веса $w^d_{ij}$ при том же
коэффициенте $\eta$ будет в $L$ раз больше, чем в классическом
алгоритме~\eqref{eq:weightchange}.  В случае продолжительной эпохи
($L=10^2\ldots 10^3$) это будет означать очень большое изменение
весового коэффициента, что обычно приводит к насыщению нейрона и
потере им способности к обучению.  Чтобы сохранить скорость и
устойчивость обучения классического алгоритма обратного
распространения в случае~\eqref{eq:equal-weights} следует взять
коэффициент $\eta$ меньшим в $L$ раз.

На практике различные обучающие пары дают различные величины коррекции
весовых коэффициентов.  Более того, эти величины могут иметь различные
знаки как из-за характера целевой функции, так и из-за наличия шумов в
обучающих данных.  Поэтому для сохранения желаемой динамики процесса
обучения нейронной сети достаточно уменьшить оптимальный коэффициент
$\eta$ в меньшее число раз, чем длительность эпохи $L$.

Уменьшение коэффициента скорости при пакетном обучении способствует
устойчивости алгоритма обратного распространения.  Это особенно важно
в тех случаях, когда обучение нейронной сети производится одновременно
с ее рабочим функционированием, как, например, при обучении
нейросетевого регулятора в контуре управления по инверсной модели
(п.~\ref{nnc_final_training}).

При обучении многослойных нейронных сетей в задачах стохастического
оптимального управления оказалось целесообразным применять меньший
коэффициент скорости обучения в выходном слое сети по сравнению со
скрытыми слоями.  В результате анализа процесса обучения на многих
экспериментах было обнаружено, что коррекция весовых коэффициентов
выходных нейронов с линейной функцией активации оказывает наибольшее
влияние на устойчивость обучения.  Изменения этих весовых
коэффициентов должны осуществляться наиболее осторожно.  В то же
время, малые изменения в скрытых слоях приводят к слишком медленной
сходимости.  Практика показала, что изменения весовых коэффициентов в
скрытых слоях могут быть б\'ольшими без потери алгоритмом устойчивой
сходимости.

Для небольших нейронных сетей (не более 10 нейронов в слое)
оптимальное соотношение коэффициента скорости обучения в скрытых слоях
$\eta_h$ к коэффициенту скорости обучения в выходном слое $\eta_o$
находится в диапазоне $2\ldots 10$.


\subsection{Выбор начального приближения НС--Р}\label{init-approach}

Обучение нейросети методом обратного распространения подобно
градиентному методу оптимизации.  Как и в градиентных методах, при
обучении нейросетевого регулятора важен выбор начального приближения.
Чем ближе он к минимуму функции ошибки, тем меньшее количество шагов
потребуется сделать и тем меньше вероятность попадания в локальные
минимумы.

В качестве начального приближения для НС--Р можно использовать
функцию, реализуемую имеющимся регулятором. Для этого по
достаточно длинной экспериментальной выборке, полученной на
функционирующей САУ с традиционным регулятором, нейросетевой
регулятор может быть обучен функционированию первого в режиме
следования эталону. Очевидно, в этом случае нейросетевой регулятор
не даст улучшения качества управления, однако полученная нейросеть
станет первым приближением в процедуре дальнейшего обучения.

Обучение начальному приближению может быть осуществлено вне контура
управления по временным рядам, полученным в процессе штатного
функционирования исходной системы управления.  Поскольку вне контура
управления можно не следовать достаточно жесткому ограничению
(см. требование~\ref{realcond} на \pgref{realcond}), в качестве
начального состояния весовых коэффициентов нейросети можно
использовать любое из известных эвристических правил~\cite{gibb96}.

После успешного обучения начальному приближению нейросетевой
регулятор может использоваться в контуре управления вместо
исходного.
