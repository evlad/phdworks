%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Вариант плана
%\section{Причины выбора стохастических методов в качестве полигона
%для применения ИНС (сравнить с другими работами где sin}

%\section{Постановка задачи в стационарном случае}

%\section{Изучение Винеровской и Калмановской фильтрации на предмет
%выявления рационального зерна}

%\section{Сама идея и е\"е аргументация схемы НОР}

%\section{Реализация НОР подобно Винеровскому оптимальному управлению
%--- эксперимент}

% Вопрос устойчивости системы с НОР
% НОР дискретный, а как в непрерывном времени?

%\section{Реализация НОР по произвольному ПИД --- эксперимент}

%\section{Обсуждение полученных результатов --- важность фазовой
%плоскости $u-e$.  Гипотеза о независимости от спектра уставки}

%\section{Проверка гипотезы --- равномерное распределение при обучении НОР
%--- эксперимент}

%\section{Сравнение эффективности НОР с оптимальным управление по
%Калману--Белману --- эксперимент}

%\section{Результаты моделирования для разнообразных
%детерминированных сигналов --- эксперимент}

%\section{Вопросы выбора структуры ИНС-О и ИНС-Р}

%\section{Обсуждение возможности применения архитектуры ИНС-О с ОС}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Введение}



В реальных системах управления полезный сигнал всегда искажен
помехой.  В рамках классической теории автоматического управления
помехой пренебрегают, рассматривая идеализированную систему.
Данный подход применяется как для задач идентификации, так и для
задач синтеза.  Кратко отметим особенности детерминистского
подхода.


Задачи данного класса могут возникать в самых разных практически
эксплуатируемых системах управления. К их специфике относятся:

\begin{itemize}
  \item Невозможность проводить эксперименты, допустимые на
  моделях.
  \item В силу постоянной эксплуатации объекта управления
  невозможно отключить регулятор на время или вставить регулятор с
  некорректно настроенными
  \item За время эксплуатации параметры объекта могли существенно
  ``уйти'' от расчетных, поэтому нужна идентификация.
\end{itemize}

Задача синтеза линейного регулятора в схожих условиях
рассматривалась в рамках стохастической линейной теории управления
Винером и Калманом.  К недостаткам разработанных ими методов
следует причислить неробастность (неустойчивость) в условиях,
отличных от модельных.  Известны способы построения нейросетевых
регуляторов в различных условиях. Однако в целом задача синтеза
нейросетевого регулятора в практических условиях

в стохастической постановке нейросетевые регуляторы никто не делал



В реальных системах управления полезный сигнал всегда искажен
помехой.  В рамках классической теории автоматического управления
помехой пренебрегают, рассматривая идеализированную систему.
Данный подход применяется как для задач идентификации, так и для
задач синтеза.  Кратко отметим особенности детерминистского
подхода.

В задачах идентификации

Из самых общих представлений очевидно, что проектирование системы
управления для идеализированных условий приводит к потере качества
при реальной эксплуатации.

Изложение метода с двумя примерами: физически реализуемым и
физически нереализуемым управлением.

%\begin{equation}
%\left\{\begin{array}{rcl}
%  x(t+1) & = & A x(t) + B u(t) + w(t) \\
%  y(t) & = & C x(t) + v(t)
%\end{array}\right.
%\end{equation}


%\begin{equation}
%\left\{\begin{array}{rcl}
%  x(t+1) & = & A x(t) + B u(t) + w(t) \\
%  y(t) & = & C x(t) + v(t)
%\end{array}\right.
%\end{equation}
%
%\begin{equation}
%  u(t) = - L \hat{x}(t)
%\end{equation}
%
%\begin{equation}
%  y(t) \equiv x(t)\quad\Rightarrow\quad\hat{x}(t) = y(t)
%\end{equation}
%
%\begin{equation}
%  \hat{x} = K(t) y(t),\quad P(0) = \mathop{\rm cov} x(0)
%\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Традиционным способом настройки параметров искусственной нейронной
сети является обучение.  Обучением НС называется итерационный
процесс изменения параметров сети с целью оптимизации заданного
функционала.  В рассматриваемой постановке функционал является
квадратичной формой по обучающей выборке.

\begin{figure}[h]
  \centering
  \input genctrlp.lp
  \caption{Объект управления.}
  \label{fig:genctrlp}
\end{figure}

Основной задачей, возникающей при синтезе НС-Р является получение

Настройка коэффициентов нейросети производится на некотором
конечном множестве обучающих пар.  Между точками нейросеть
выполняет интерполяцию. Представим каждую пару точкой в
пространстве подходящей размерности.  Известно, что нейросети
являются хорошими интерполяторами, но плохими аппроксиматорами.
Поэтому логично ввести понятие {\em области определения
нейросети,} охватывающей все точки обучающего множества.  За
пределами этой области поведение нейросети может сколь угодно
сильно отличаться от ожидаемого.

В рассматриваемом примере обучающим множеством является пара

%Построение нейросетевой модели объекта производится на некотором
%конечном множестве обучающих пар.  Эти пары задают узловые точки,
%через которые проходит целевая функция обучения.  Нейросеть
%обучается проходить как можно ближе к этим точкам, но между ними
%еј поведение может значительно отличаться от целевой функции.  При
%достаточном количестве обучающих пар и ограниченном числе весовых
%коэффициентов (оптимизируемых параметров), реализуемая нейросетью
%функция будет достаточно хорошо повторять поведение целевой
%функции между узловыми точками.  Однако за пределами области, в
%которой группируются узловые точки, поведение функции
%$\mathcal{B}$ может сколь угодно сильно отличаться от ожидаемого.
%Назовем область, охватывающую множество обучающих точек, {\it
%областью определения нейросети.}

 Функция $\mathcal{B}^o$ для заданных $u_k$ и
$\hat{y}_{k+1}$ реализует инверсию объекта управления

Переменные $\hat{y}_{k+1}$ и $r_{k+1}$ входят в функцию
$\mathcal{B}^o$ в форме разности $\hat{e}_{k+1}=\hat{y}_{k+1} -
r_{k+1}$ (см.~\eqref{eq:deltaprop}).  Фактически, можно считать,
что область определения НС--О образуется множеством точек $(u_k,
\hat{e}_{k+1})$
 , то есть,
фактически При инверсии объекта управления заменяем $r_{k+1}$ на
$\tilde{y}_{k+1}$. Однако, если окажется, что разность
$\hat{y}_{k+1} - \tilde{y}_{k+1}$ выводит точку $(u_k,
\hat{y}_{k+1}, \tilde{y}_{k+1})$ за пределы области определения
$\mathcal{N}^o$, точность инверсии может оказаться очень плохой.
Данная ситуация произойдет

при плохом качестве предсказания выхода объекта управления уже
нельзя считать $y_{k+1} \approx \hat{y}_{k+1}$.  В этом случае ,
то есть,  выше определенного предела, качество инверсии резко
упадет.

Опущенные в~\eqref{eq:nno_y_to_u} аргументы в можно
интерпретировать как точку $(u_k, \hat{y}_{k+1})$, в которой
определена функция $\mathcal{B}^o: \tilde{y}_{k+1} \rightarrow
\tilde{u}_k$.  Смысл определения состоит в том, что если

Можно интерпретировать $\mathcal{B}^o$ как функцию, отображающую
фактическое управляющее воздействие в желаемое для достижения
требуемого выхода объекта $\tilde{y}_{k+1}$:

$$ \mathcal{B}^o: u_k \rightarrow \tilde{u}_k $$

Построение нейросетевой модели объекта производится на некотором
конечном множестве обучающих пар.  Эти пары задают узловые точки,
через которые проходит целевая функция обучения.  Нейросеть
обучается проходить как можно ближе к этим точкам, но между ними
еј поведение может значительно отличаться от целевой функции.  При
достаточном количестве обучающих пар и ограниченном числе весовых
коэффициентов (оптимизируемых параметров), реализуемая нейросетью
функция будет достаточно хорошо повторять поведение целевой
функции между узловыми точками.  Однако за пределами области, в
которой группируются узловые точки, поведение функции
$\mathcal{B}$ может сколь угодно сильно отличаться от ожидаемого.

Учитывая, что функция $\mathcal{B}^o$ зависит трех аргументов, от
значений

Обобщая свойства нейросетевой функции $\mathcal{B}^o$ можно
считать, что функция $\mathcal{B}^o: \tilde{y}(t) \rightarrow
\tilde{u}(t)$ определена в некоторой окрестности

Если считать  Зависимость функции $\mathcal{B}^o$ от значений
$u_k$ и $\hat{y}_{k+1}$ делает

Поэтому

 Поскольку $\mathcal{B}^o$ зависит от разности
$\hat{y}_{k+1} - r_{k+1}$ (см.~\eqref{eq:deltaprop}), при плохом
качестве предсказания выхода объекта управления уже нельзя считать
$y_{k+1} \approx \hat{y}_{k+1}$.  В этом случае , то есть,  выше
определенного предела, качество инверсии резко упадет.

Зависимость функции $\mathcal{B}^o$ от $u_k$ и $\hat{y}_{k+1}$
Таким образом, функция

С другой стороны, локальная инверсия объекта управления вблизи
$u_k$ и $\hat{y}_{k+1}$ расширяет возможности представления
нейросетью сложных объектов.  Можно показать, что для многозначной
функции из достаточно широкого класса  имеется возможность
построить кусочно--однозначную функцию.



Ненулевая ошибка управления вызвана (по условию отсутствия помех)
неоптимальным функционированием регулятора.  В силу
равенства~\eqref{eq:outputs} можем использовать $y_{k+1}$ вместо
$\hat{y}_{k+1}$ в~\eqref{eq:invobj} для вычисления требуемого
управляющего воздействия $u^*_k$ на предыдущем такте.



\subsection{Синтез нейросетевого регулятора в реальных условиях}

Описанный в разделе~\ref{nnplearning} метод обучения НС--Р
рассматривался в идеальных условиях отсутствия помех и абсолютно
идентично настроенной модели объекта управления.  Кроме того не
учитывался тот факт, что объект управления является динамической
системой обладающей состоянием, а значит выход объекта зависит не
только от управляющего воздействия, но и от состояния объекта
управления.

Не затрагивался также вопрос применения нейросетей в случае
многомерного объекта управления и нескольких каналов
регулирования.  В рамках рассматриваемой структуры САУ,
представленной на \figref{fig:ctrlloop} это не должно представлять
проблемы, так как нейронные сети изначально были предназначены для
решения многомерных задач.  Однако следует отметить, что в случае
невозможности непосредственного наблюдения состояния объекта
управления необходимо предусмотреть схему восстановления состояния
по наблюденным данным, такую как фильтр Калмана~\cite{bramziff82}.
Очевидно, в этом случае объект должен быть наблюдаем.

\subsubsection{Построение нейросетевой модели объекта управления}

Рассмотрим задачу построения нейросетевой модели одномерного
динамического объекта управления, описываемого некоторой
передаточной функцией.  В терминах пространства состояний объект
управления можно представить следующей системой разностных
уравнений:

\begin{equation}\label{eq:1d-ss}
\left\{\begin{array}{rcl}
  \mathbf{x}_{k+1} & = & F \mathbf{x}_k + G u_k \\
  y_k & = & H \mathbf{x}_k
\end{array}\right.
\end{equation} где $y_k$ и $u_k$ --- скаляры, а $\mathbf{x}$ --- вектор
состояния.

Статическая нейросеть, реализующая функцию
$\hat{y}_{k+1}=\mathcal{N}^o(u_k)$ принципиально не может решить
задачу имитации поведения объекта \eqref{eq:1d-ss}, так как
нейросеть не обладает состоянием: в любой момент выход нейронной
сети прямого распространения полностью определяется еј актуальными
входами и не зависит от предыдущих входов.

Информация о состоянии объекта может хранится в НС--О двумя
способами.  Первый из них связан с введением обратных связей в
нейронную сеть модели объекта управления~\cite{sigom00}. Второй
основан на нейросетевой модели АРСС.

\paragraph{Обратные связи в структуре НС--О}
Обратная связь рассматривается в качестве дополнительного входа
нейросети. НС--О функционирует в этом случае в соответствии с
уравнением

$$ \hat{y}_{k+1}=\mathcal{N}^o(u_k, \hat{y}_k) $$

Задержанный сигнал обратной связи $\hat{y}_k$ имеет смысл памяти
состояния.  Таким образом, нейросетевая модель объекта в этом
случае является полностью автономной системой.

Для обучения нейронных сетей в обратными связями используется
метод обратного распространения в времени ({\em backpropagation
through time --- BPTT})~\cite{gibb96}. Преимуществом данного
подхода является возможность настройки модели вне контура
управления.  К недостаткам метода обучения BPTT относится эффект
исчезающего градиента ({\em vanishing gradient}), проявляющийся в
том, что нейросеть выявляет короткие зависимости, но не может
научиться длинным в силу многократного ослабления информации о
зависимости в обратной связи~\cite{linetal}.

Применительно к задаче нейросетевой имитации объекта управления
проблема исчезающего градиента будет возникать в двух случаях:
\begin{itemize}
  \item значительное чистое запаздывание в динамике объекта
  управления;
  \item шаг квантования времени слишком мал по сравнению с
  характерным временем наступления установившегося режима.
\end{itemize}

\paragraph{Структура НС--О подобно модели АРСС}
Второй способ введения состояния основан на представлении объекта
в виде нейросетевой модели авторегрессии--скользящего среднего
(АРСС).  В этом случае нейронная сеть на каждом шаге воспроизводит
состояние объекта на основании запомненных на некотором интервале
наблюдений о состоянии объекта и управляющем воздействии:

$$ \hat{y}_{k+1}=\mathcal{N}^o(u_k, u_{k-1},\ldots,u_{k-D_u}, y_k,
y_{k-1},\ldots, y_{k-D_y}) $$

Как видно, нейросетевая модель опирается на информацию об
истинном, а не предсказанном на предыдущих шагах состоянии
объекта, как в случае с обратными связями.

Имеет место задача выбора интервала прошлых наблюдений,
используемых для построения модели.  Поскольку в рамках данной
главы рассматриваются стационарные линейные объекты управления,
для построения соответствующих дискретных моделей допустимо
применять соответствующие методы идентификации.  Поскольку этап
подгонки модели соответствует процессу обучения НС--О, для выбора
структуры входов нейросетевой модели достаточно воспользоваться
методами, основанными на построении выборочной взаимной
корреляционной функции, описанными в
литературе~\cite{ostrem73}\cite{boxjenk74}.

\subsubsection{Выбор начального приближения}

% Начальное приближение
Обучение нейросети методом обратного распространения подобно
градиентному методу оптимизации.  Как и в градиентных методах, при
обучении нейросетевого регулятора важен выбор начального
приближения. В качестве него можно использовать функцию,
реализуемую имеющимся регулятором.  Для этого по достаточно
длинной экспериментальной выборке, полученной на функционирующей
САУ с традиционным регулятором, нейросетевой регулятор может быть
обучен функционированию первого в режиме следования эталону.
Очевидно, в этом случае нейросетевой регулятор не даст улучшения
качества управления, однако полученная нейросеть станет первым
приближением в процедуре дальнейшего обучения.

Обучение начальному приближению может быть осуществлено вне
контура управления по временным рядам, полученным в процессе
штатного функционирования исходной системы управления.  Поскольку
вне контура управления можно не следовать достаточно жесткому
ограничению (см. требование~\ref{realcond} на
с.~\pageref{realcond}), в качестве начального состояния весовых
коэффициентов нейросети можно использовать любое из известных
эвристических правил~\cite{gibb96}.

После успешного обучения начальному приближению нейросетевой
регулятор может использоваться в контуре управления вместо
исходного.

\subsubsection{Дообучение нейрорегулятора}

% Окончательное обучение
Использование критерия минимизации среднеквадратичной ошибки
воспроизведения по обучающей выборке приводит к классическому
алгоритму обратного распространения ошибки.  Как видим, критерий
совпадает с общепринятым в линейной оптимальной теории управления.

Дообучение нейросетевого регулятора от начального приближения до
получения приемлемого улучшения качества управления осуществляется
с помощью предварительно настроенной нейросетевой модели.  В
процессе обучения регулятора модель выдает на выходе предсказанное
измеряемое состояние объекта управления.  В случае идеально
настроенной модели и при отсутствии шумов выход объекта и модели
должны совпадать. Пусть выход объекта отличается от уставки, что
дает некоторую ненулевую мгновенную ошибку управления.  Эта ошибка
является следствием неоптимальной настройки регулятора.  Для
получения оценки ошибки управляющего воздействия на входе объекта
подадим ошибку управления на выход модели и распространим еј в
обратном направлении к входу.  В отличие от процедуры обучения
нейросети, при обратном распространении не следует корректировать
весовые коэффициенты нейросетевой модели, так как известно, что
ошибка является следствием действия регулятора.  Приведенная к
входу модели (и объекта) ошибка является оценкой ошибки
управляющего воздействия регулятора.  Складывая еј с актуальным
выходом регулятора получаем эталонное управляющее воздействие.
Если бы оно было подано на вход объекта вместо актуального, то
выход модели не отличался бы от уставки.  При идеальном
соответствии модели и объекта ошибка управления также была бы
равна равна нулю.

В реальности всегда имеются случайные помехи.  Кроме того,
практически невозможно обучить нейросеть функционировать абсолютно
адекватно некоторой функции, к тому же, заданной таблично.  Однако
при хорошей настройке нейросетевой модели, ошибку предсказания
выхода объекта можно считать белым шумом. Таким образом,
изложенный алгоритм получения ошибки управляющего воздействия по
ошибке управления статистически будет работать.

\subsubsection{Помехи и возмущающие воздействия}

Как уже отмечалось, помеха, присутствующая в обучающей выборке для
нейросети не только не мешает обучению, но даже способствует
лучшей обобщающей способности сети.  В этом случае алгоритм
обучения ищет взаимосвязь между входом и выходом, статистически
обобщая на еј выборке.  Критерий обучения (минимум средней
квадратичной ошибки на выборке) аналогичен используемому в
гауссовском методе наименьших квадратов.  Он традиционно
используется в стохастической теории управления для фильтрации
белого шума.

\subsubsection{Начальное состояние весовых коэффициентов НС--О}

Известно, что процесс настройки нейронной сети аналогичен градиентному
методу оптимизации.  В том случае, если оптимизируемый функционал
имеет сложную поверхность с локальными минимумами, успех отыскания
глобального с помощью градиентного спуска зависит от выбора начальной
точки.  Если точка выбрана ``неправильно'', то классический
градиентный метод привед\"ет в локальный минимум.  Выбор начальной
точки также сказывается на скорости сходимости.

%Пространство настраиваемых параметров в случае с обучением нейронной
%сети образуется весовыми коэффициентами нейронов.  Оптимизируемый
%функционал включает в себя данные обучающей выборки.  Вид функционала
%определяется архитектурой нейронной сети.

В случае с обучением нейросетевой модели объекта управления
пространство настраиваемых параметров образуется весовыми
коэффициентами нейронов.  Традиционно их начальное значение задается
случайным с равномерным распределением в окрестности нуля.
Представляется важным выяснить чувствительность процедуры обучения
НС--О к выбору начальной точки.  Поскольку оптимизируемый функционал
включает в себя данные обучающей выборки, а его вид определяется
архитектурой нейронной сети, исследование целесообразно провести для
различных реализаций обучающих данных и различных архитектур сети.

\paragraph{Эксперимент T5}

Для выяснения зависимости сходимости алгоритма обучения от выбора
начальной точки был проведен вычислительный эксперимент, в рамках
которого при заданной обучающей выборке и архитектуре нейросети
варьировались начальные значения весовых коэффициентов.

Были зафиксированы:

\begin{itemize}
  \item Объект управления: $G(z)=\frac{0.25z}{z-0.75}$
  \item Помеха: белый шум с параметрами $\{0, 0.1\}$
  \item Регулирующее воздействие: белый шум с параметрами $\{0, 1\}$
  \item Длина обучающей выборки: 250
  \item Длина тестовой выборки: 500
  \item Число и номенклатура входов нейронной сети:
  $\mathcal{N}^o(u_k, y_k, y_{k-1}, y_{k-2})$
\end{itemize}

В ходе эксперимента проводились сеансы обучения НС--О с различными
случайно выбранными в диапазоне $-\Delta, \Delta$ начальными
значениями весовых коэффициентов.  Для каждого значения $\Delta$
проводилось 10 сеансов обучения.  Были проведены серии сеансов
обучения со значениями $\Delta$: 0.05, 0.1, 0.2, 0.3, 0.4, 0.5.

В эксперименте участвовали нейронные сети с различной внутренней
архитектурой, а именно, однослойная $\mathcal{N}^o_{1+3,1}$,
двухслойная $\mathcal{N}^o_{1+3,4,1}$, трехслойная
$\mathcal{N}^o_{1+3,7,4,1}$.  Длительность сеанса обучения была
выбрана равной 400 эпохам.

В эксперименте исследовалось поведение траектории среднеквадратичной
ошибки на тестовой выборке.  Обучение прекращалось в том случае, если
СО на тестовой выборке начинала возрастать.  В этом случае траектория
выбывала из расчета средней на завершающем участе.  По сумме 10
сеансов обучения рассчитывалась средняя траектория и траектория
выборочного среднеквадратического отклонения.  Результаты
экспериментов в численной форме приведены в таблице \ref{tabl:T5}.

\begin{table}[ht]
\caption{Чувствительность процедуры обучения НС--О к выбору начальной
         точки в пространстве весовых коэффициентов}\label{tabl:T5}
\begin{tabular}{|l|l|c|c|c|c|c|}
\hline
НС--О & $\Delta$ &
\multicolumn{2}{|c|}{среднее $\SE$} &
\multicolumn{2}{|c|}{отклонение $\SE$} & Выбыло \\
\cline{3-6}
 & & $t=0$ & $t=400$ & $t=0$ & $t=400$ & \\
\hline
 & 0.05 & 0.9508 & 0.0510 & 0.0991 & 0.0044 & 0 \\
 & 0.1  & 0.9842 & 0.0497 & 0.3030 & 0.0053 & 0 \\
$\mathcal{N}^o_{1+3,1}$
 & 0.2  & 1.3027 & 0.0569 & 0.4749 & 0.0126 & 0 \\
 & 0.3  & 1.3617 & 0.0572 & 0.6595 & 0.0133 & 0 \\
 & 0.4  & 1.9263 & 0.0458 & 1.0056 & 0.0149 & 0 \\
 & 0.5  & 2.2544 & 0.0622 & 1.4277 & 0.0262 & 0 \\
\hline
 & 0.05 & 1.0013 & 1.0074 & 0.0082 & 0 & 9 \\
 & 0.1  & 1.0325 & 0.0712 & 0.0314 & 0.0076 & 6 \\
$\mathcal{N}^o_{1+3,4,1}}$
 & 0.2  & 1.0987 & 0.0687 & 0.1047 & 0.0089 & 0 \\
 & 0.3  & 1.2854 & 0.0681 & 0.2345 & 0.0129 & 0 \\
 & 0.4  & 1.2554 & 0.0598 & 0.2631 & 0.0229 & 0 \\
 & 0.5  & 1.6581 & 0.0804 & 0.6398 & 0.0213 & 0 \\
\hline
 & 0.05 & 0.9997 & 1.0261 & 0.0078 & 0 & 9 \\
 & 0.1  & 1.0106 & 1.0290 & 0.0162 & 0 & 9 \\
$\mathcal{N}^o_{1+3,7,4,1}$
 & 0.2  & 1.0705 & 1.0375 & 0.0461 & 0 & 9 \\
 & 0.3  & 1.2134 & 0.0947 & 0.2154 & 0.0048 & 6 \\
 & 0.4  & 1.2788 & 0.0981 & 0.2218 & 0.0207 & 6 \\
 & 0.5  & 1.7474 & 0.0823 & 0.7961 & 0.0550 & 6 \\
\hline
\end{tabular}
\end{table}

Результаты эксперимента можно обобщить в следующих зависимостях.

Во-первых, больший диапазон разброса значений начальных весов в
среднем приводит к более хорошим результатам в обучении.

Во-вторых, ограничение диапазона распределения начальных весов может
привести к проблеме переобучения НС, то есть, уменьшение СО на
обучающей выборке сопровождается увеличением СО на тестовой.  Это
явление зависит от сложности архитектуры сети.  В частности, оно
совсем не наблюдалось на однослойной сети, на двухслойной сети оно
имело место при $\Delta=0.05$ и $\Delta=0.1$, на трехслойной сети
переобучение наблюдалось при всех значениях $\Delta$.

\begin{figure}
\begin{tabular}{cc}
\vbox{%
\hbox{\psfig{figure=T5_mse_mean_1+3_1.ps,angle=270,width=0.46\textwidth}}
\hbox to 0.46\textwidth{\hfil а) средняя траектория СО\hfil}}&
\vbox{%
\hbox{\psfig{figure=T5_mse_stddev_1+3_1.ps,angle=270,width=0.46\textwidth}}
\hbox to 0.46\textwidth{\hfil б) разброс траекторий СО\hfil}}
\end{tabular}
\caption{Графики обучения $\mathcal{N}^o_{1+3,1}$ при разных величинах
         начального разброса весовых коэффициентов НС}\label{fig:T5-1+3_1}
\end{figure}

\begin{figure}
\centerline{\hbox{%
\psfig{figure=T5_mse_mean_1+3_1.ps,angle=270,height=8cm,width=1\textwidth}}}
\caption{Графики средних траекторий СО при обучении $\mathcal{N}^o_{1+3,1}$
         при разных величинах начального разброса весовых коэффициентов НС}
\label{fig:T5mean-1+3_1}
\end{figure}

\begin{figure}
\centerline{\hbox{%
\psfig{figure=T5_mse_mean_1+3_41.ps,angle=270,height=8cm,width=1\textwidth}}}
\caption{Графики средних траекторий СО при обучении $\mathcal{N}^o_{1+3,4,1}$
         при разных величинах начального разброса весовых коэффициентов НС}
\label{fig:T5mean-1+3_41}
\end{figure}

\begin{figure}
\centerline{\hbox{%
\psfig{figure=T5_mse_mean_1+3_731.ps,angle=270,height=8cm,width=1\textwidth}}}
\caption{Графики средних траекторий СО при обучении $\mathcal{N}^o_{1+3,7,3,1}$
         при разных величинах начального разброса весовых коэффициентов НС}
\label{fig:T5mean-1+3_731}
\end{figure}

%\begin{figure}
%\centerline{\hbox{%
%\psfig{figure=T5_mse_stddev_1+3_41.ps,angle=270,width=1\textwidth}}}
%\caption{Графики обучения $\mathcal{N}^o_{1+3,4,1}$ при разных величинах
%         начального разброса весовых коэффициентов НС}\label{fig:T5stddev-1+3_41}
%\end{figure}

% Были проведены численные эксперименты с 

%% показать, что поверхность достаточно гладкая или найти проблемы

\subsubsection{Структура и число входов НС--О}

Поскольку в рамках данной главы рассматриваются стационарные линейные
объекты управления, предлагается методика расчета числа входов
нейросетевой модели, основанная на предположении о линейности объекта.

%Это не означает, что рассматриваемый метод ограничен сугубо линейным

Линейный объект управления полностью характеризуется имульсной
переходной характеристикой.  Пример отклика приведен на
\figref{step-response}.  Времена $T_{delay}$ и $T_{perehod}$
характеризуют чистое запаздывание и длительность переходного процесса.

Выбор числа входов для НС--О должен делаться на основе свойства
отсутствия памяти состояния в нейросети.  Поэтому нейросеть должна
быть обеспечена всей необходимой информацией для имитации объекта.

В случае наличия в объекте чистого запаздывания информация о
воздействии, породившем отклик объекта, должна иметься у нейронной
сети к моменту появления этого отклика на выходе объекта.  То есть,
достаточное число повторов управляющего воздействия на входе НС--О
должно быть не больше $1+T_{delay}/\Delta T$, где $\Delta T$ --- шаг
квантования времени в системе.

Переходный процесс является характерным проявлением динамических
свойств объекта управления.  Время его завершения является мерой
инерционности объекта и оно должно имитироваться нейросетевой моделью.
Для описания инерционности объекта статической нейросетью требуется не
больше чем $1+T_{perehod}/\Delta T$ повторений прошлых состояний
объекта управления.

Таким образом, получены верхние оценки необходимого числа входов для
нейросетевой модели объекта управления:

\begin{equation}\label{eq:nnp-inputs-number}
\begin{array}{rcl}
  D_u & = & T_{delay}/\Delta T \\
  D_y & = & T_{perehod}/\Delta T
\end{array}
\end{equation}

%Поскольку
%этап подгонки модели соответствует процессу обучения НС--О, для выбора
%структуры входов нейросетевой модели достаточно воспользоваться
%методами, основанными на построении выборочной взаимной корреляционной
%функции, описанными в литературе~\cite{ostrem73}\cite{boxjenk74}.


\subsubsection{Влияние выбора начальной точки в пространстве весовых
               коэффициентов}

Известно, что процесс настройки нейронной сети аналогичен градиентному
методу оптимизации.  В том случае, если оптимизируемый функционал
имеет сложную поверхность с локальными минимумами, успех отыскания
глобального с помощью градиентного спуска зависит от выбора начальной
точки.  Если точка выбрана ``неправильно'', то классический
градиентный метод привед\"ет в локальный минимум.  Выбор начальной
точки также сказывается на скорости сходимости.

В случае с обучением нейросетевой модели объекта управления
пространство настраиваемых параметров образуется весовыми
коэффициентами нейронов.  Традиционно их начальное значение задается
случайно с равномерным распределением в окрестности нуля.
Представляется важным выяснить чувствительность процедуры обучения
НС--О к выбору начальной точки.  Поскольку оптимизируемый функционал
включает в себя данные обучающей выборки, а его вид определяется
архитектурой нейронной сети, исследование целесообразно провести для
различных реализаций обучающих данных и различных архитектур сети.

Для выяснения зависимости сходимости алгоритма обучения от выбора
начальной точки был проведен вычислительный эксперимент, в рамках
которого при заданной обучающей выборке и архитектуре нейросети
варьировались начальные значения весовых коэффициентов.

Были зафиксированы:

\begin{itemize}
  \item Объект управления: $G(z)=\frac{0.25z}{z-0.75}$
  \item Помеха: белый шум с параметрами $\{0, 0.1\}$
  \item Регулирующее воздействие: белый шум с параметрами $\{0, 1\}$
  \item Длина обучающей выборки: 250
  \item Длина тестовой выборки: 500
  \item Число и номенклатура входов нейронной сети:
  $\mathcal{N}^o(u_k, y_k, y_{k-1}, y_{k-2})$
\end{itemize}

В ходе эксперимента проводились сеансы обучения НС--О с различными
случайно выбранными в диапазоне $(-\Delta, \Delta)$ начальными
значениями весовых коэффициентов.  Для каждого значения $\Delta$
проводилось 10 сеансов обучения.  Были проведены серии сеансов
обучения со значениями $\Delta$: 0.05, 0.1, 0.2, 0.3, 0.4, 0.5.

В эксперименте участвовали нейронные сети с различной внутренней
архитектурой, а именно, однослойная $\mathcal{N}^o_{1+3,1}$,
двухслойная $\mathcal{N}^o_{1+3,4,1}$, трехслойная
$\mathcal{N}^o_{1+3,7,4,1}$.  Длительность сеанса обучения была
выбрана равной 400 эпохам.

В эксперименте исследовалось поведение траектории среднеквадратичной
ошибки в процессе обучения на тестовой выборке, причем в качестве
объекта измерения были взяты СО в начальный и конечный момент времени.
Для каждой архитектуры нейросети и значения $\Delta$ по результатам 10
сеансов обучения определялось среднее значение СО и разброс (среднее
квадратическое отклонение).  Если СО на тестовой выборке начинала
возрастать, то сеанс обучения прекращался и траектория выбывала из
финального расчета для конечного момента времени.

Результаты эксперимента представлены на \figref{fig:initial-weights} в
виде графиков, причем диаграммы (а) и (б) демонстрируют зависимость
среднего значения СО от диапазона разброса весов в начальный и
конечный моменты времени, а (в) и (г) демонстрируют зависимость
среднеквадратического отклонения СО соответственно.

\begin{figure}
\begin{tabular}{p{0.46\textwidth}p{0.46\textwidth}}
\psfig{figure=T5_mse_mean_t0.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T5_mse_mean_t400.ps,angle=270,width=0.46\textwidth}\\[0pt]
а) среднее значение СО в начале обучения &
б) среднее значение СО в конце обучения\\[16pt]
\psfig{figure=T5_mse_stddev_t0.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T5_mse_stddev_t400.ps,angle=270,width=0.46\textwidth}\\[0pt]
в) разброс СО в начале обучения &
г) разброс СО в конце обучения\\[16pt]
\end{tabular}
\caption{Чувствительность процедуры обучения НС--О к выбору начальной
         точки в пространстве весовых коэффициентов}\label{fig:initial-weights}
\end{figure}

Результаты эксперимента дают основание следующим обобщениям:

\begin{enumerate}
  \item Б\'ольший диапазон разброса значений начальных весов в среднем
        приводит к более хорошим результатам в обучении независимо от
        сложности архитектуры нейросети.  Однако для сложных
        архитектур это приводит к относительно б\'ольшему разбросу
        результатов обучения.
  \item Ограничение диапазона распределения начальных весов может
        привести к проблеме переобучения НС, то есть, уменьшение СО на
        обучающей выборке сопровождается увеличением СО на тестовой.
        Это явление зависит от сложности архитектуры сети.  В
        частности, оно совсем не наблюдалось на однослойной сети, на
        двухслойной сети оно имело место при $\Delta=0.05$ и
        $\Delta=0.1$, на трехслойной сети переобучение наблюдалось при
        всех значениях $\Delta$.
\end{enumerate}



\subsubsection{Ограниченное усиление нейронной сети}

Искусственная нейронная сеть рассматриваемой архитектуры представляет
собой композицию нелинейных пороговых элементов.  Выходные нейроны в
зависимости от выбора инженера могут также иметь пороговую
сигмоидальную или линейную функцию активации.  Последний вариант
делает из выходного нейрона линейный сумматор с весовыми
коэффициентами.  Однако рабочая часть нейронной сети --- скрытые слои
нейронов --- обязательно имеют сигмоидальную функцию активации, то
есть, наличие пороговых элементов делает выход ИНС независимым от
уровня входных сигналов.  Итак, выход нейросети представляет собой
ограниченную функцию (взвешенная сумма ограниченных функций тоже
является таковой).

\begin{figure}[h]
\centerline{\hbox{\psfig{figure=nnp_limited_amplif_learn.ps,%
angle=270,width=0.8\textwidth,height=0.3\textheight}}}
\centerline{а)}
\centerline{\hbox{\psfig{figure=nnp_limited_amplif_test.ps,%
angle=270,width=0.8\textwidth,height=0.3\textheight}}}
\centerline{б)}
\caption{Графики аппроксимации выхода объекта на обучающей (а) и
         контрольной траектории (б).}
\label{fig:limited_amplification}
\end{figure}

Применение нейронных сетей в реальных системах управления требует
адаптации к произвольным уровням сигналов.  При ошибочном выборе
нейронная сеть будет плохо обучаться и еще хуже функционировать.
Рассмотрим пример обучения НС--О без масштабирования уровня сигналов.
На~\figref{fig:limited_amplification}а видно, что при обучении
нейросеть не смогла повторить траекторию объекта в крайних значениях.
Уровень, достигнутый НС--О, обозначен горизонтальными прямыми $4.1$ и
$-5.4$.  На \figref{fig:limited_amplification}б траектория объекта в
пределах, достигнутых при обучении, достаточно точно повторяется
нейросетью.  Однако ограниченность усиления НС--О проявляется там, где
траектория объекта лежит за пределами $4.1$ и $-5.4$, причем на
графике видно, что они в самом деле являются границами области
значений нейросетевой функции.

В данном примере в качестве сигмоидальной функции активации
использовался гиперболический тангенс.  Он имеет область значений
$(-1, 1)$.


Результаты имитационного эксперимента сведены в таблицу
\ref{tabl:nnp_mse_freq}:

\begin{table}[ht]
\caption{Зависимость СО предсказания нейросетевых моделей от частоты}
\label{tabl:nnp_mse_freq}
\begin{tabular}{|l|l|c|c|c|}
\hline
$T$ & $f$ &
$\mathcal{N}_{step}$ &
$\mathcal{N}_{sin}$ &
$\mathcal{N}_{stoch}$ \\
 3 & 0.333 & 0.086 & 0.079 & 0.145 \\
 5 & 0.200 & 0.019 & 0.013 & 0.067 \\
 10 & 0.100 & 0.008 & 0.002 & 0.054 \\[16pt]
 20 & 0.050 & 0.005 & 0.001 & 0.052 \\[16pt]
 30 & 0.033 & 0.003 & 0.002 & 0.054 \\
 40 & 0.025 & 0.002 & 0.002 & 0.059 \\
 50 & 0.020 & 0.002 & 0.004 & 0.052 \\
\hline
\end{tabular}
\end{table}


\paragraph{Оценка эффективности обучения НС--О}
Однако приведенные графики зависимости ошибки воспроизведения от
различных параметров не несут информации о пригодности обученных НС--О
разной архитектуры для дальнейшей настройки нейросетевого регулятора.
Учитывая соображения, изложенные в п.~\ref{criteria_and_goal},
реальная эффективность НС--О определяется точностью воспроизведения
якобиана объекта~\eqref{eq:jacobinv}.  В имитационном эксперименте
можно точно рассчитать якобиан объекта, но в реальной ситуации в
лучшем случае придется довольствоваться его приближением.
Руководствуясь выбранными ограничениями ``реальности'' объекта
управления, разработаем методику оценки качества обучения нейросетевой
модели объекта управления, пригодную для применения на реальном
физически существующем объекте.

Итак, сравнивать эффективность инвертирования объект управления с
помощью НС--О не с чем, так как считаем якобиан объекта неизвестным.
Однако можно оценить степень имитации объекта нейросетью.
Количественной оценкой может служить средний квадрат ошибки имитации
объекта на пробном управляющем воздействии.  В качестве такового можно
взять ступенчатое или гармоническое возмущение на конечном интервале
времени.  Можно привести два аргумента в пользу выбора именно
детерминированного воздействия для проверки эффективности обученной
НС--О: во-первых, полезно проверить функционирование имитатора на
сигнале, принципиально отличном от обучающего; во-вторых, в силу
простоты формы возмущения (и, как правило, отклика объекта) достаточно
легко диагностировать проблемы, вызванные неправильным выбором
архитектуры НС--О.

%Практический вывод данного исследования заключается в том, что вполне
%достаточной 

{\bf Как проверить качество НС--О по входу $u_k$?}

{\bf Соответствие сложности сети и сложности обучающих данных?}



\paragraph{Влияние длины выборки на обучение НС--О}

%Известно, что решение задачи интерполяции по конечному числу точек
%всегда сопряжено с опасностью настройки параметров модели на эти точки
%в ущерб обобщающей способности модели, то есть, ``правильному''
%поведению модели между точками.  Ухудшение обобщающей способности при
%улучшении результата на исходных точках для искусственных нейронных
%сетей называется проблемой переобучения.  Для контроля над обобщающей
%способностью в процессе настройки модели используются тестовые точки и
%оценка качества настройки проводится именно по ним.

Известная проблема переобучения нейросети вызвана комплеском
взаимосвязанных факторов.  В их числе количество весовых коэффициентов
нейросети, е\"е архитектура, длина обучающей и тестовой выборок.
Исследуем на примере нескольких нейросетевых архитектур влияние длины
обучающей выборки на качество обучения НС--О.  Для этого проведем
вычислительный эксперимент при следующих условиях:

\begin{itemize}
  \item Длина тестовой выборки: 500
  \item Продолжительность обучения: 400 эпох
  \item Реализация управляющего воздействия: белый шум с параметрами
        $\{0,1\}$
  \itemРеализация помехи: белый шум с параметрами $\{0,0.1\}$
\end{itemize}

В процессе эксперимента будем обучать НС--О заданной архитектуры с
помощью ряда $(u_k, y_k)$ заданной длины, при этом обучение
контролируется по завершении каждой эпохи на тестовой выборке
фиксированной длины.  Эта длина выбрана заведомо больше необходимой
для проверки модели типа АРСС если бы оценка параметров процесса
проводилась бы линейными методами анализа временных рядов.

Длина обучающей выборки, напротив, выбиралась от самых малых значений
до длины тестовой выборки.  Эксперимент проводился для следующих длин
выборок: 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 60, 70, 80, 90,
100, 250, 300, 400, 500.  При каждой длине выборки проводилось 5
сессий обучения по различным реализациям обучающей выборки.

Результаты эксперимента для трех нейросетевых архитектур приводятся на
\figref{fig:length_influence_nnp}.  Графики наглядно демонстрируют
следующие зависимости:

\begin{enumerate}

  \item Начиная с некоторого порога, зависящего от сложности
        архитектуры НС--О, процесс обучения становится монотонным, что
        позволяет при обучающей выборке фиксированной длины добиваться
        уменьшения СО путем увеличения продолжительности обучения.

  \item Увеличение длины обучающей выборки ускоряет процесс обучения.

\end{enumerate}


{\bf графики}

%\begin{figure}
%\centerline{\hbox{\psfig{figure=T6_mse_1+3_1_n50.eps,width=0.7\textwidth}}}
%\caption{График}\label{fig:T6}
%\end{figure}



\subsubsection{Следствия неавтономности нейросетевой модели}

Неавтономность используемой нейросетевой модели объекта управления
является важной особенностью предлагаемого метода, поскольку из не\"е
следуют серьезные ограничения при работе с реальным объектом
управления:

\begin{enumerate}

  \item\label{stability-cond} В процессе настройки нейросетевого
  регулятора должна обеспечиваться устойчивость замкнутого контура САУ
  и объекта управления (если он в разомкнутом состоянии неустойчив).

  \item\label{force-limits} Величины управляющих воздействий не должны
  превышать пределов, накладываемых конструктивными особенностями
  исполняющих органов.

  \item\label{real-time} Время обучения нейросетевого регулятора
  становится реальным, то есть, квант времени алгоритма обучения
  оказывается связан с физическим временем системы управления.

\end{enumerate}

Ограничение \ref{stability-cond} на начальных порах настройки НС--Р в
замкнутом контуре должно обеспечиваться с помощью выбора подходящего
начального приближения.  Наиболее очевидный вариант выбора описан в
разделе \ref{init-approach}.  Поддержание устойчивости в процессе
дообучения НС--Р с помощью инверсной нейросетевой модели должно быть
организовано {\bf специальной процедурой, описанной в ????}

%, отключающей НС--Р от управления объектом в

Для гарантированного выполнения ограничения \ref{force-limits}
предлагается пользоваться масштабированием выходных значений НС--Р в
желаемый диапазон, описанным в разделе \ref{nnarch}.

В том случае, когда существенно ограничение по времени обучения
квазиоптимального нейросетевого регулятора, предлагается осуществлять
настройку НС--Р вне контура управления по физической модели объекта
управления, используемой вместо него самого.


%Синтез нейросетевого регулятора состоит из трех этапов. Первый
%этап включает в себя предварительную настройку НС-Р, на втором
%этапе настраивается модель объекта (НС-О), на третьем этапе НС-Р
%осуществляется окончательная настройка НС-Р.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Особенности применения нейронных сетей}

Рассмотренная методика синтеза нейросетевого оптимального регулятора
целиком базируется на избранной архитектуре искусственных нейронных
сетей и градиентного метода их обучения.  Нейронная сеть как базовый
элемент методики выступает в качестве заместителя объекта управления и
регулятора.  При рассмотрении системы управления в линейном
приближении нейронная сеть заменяет цепочку линейных звеньев, будь то
модель объекта или регулятора.  Искусственная нейронная сеть ---
объект существенно нелинейный, поэтому для предотвращения
нежелательных эффектов всегда следует анализировать результаты,
полученные с помощью ИНС.

Рассмотрим некоторые необычные свойства искусственных нейронных сетей,
проявляющиеся в процессе построения НОР.

\subsubsection{Область определения функции нейронной сети}

Обученная нейросеть реализует некоторую желаемую функцию, заданную при
обучении таблично.  Табличный способ подразумевает ограниченность
значений как аргумента, так и функции в некоторых диапазонах.  В том
случае, когда область определения желаемой функции шире диапазона
аргументов, используемых при обучении, правильнее говорить об обучении
нейросети некоторой ограниченной на обучающем множестве функции.
Существенно, что нейросеть при обучении не имеет информации о
поведении исходной (``неограниченной'') функции за пределами
обучающего множества.  Поэтому поведение нейросетевой аппроксимации за
пределами обучающего множества может сколь угодно сильно отличаться от
желаемого оригинала.  Кратко, нейронная сеть является хорошим
интерполятором, но плохим аппроксиматором.

Данное свойство ограниченности области определения сильно отличает
нейронные сети от объектов линейной теории управления и, казалось бы,
существенно сужает их применимость.  Однако объекты реального мира
всегда имеют ограничения, связанные со своей природой.  Сигналы,
поступающие с датчиков, уставки и прочие потоки информации о системе
управления, всегда имеют некоторый рабочий диапазон значений.
Известны также пределы их внештатного поведения.  Исходя из информации
об ограничивающих диапазонах инженер всегда может так настроить
нейросеть и алгоритм ее обучения, что обучающее множество охватит
область значений, необходимую для корректного функционирования НС в
реальной системе управления.

\paragraph{Синтез нейросетевой модели объекта управления}
% ~/nn/CheckNNP

Рассмотрим пример влияния диапазона обучающего множества на качество
нейросетевой модели объекта управления.  По методике для синтеза НС--О
следует взять ряд значений управляющего воздействия и наблюдаемой
реакции объекта управления в дискретные моменты времени.  Далее,
используя эти временные ряды в качестве обучающего множества,
настраиваем нейронную сеть до получения удовлетворительного качества
предсказания.  После чего на независимой выборке проверим качество
обучения.

Моделью объекта управления служила дискретная передаточная функция
$G(z)=\frac{0.5z^2}{z^2-0.7}$.  Нейросетевая модель объекта управления
имела архитектуру $\mathcal{N}_{1+1,8,3,1}(u_k, y_k)$ с линейной
функцией активации последнего слоя и с масштабированием входов
$(-3,3)\to(-1,1)$ и выхода $(-1,1)\to(-15,15)$.

\begin{figure}[h]
\centerline{\hbox{\psfig{figure=nnp_bad_range_learn.ps,%
angle=270,width=0.8\textwidth,height=0.3\textheight}}}
\centerline{а)}
\centerline{\hbox{\psfig{figure=nnp_bad_range_test.ps,%
angle=270,width=0.8\textwidth,height=0.3\textheight}}}
\centerline{б)}
\caption{Неправильно выбранное обучающее множество.  Графики аппроксимации
         выхода объекта на обучающей (а) и контрольной траектории (б).}
\label{fig:nnp_bad_range}
\end{figure}

Рассмотрим пример неправильного выбора обучающего множества.
Траектория с наблюдаемого выхода объекта и с обученной нейросетевой
модели изображены на \figref{fig:nnp_bad_range}а.  Диапазон
предсказываемых нейросетью значений на обучающем множестве ограничен
горизонтальными линиями $4.9$ и $-6.3$.  Представим ситуацию в которой
наблюдаемые на выходе объекта управления значения могут лежать в более
широком диапазоне.  Траектория, охватывающая более широкий диапазон
значений, изображена на \figref{fig:nnp_bad_range}б.  Здесь же
приводится траектория предсказания выхода объекта нейросетевой
моделью.  Видим, что на участках выхода траектории объекта за
известный для НС--О диапазон качество предсказания значительно
ухудшается.

\begin{figure}[h]
\centerline{\hbox{\psfig{figure=nnp_good_range_learn.ps,%
angle=270,width=0.8\textwidth,height=0.3\textheight}}}
\centerline{а)}
\centerline{\hbox{\psfig{figure=nnp_good_range_test.ps,%
angle=270,width=0.8\textwidth,height=0.3\textheight}}}
\centerline{б)}
\caption{Правильно выбранное обучающее множество.  Графики аппроксимации
         выхода объекта на обучающей (а) и контрольной траектории (б).}
\label{fig:nnp_good_range}
\end{figure}

Теперь возьмем в качестве обучающего множества выборку, охватывающую
больший диапазон значений.  Результат обучения по ней приводится на
\figref{fig:nnp_good_range}а.  В этом случае нейросеть охватывает
диапазон от $-12.6$ до $7.5$, что по предположению примерно совпадает
с рабочим диапазоном объекта управления.  Та же контрольная выборка в
этом случае будет предсказана с гораздо лучшим качеством
(\figref{fig:nnp_good_range}б), так как нейросетевой модели ``знаком''
весь диапазон значений на траектории.

В примерах анализировалась только траектория наблюдаемого выхода
объекта, в то время как траектория управляющего воздействия не
рассматривалась.  Однако подобный анализ на охват всего рабочего
диапазона значений надо проводить для всех видов временных рядов,
участвующих в обучении.

{\bf пример области определения НС--Р}


Однако метод обратного распространения во времени
(BPTT) не может быть реализован в физической системе, так как
использует концепцию обратного времени. {\bf ???}




\subsubsection{Требования к обучающей и контрольной выборкам}

По предлагаемой методике обучение нейросетевого имитатора объекта
управления должно осуществляться вне контура управления на выборке,
полученной экспериментальным путем.  Очевидно, временные ряды должны
нести достаточно информации для того, чтобы обучить нейросетевую
модель функционировать с приемлемым качеством.  Встает вопрос о
необходимых требованиях к обучающей и тестовой выборкам $\{u_k,
y_k\}_N$.

В общем случае, выбор идентифицирующего сигнала $u_k$, позволяющего
``изучить'' объект управления, во многом зависит от свойств самого
объекта, а также помехи, неизбежно присутствующей в любой реальной
системе.  Перечислим известные методы идентификации, применяемые к
простым односвязным объектам в линейном приближении.

\subbbsection{Идентификация в линейной теории управления}
Детерминистский подход в традиционной теории управления предлагает в
качестве пробных сигналов некоторые ``удобные'' формы, легко
реализуемые физически: гармонический сигнал и ступенчатое воздействие.

С точки зрения линейной теории автоматического управления
гармоническое воздействие позволяет исследовать поведение объекта
только на одной частоте.  Ступенька позволяет получить отклик объекта,
теоретически содержащий все частоты, то есть, исчерпывающе
характеризующий обследуемый объект.  В обоих случаях длина выборки,
содержащей всю полезную информацию, определяется инерционными
свойствами объекта.  Амплитуда (мощность) входного воздействия обычно
берется значительно больше уровня шумов, имеющихся в системе
управления.

Статистические методы исследования линейных систем базируются на
идентифицирующих свойствах случайных сигналов.  Идеальный пробный
сигнал --- белый шум --- на практике недостижим и не всегда применим
из-за физических ограничений на амплитуду возмущающего воздействия.
Обычно бывает достаточно сигнала с известным спектром.

Идентификация объекта управления основывается на коррелировании
входного и выходного сигналов.  Для повышения помехозащищенности
рекомендуется увеличивать длину выборки.  Повышение мощности входного
сигнала также способствует этой цели.

\subbbsection{Нейросетевая идентификация}
Очевидно, что перечисленные методы идентификации с чистом виде не
применимы к нейронным сетям.  Однако имеет смысл отталкиваться от
известных подходов с целью выработки новых.

С целью исследования применимости традиционных пробных сигналов при
обучении нейросетевой модели объекта были проведены многочисленные
имитационные эксперименты со ступенчатым, гармоническим и
стохастическим управляющим воздействием.  Обобщая полученный опыт,
можно сделать некоторые выводы качественного плана.

В качестве примера рассмотрим серию экспериментов с дискретным
объектом управления с передаточной функцией
$G(z)=\frac{0.5z^2}{z^2-0.7}$.  Была выбрана архитектура НС--О
$\mathcal{N}^o_{1+1,8,3,1}(u_k,y_k)$ с линейной функцией активации
последнего слоя и масштабированием $(-3,3)\to(-1,1)$ на входах и
$(-1,1)\to(-15,15)$ на выходе.


\begin{figure}[h]
\begin{tabular}{p{0.46\textwidth}p{0.46\textwidth}}
\psfig{figure=T7_learn_Kn+L_1+1_531.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T7_test_Kn+L_1+1_531.ps,angle=270,width=0.46\textwidth}\\[0pt]
\hfil а) Обучение; $D_y=1$\hfil & \hfil б) Проверка; $D_y=1$\hfil \\[16pt]
\psfig{figure=T7_learn_Kn+L_1+2_531.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T7_test_Kn+L_1+2_531.ps,angle=270,width=0.46\textwidth}\\[0pt]
\hfil в) Обучение; $D_y=2$\hfil & \hfil г) Проверка; $D_y=2$\hfil \\[16pt]
\psfig{figure=T7_learn_Kn+L_1+3_531.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T7_test_Kn+L_1+3_531.ps,angle=270,width=0.46\textwidth}\\[0pt]
\hfil д) Обучение; $D_y=3$\hfil & \hfil е) Проверка; $D_y=3$\hfil \\[16pt]
\end{tabular}
\caption{Зависимость качества предсказания от мощности помехи $K_n^2$
         и длины обучающей выборки $L$}
\label{fig:nnp_quality_KnL}
\end{figure}






% $Id: Otstoy2.tex,v 1.5 2001-12-15 13:56:58 vlad Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Синтез нейросетевого регулятора}\label{nncsynthesis}

Задача обучения нейросетевого регулятора (НС--Р), как уже отмечалось в
п.~\ref{nnplearning}, состоит из двух этапов: получения копии
действующего регулятора вне контура управления и дообучение
функционирующего нейросетевого регулятора в контуре с использованием
инверсной модели объекта.  Будем считать, что в контуре управления
функционирует какой-либо линейный регулятор, например, ПИД.

Сравнивая задачу построения НС--Р с задачей получения нейросетевой
модели объекта следует отметить два фундаментальный различия.
Во-первых, НС--О может быть реализована как в виде автономной модели
поведения, так и в виде зависимой от объекта модели предсказания, в то
время как НС--Р должен полностью заменить исходный регулятор.
Во-вторых, НС--О должна полностью копировать поведение объекта
управления, а НС--Р должен быть сначала обучен подобно исходному
линейному регулятору, но потом в процессе дообучения в контуре
управления может изменить свои свойства сообразно задаче минимизации
среднеквадратичной ошибки управления.

Очевидно, что реализовать нейросетевой регулятор по тем же принципам,
что и НС--О, не удасться.  Конечно, можно синтезировать автономную
нейросеть, функционирующую подобно исходному регулятору, а потом
дообучать ее.  Однако повторение свойств линейного регулятора не
является основной целью, а лишь предваряет ее, поэтому не имеет смысла
формировать архитектуру нейросетевого регулятора только исходя из
линейности исходного регулятора.

\subsubsection{Структура входов нейросети}

После первого этапа настройки нейросетевой регулятор должен
имитировать функционирование исходного ПИД-регулятора.  Любая из
разновидностей ПИД-регуляторов (кроме пропорционального) представляет
собой динамическую систему с памятью.  Как уже отмечалось
(п.~\ref{nnp_inputs}), имитация памяти требует введения обратных
связей.

Дифференциальная часть регулятора в дискретной форме
представляет собой 

Проанализируем возможность нейросетевой имитации ПИД закона
управления:

\begin{equation}\label{pid-continuous}
u(t)=K_P e(t)+K_I\int\limits_0^T e(t)dt+K_D\frac{de(t)}{dt}
\end{equation}

Первое слагаемое $K_P e(t)$ реализует пропорциональную зависимость
управления от ошибки в текущий момент времени.  Данная зависимость
легко реализуется нейронной сетью.

Второе слагаемое $K_I\int\limits_0^T e(t)dt$ усиливает управляющее
воздействие в случае наличия ошибки на протяжении некоторого времени.
Таким образом, память позволяет ускорить 

Третье слагаемое $K_D\frac{de(t)}{dt}$ определяет реакцию регулятора
на изменение ошибки.  В дискретном случае производная обычно
представляется разностью $\Delta e_k=e_k-e_{k-1}$.

Рассмотрим альтернативный способ реализации 

Из традиционной теории управления известны два способа реализации
регулирования: по возмущению и по отклонению.  В линейной ТАУ первый
способ в чистом виде практически не используется, так как в нем не
задействуется информация о фактическом состоянии объекта управления.
Неточность идентификации объекта управления, наличие неконтролируемых
возмущений и помех обычно приводят к неудовлетворительному качеству
управления по возмущению.  Нейросетевые регуляторы, основанные на этом
принципе (последовательная схема нейронного управления в обзоре
\cite{sigom00}), эксплуатируют возможность инверсии объекта
искусственной нейронной сетью после обучения.  Однако недостатки,
присущие принципу регулирования по возмущению остаются и в случае его
нейросетевой реализации.

Гораздо более распространено регулирование по отклонению.  В линейной
теории управления особое внимание уделяется специальному типу
регуляторов, которые реализуют суперпозицию пропорциональной,
дифференциальной или интегральной зависимости управляющего воздействия
от входной ошибки.  ПИД регуляторы широко используется в
промышленности, так как они позволяют решать задачи стабилизации и
слежения в хорошо линеаризуемых детерминированных линейных системах
управления.

\begin{equation}
u_k-u_{k-1}=\Delta u_k=K_P(e_k-e_{k-1})+K_I e_k+K_D(e_k-2e_{k-1}+e_{k-2})
\end{equation}


\begin{equation}\label{eq:reference}
R^*(z)=\displaystyle\frac{0.625z}{z-0.779}
\end{equation}

\begin{equation}\label{eq:noise}
N^*(z)=0.7
\end{equation}

\begin{equation}\label{eq:plant}
P^*(z)=\displaystyle\frac{z}{z-0.5}
\end{equation}

\begin{equation}\label{eq:contr-pid}
C_{PID}^*(z)=0.4 +
       0.5\displaystyle\frac{z}{z-1} +
       0.05\displaystyle\frac{z^2-2z+1}{z(z-1)}
\end{equation}

\begin{equation}\label{eq:contr-wiener}
C_W^*(z)=\displaystyle\frac{0.528z-0.264}{z-0.896}
\end{equation}


\subsubsection{Архитектура нейронной сети регулятора}
\subsubsection{Настройка нейросетевого регулятора}
\subbbsection{Предварительное обучение нейросети}
\subbbsection{Обучение нейросети в контуре управления}

\subsubsection{Влияние качества НС--О на скорость обучения НС--Р в контуре}


\begin{table}[ht]
\caption{Сравнение точности имитации ПИД регулятора вне контура при
         различном способе формирования входного вектора НС--Р
         ($N^*(z)=0.4$)}
\label{tabl:nnc_pretr_input_vec_N=0.4}
\begin{tabular}{|c|l|c|c|}
\hline
N пп. & Входной & \multicolumn{2}{|c|}{Финальное значение}\\
\cline{3-4}
 & вектор & СО обучения & СО контроля\\
\hline
1 & $e_k$ & 0.3403 & 0.3228 \\
2 & $e_k,e_{k-1}$ & 0.3131 & 0.2993 \\
3 & $e_k,e_{k-1},e_{k-2}$ & 0.2819 & 0.2709 \\
4 & $e_k,e_{k-1},e_{k-2},e_{k-3}$ & 0.2507 & 0.2482 \\
5 & $e_k,e_{k-1},e_{k-2},e_{k-3},e_{k-4}$ & 0.2428 & 0.2385 \\
6 & $e_k,\Delta e_k$ & 0.3120 & 0.2980 \\
7 & $e_k,r_k$ & 0.0375 & 0.0388 \\
\hline
\end{tabular}
\end{table}

Как видно из таблицы~\ref{tabl:nnc_pretr_input_vec_N=0.4} с
результатами эксперимента, увеличение емкости памяти прошлых входов
позволяет лишь незначительно уменьшить ошибку имитации (строки таблицы
1--5).  Вариант с первой разностью ошибки (строка 6) показал близкие
результаты с вариантом $e_k,e_{k-1}$ (строка 2).  Очевидно, что для
НС--Р эти варианты информационно эквивалентны.  Наилучшее качество
имитации исходного регулятора было достигнуто НС--Р с входным вектором
$e_k,r_k$, причем уровень ошибки в этом случае оказался меньше почти
на порядок, чем в остальных.

По результатам других экспериментов со стохастической уставкой было
обнаружено, что увеличение мощности помехи улучшает качество имитации
НС--Р с повторением прошлых входов и ухудшает качество имитации НС--Р
с управлением по возмущению и отклонению.  Результаты предварительного
синтеза НС--Р в аналогичных предыдущему эксперименту условиях, но с
мощностью помехи $N^*(z)=0.7$ приводятся в
таблице~\ref{tabl:nnc_pretr_input_vec_N=0.7}.

\begin{table}[ht]
\caption{Сравнение точности имитации ПИД регулятора вне контура при
         различном способе формирования входного вектора НС--Р
         ($N^*(z)=0.7$)}
\label{tabl:nnc_pretr_input_vec_N=0.7}
\begin{tabular}{|c|l|c|c|}
\hline
N пп. & Входной & \multicolumn{2}{|c|}{Финальное значение}\\
\cline{3-4}
 & вектор & СО обучения & СО контроля\\
\hline
1 & $e_k$ & 0.3117 & 0.2906 \\
2 & $e_k,e_{k-1}$ & 0.2946 & 0.2710 \\
3 & $e_k,e_{k-1},e_{k-2}$ & 0.2551 & 0.2459 \\
4 & $e_k,e_{k-1},e_{k-2},e_{k-3}$ & 0.2308 & 0.2284 \\
5 & $e_k,e_{k-1},e_{k-2},e_{k-3},e_{k-4}$ & 0.2133 & 0.2163 \\
6 & $e_k,\Delta e_k$ & 0.2935 & 0.2738 \\
7 & $e_k,r_k$ & 0.0712 & 0.0968 \\
\hline
\end{tabular}
\end{table}



По синусоиде


\begin{table}[ht]
\caption{ }
\begin{tabular}{|c|l|c|c|}
\hline
N пп. & Входной & \multicolumn{2}{|c|}{Финальное значение}\\
\cline{3-4}
 & вектор & СО обучения & СО контроля\\
\hline
1 & $e_k$ & 0.1269 & 0.1299 \\
2 & $e_k,e_{k-1}$ &  &  \\
3 & $e_k,e_{k-1},e_{k-2}$ &  &  \\
4 & $e_k,e_{k-1},e_{k-2},e_{k-3}$ &  &  \\
5 & $e_k,e_{k-1},e_{k-2},e_{k-3},e_{k-4}$ &  &  \\
6 & $e_k,\Delta e_k$ & 0.1251 & 0.1293 \\
7 & $e_k,r_k$ & 0.0032 & 0.0039 \\
\hline
\end{tabular}
\end{table}


По нулю


\begin{table}[ht]
\caption{ }
\begin{tabular}{|c|l|c|c|}
\hline
N пп. & Входной & \multicolumn{2}{|c|}{Финальное значение}\\
\cline{3-4}
 & вектор & СО обучения & СО контроля\\
\hline
1 & $e_k$ & 0.0023 & 0.0027 \\
2 & $e_k,e_{k-1}$ &  &  \\
3 & $e_k,e_{k-1},e_{k-2}$ &  &  \\
4 & $e_k,e_{k-1},e_{k-2},e_{k-3}$ &  &  \\
5 & $e_k,e_{k-1},e_{k-2},e_{k-3},e_{k-4}$ &  &  \\
6 & $e_k,\Delta e_k$ & 0.0017 & 0.0023 \\
7 & $e_k,r_k$ & 0.0031 & 0.0040 \\
\hline
\end{tabular}
\end{table}
