\section{Введение}



В реальных системах управления полезный сигнал всегда искажен
помехой.  В рамках классической теории автоматического управления
помехой пренебрегают, рассматривая идеализированную систему.
Данный подход применяется как для задач идентификации, так и для
задач синтеза.  Кратко отметим особенности детерминистского
подхода.


Задачи данного класса могут возникать в самых разных практически
эксплуатируемых системах управления. К их специфике относятся:

\begin{itemize}
  \item Невозможность проводить эксперименты, допустимые на
  моделях.
  \item В силу постоянной эксплуатации объекта управления
  невозможно отключить регулятор на время или вставить регулятор с
  некорректно настроенными
  \item За время эксплуатации параметры объекта могли существенно
  ``уйти'' от расчетных, поэтому нужна идентификация.
\end{itemize}

Задача синтеза линейного регулятора в схожих условиях
рассматривалась в рамках стохастической линейной теории управления
Винером и Калманом.  К недостаткам разработанных ими методов
следует причислить неробастность (неустойчивость) в условиях,
отличных от модельных.  Известны способы построения нейросетевых
регуляторов в различных условиях. Однако в целом задача синтеза
нейросетевого регулятора в практических условиях

в стохастической постановке нейросетевые регуляторы никто не делал



В реальных системах управления полезный сигнал всегда искажен
помехой.  В рамках классической теории автоматического управления
помехой пренебрегают, рассматривая идеализированную систему.
Данный подход применяется как для задач идентификации, так и для
задач синтеза.  Кратко отметим особенности детерминистского
подхода.

В задачах идентификации

Из самых общих представлений очевидно, что проектирование системы
управления для идеализированных условий приводит к потере качества
при реальной эксплуатации.

Изложение метода с двумя примерами: физически реализуемым и
физически нереализуемым управлением.

%\begin{equation}
%\left\{\begin{array}{rcl}
%  x(t+1) & = & A x(t) + B u(t) + w(t) \\
%  y(t) & = & C x(t) + v(t)
%\end{array}\right.
%\end{equation}


%\begin{equation}
%\left\{\begin{array}{rcl}
%  x(t+1) & = & A x(t) + B u(t) + w(t) \\
%  y(t) & = & C x(t) + v(t)
%\end{array}\right.
%\end{equation}
%
%\begin{equation}
%  u(t) = - L \hat{x}(t)
%\end{equation}
%
%\begin{equation}
%  y(t) \equiv x(t)\quad\Rightarrow\quad\hat{x}(t) = y(t)
%\end{equation}
%
%\begin{equation}
%  \hat{x} = K(t) y(t),\quad P(0) = \mathop{\rm cov} x(0)
%\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Традиционным способом настройки параметров искусственной нейронной
сети является обучение.  Обучением НС называется итерационный
процесс изменения параметров сети с целью оптимизации заданного
функционала.  В рассматриваемой постановке функционал является
квадратичной формой по обучающей выборке.

\begin{figure}[h]
  \centering
  \input genctrlp.lp
  \caption{Объект управления.}
  \label{fig:genctrlp}
\end{figure}

Основной задачей, возникающей при синтезе НС-Р является получение

Настройка коэффициентов нейросети производится на некотором
конечном множестве обучающих пар.  Между точками нейросеть
выполняет интерполяцию. Представим каждую пару точкой в
пространстве подходящей размерности.  Известно, что нейросети
являются хорошими интерполяторами, но плохими аппроксиматорами.
Поэтому логично ввести понятие {\em области определения
нейросети,} охватывающей все точки обучающего множества.  За
пределами этой области поведение нейросети может сколь угодно
сильно отличаться от ожидаемого.

В рассматриваемом примере обучающим множеством является пара

%Построение нейросетевой модели объекта производится на некотором
%конечном множестве обучающих пар.  Эти пары задают узловые точки,
%через которые проходит целевая функция обучения.  Нейросеть
%обучается проходить как можно ближе к этим точкам, но между ними
%еј поведение может значительно отличаться от целевой функции.  При
%достаточном количестве обучающих пар и ограниченном числе весовых
%коэффициентов (оптимизируемых параметров), реализуемая нейросетью
%функция будет достаточно хорошо повторять поведение целевой
%функции между узловыми точками.  Однако за пределами области, в
%которой группируются узловые точки, поведение функции
%$\mathcal{B}$ может сколь угодно сильно отличаться от ожидаемого.
%Назовем область, охватывающую множество обучающих точек, {\it
%областью определения нейросети.}

 Функция $\mathcal{B}^o$ для заданных $u_k$ и
$\hat{y}_{k+1}$ реализует инверсию объекта управления

Переменные $\hat{y}_{k+1}$ и $r_{k+1}$ входят в функцию
$\mathcal{B}^o$ в форме разности $\hat{e}_{k+1}=\hat{y}_{k+1} -
r_{k+1}$ (см.~\eqref{eq:deltaprop}).  Фактически, можно считать,
что область определения НС--О образуется множеством точек $(u_k,
\hat{e}_{k+1})$
 , то есть,
фактически При инверсии объекта управления заменяем $r_{k+1}$ на
$\tilde{y}_{k+1}$. Однако, если окажется, что разность
$\hat{y}_{k+1} - \tilde{y}_{k+1}$ выводит точку $(u_k,
\hat{y}_{k+1}, \tilde{y}_{k+1})$ за пределы области определения
$\mathcal{N}^o$, точность инверсии может оказаться очень плохой.
Данная ситуация произойдет

при плохом качестве предсказания выхода объекта управления уже
нельзя считать $y_{k+1} \approx \hat{y}_{k+1}$.  В этом случае ,
то есть,  выше определенного предела, качество инверсии резко
упадет.

Опущенные в~\eqref{eq:nno_y_to_u} аргументы в можно
интерпретировать как точку $(u_k, \hat{y}_{k+1})$, в которой
определена функция $\mathcal{B}^o: \tilde{y}_{k+1} \rightarrow
\tilde{u}_k$.  Смысл определения состоит в том, что если

Можно интерпретировать $\mathcal{B}^o$ как функцию, отображающую
фактическое управляющее воздействие в желаемое для достижения
требуемого выхода объекта $\tilde{y}_{k+1}$:

$$ \mathcal{B}^o: u_k \rightarrow \tilde{u}_k $$

Построение нейросетевой модели объекта производится на некотором
конечном множестве обучающих пар.  Эти пары задают узловые точки,
через которые проходит целевая функция обучения.  Нейросеть
обучается проходить как можно ближе к этим точкам, но между ними
еј поведение может значительно отличаться от целевой функции.  При
достаточном количестве обучающих пар и ограниченном числе весовых
коэффициентов (оптимизируемых параметров), реализуемая нейросетью
функция будет достаточно хорошо повторять поведение целевой
функции между узловыми точками.  Однако за пределами области, в
которой группируются узловые точки, поведение функции
$\mathcal{B}$ может сколь угодно сильно отличаться от ожидаемого.

Учитывая, что функция $\mathcal{B}^o$ зависит трех аргументов, от
значений

Обобщая свойства нейросетевой функции $\mathcal{B}^o$ можно
считать, что функция $\mathcal{B}^o: \tilde{y}(t) \rightarrow
\tilde{u}(t)$ определена в некоторой окрестности

Если считать  Зависимость функции $\mathcal{B}^o$ от значений
$u_k$ и $\hat{y}_{k+1}$ делает

Поэтому

 Поскольку $\mathcal{B}^o$ зависит от разности
$\hat{y}_{k+1} - r_{k+1}$ (см.~\eqref{eq:deltaprop}), при плохом
качестве предсказания выхода объекта управления уже нельзя считать
$y_{k+1} \approx \hat{y}_{k+1}$.  В этом случае , то есть,  выше
определенного предела, качество инверсии резко упадет.

Зависимость функции $\mathcal{B}^o$ от $u_k$ и $\hat{y}_{k+1}$
Таким образом, функция

С другой стороны, локальная инверсия объекта управления вблизи
$u_k$ и $\hat{y}_{k+1}$ расширяет возможности представления
нейросетью сложных объектов.  Можно показать, что для многозначной
функции из достаточно широкого класса  имеется возможность
построить кусочно--однозначную функцию.



Ненулевая ошибка управления вызвана (по условию отсутствия помех)
неоптимальным функционированием регулятора.  В силу
равенства~\eqref{eq:outputs} можем использовать $y_{k+1}$ вместо
$\hat{y}_{k+1}$ в~\eqref{eq:invobj} для вычисления требуемого
управляющего воздействия $u^*_k$ на предыдущем такте.



\subsection{Синтез нейросетевого регулятора в реальных условиях}

Описанный в разделе~\ref{nnplearning} метод обучения НС--Р
рассматривался в идеальных условиях отсутствия помех и абсолютно
идентично настроенной модели объекта управления.  Кроме того не
учитывался тот факт, что объект управления является динамической
системой обладающей состоянием, а значит выход объекта зависит не
только от управляющего воздействия, но и от состояния объекта
управления.

Не затрагивался также вопрос применения нейросетей в случае
многомерного объекта управления и нескольких каналов
регулирования.  В рамках рассматриваемой структуры САУ,
представленной на \figref{fig:ctrlloop} это не должно представлять
проблемы, так как нейронные сети изначально были предназначены для
решения многомерных задач.  Однако следует отметить, что в случае
невозможности непосредственного наблюдения состояния объекта
управления необходимо предусмотреть схему восстановления состояния
по наблюденным данным, такую как фильтр Калмана~\cite{bramziff82}.
Очевидно, в этом случае объект должен быть наблюдаем.

\subsubsection{Построение нейросетевой модели объекта управления}

Рассмотрим задачу построения нейросетевой модели одномерного
динамического объекта управления, описываемого некоторой
передаточной функцией.  В терминах пространства состояний объект
управления можно представить следующей системой разностных
уравнений:

\begin{equation}\label{eq:1d-ss}
\left\{\begin{array}{rcl}
  \mathbf{x}_{k+1} & = & F \mathbf{x}_k + G u_k \\
  y_k & = & H \mathbf{x}_k
\end{array}\right.
\end{equation} где $y_k$ и $u_k$ --- скаляры, а $\mathbf{x}$ --- вектор
состояния.

Статическая нейросеть, реализующая функцию
$\hat{y}_{k+1}=\mathcal{N}^o(u_k)$ принципиально не может решить
задачу имитации поведения объекта \eqref{eq:1d-ss}, так как
нейросеть не обладает состоянием: в любой момент выход нейронной
сети прямого распространения полностью определяется еј актуальными
входами и не зависит от предыдущих входов.

Информация о состоянии объекта может хранится в НС--О двумя
способами.  Первый из них связан с введением обратных связей в
нейронную сеть модели объекта управления~\cite{sigom00}. Второй
основан на нейросетевой модели АРСС.

\paragraph{Обратные связи в структуре НС--О}
Обратная связь рассматривается в качестве дополнительного входа
нейросети. НС--О функционирует в этом случае в соответствии с
уравнением

$$ \hat{y}_{k+1}=\mathcal{N}^o(u_k, \hat{y}_k) $$

Задержанный сигнал обратной связи $\hat{y}_k$ имеет смысл памяти
состояния.  Таким образом, нейросетевая модель объекта в этом
случае является полностью автономной системой.

Для обучения нейронных сетей в обратными связями используется
метод обратного распространения в времени ({\em backpropagation
through time --- BPTT})~\cite{gibb96}. Преимуществом данного
подхода является возможность настройки модели вне контура
управления.  К недостаткам метода обучения BPTT относится эффект
исчезающего градиента ({\em vanishing gradient}), проявляющийся в
том, что нейросеть выявляет короткие зависимости, но не может
научиться длинным в силу многократного ослабления информации о
зависимости в обратной связи~\cite{linetal}.

Применительно к задаче нейросетевой имитации объекта управления
проблема исчезающего градиента будет возникать в двух случаях:
\begin{itemize}
  \item значительное чистое запаздывание в динамике объекта
  управления;
  \item шаг квантования времени слишком мал по сравнению с
  характерным временем наступления установившегося режима.
\end{itemize}

\paragraph{Структура НС--О подобно модели АРСС}
Второй способ введения состояния основан на представлении объекта
в виде нейросетевой модели авторегрессии--скользящего среднего
(АРСС).  В этом случае нейронная сеть на каждом шаге воспроизводит
состояние объекта на основании запомненных на некотором интервале
наблюдений о состоянии объекта и управляющем воздействии:

$$ \hat{y}_{k+1}=\mathcal{N}^o(u_k, u_{k-1},\ldots,u_{k-D_u}, y_k,
y_{k-1},\ldots, y_{k-D_y}) $$

Как видно, нейросетевая модель опирается на информацию об
истинном, а не предсказанном на предыдущих шагах состоянии
объекта, как в случае с обратными связями.

Имеет место задача выбора интервала прошлых наблюдений,
используемых для построения модели.  Поскольку в рамках данной
главы рассматриваются стационарные линейные объекты управления,
для построения соответствующих дискретных моделей допустимо
применять соответствующие методы идентификации.  Поскольку этап
подгонки модели соответствует процессу обучения НС--О, для выбора
структуры входов нейросетевой модели достаточно воспользоваться
методами, основанными на построении выборочной взаимной
корреляционной функции, описанными в
литературе~\cite{ostrem73}\cite{boxjenk74}.

\subsubsection{Выбор начального приближения}

% Начальное приближение
Обучение нейросети методом обратного распространения подобно
градиентному методу оптимизации.  Как и в градиентных методах, при
обучении нейросетевого регулятора важен выбор начального
приближения. В качестве него можно использовать функцию,
реализуемую имеющимся регулятором.  Для этого по достаточно
длинной экспериментальной выборке, полученной на функционирующей
САУ с традиционным регулятором, нейросетевой регулятор может быть
обучен функционированию первого в режиме следования эталону.
Очевидно, в этом случае нейросетевой регулятор не даст улучшения
качества управления, однако полученная нейросеть станет первым
приближением в процедуре дальнейшего обучения.

Обучение начальному приближению может быть осуществлено вне
контура управления по временным рядам, полученным в процессе
штатного функционирования исходной системы управления.  Поскольку
вне контура управления можно не следовать достаточно жесткому
ограничению (см. требование~\ref{realcond} на
с.~\pageref{realcond}), в качестве начального состояния весовых
коэффициентов нейросети можно использовать любое из известных
эвристических правил~\cite{gibb96}.

После успешного обучения начальному приближению нейросетевой
регулятор может использоваться в контуре управления вместо
исходного.

\subsubsection{Дообучение нейрорегулятора}

% Окончательное обучение
Использование критерия минимизации среднеквадратичной ошибки
воспроизведения по обучающей выборке приводит к классическому
алгоритму обратного распространения ошибки.  Как видим, критерий
совпадает с общепринятым в линейной оптимальной теории управления.

Дообучение нейросетевого регулятора от начального приближения до
получения приемлемого улучшения качества управления осуществляется
с помощью предварительно настроенной нейросетевой модели.  В
процессе обучения регулятора модель выдает на выходе предсказанное
измеряемое состояние объекта управления.  В случае идеально
настроенной модели и при отсутствии шумов выход объекта и модели
должны совпадать. Пусть выход объекта отличается от уставки, что
дает некоторую ненулевую мгновенную ошибку управления.  Эта ошибка
является следствием неоптимальной настройки регулятора.  Для
получения оценки ошибки управляющего воздействия на входе объекта
подадим ошибку управления на выход модели и распространим еј в
обратном направлении к входу.  В отличие от процедуры обучения
нейросети, при обратном распространении не следует корректировать
весовые коэффициенты нейросетевой модели, так как известно, что
ошибка является следствием действия регулятора.  Приведенная к
входу модели (и объекта) ошибка является оценкой ошибки
управляющего воздействия регулятора.  Складывая еј с актуальным
выходом регулятора получаем эталонное управляющее воздействие.
Если бы оно было подано на вход объекта вместо актуального, то
выход модели не отличался бы от уставки.  При идеальном
соответствии модели и объекта ошибка управления также была бы
равна равна нулю.

В реальности всегда имеются случайные помехи.  Кроме того,
практически невозможно обучить нейросеть функционировать абсолютно
адекватно некоторой функции, к тому же, заданной таблично.  Однако
при хорошей настройке нейросетевой модели, ошибку предсказания
выхода объекта можно считать белым шумом. Таким образом,
изложенный алгоритм получения ошибки управляющего воздействия по
ошибке управления статистически будет работать.

\subsubsection{Помехи и возмущающие воздействия}

Как уже отмечалось, помеха, присутствующая в обучающей выборке для
нейросети не только не мешает обучению, но даже способствует
лучшей обобщающей способности сети.  В этом случае алгоритм
обучения ищет взаимосвязь между входом и выходом, статистически
обобщая на еј выборке.  Критерий обучения (минимум средней
квадратичной ошибки на выборке) аналогичен используемому в
гауссовском методе наименьших квадратов.  Он традиционно
используется в стохастической теории управления для фильтрации
белого шума.

\subsubsection{Начальное состояние весовых коэффициентов НС--О}

Известно, что процесс настройки нейронной сети аналогичен градиентному
методу оптимизации.  В том случае, если оптимизируемый функционал
имеет сложную поверхность с локальными минимумами, успех отыскания
глобального с помощью градиентного спуска зависит от выбора начальной
точки.  Если точка выбрана ``неправильно'', то классический
градиентный метод привед\"ет в локальный минимум.  Выбор начальной
точки также сказывается на скорости сходимости.

%Пространство настраиваемых параметров в случае с обучением нейронной
%сети образуется весовыми коэффициентами нейронов.  Оптимизируемый
%функционал включает в себя данные обучающей выборки.  Вид функционала
%определяется архитектурой нейронной сети.

В случае с обучением нейросетевой модели объекта управления
пространство настраиваемых параметров образуется весовыми
коэффициентами нейронов.  Традиционно их начальное значение задается
случайным с равномерным распределением в окрестности нуля.
Представляется важным выяснить чувствительность процедуры обучения
НС--О к выбору начальной точки.  Поскольку оптимизируемый функционал
включает в себя данные обучающей выборки, а его вид определяется
архитектурой нейронной сети, исследование целесообразно провести для
различных реализаций обучающих данных и различных архитектур сети.

\paragraph{Эксперимент T5}

Для выяснения зависимости сходимости алгоритма обучения от выбора
начальной точки был проведен вычислительный эксперимент, в рамках
которого при заданной обучающей выборке и архитектуре нейросети
варьировались начальные значения весовых коэффициентов.

Были зафиксированы:

\begin{itemize}
  \item Объект управления: $G(z)=\frac{0.25z}{z-0.75}$
  \item Помеха: белый шум с параметрами $\{0, 0.1\}$
  \item Регулирующее воздействие: белый шум с параметрами $\{0, 1\}$
  \item Длина обучающей выборки: 250
  \item Длина тестовой выборки: 500
  \item Число и номенклатура входов нейронной сети:
  $\mathcal{N}^o(u_k, y_k, y_{k-1}, y_{k-2})$
\end{itemize}

В ходе эксперимента проводились сеансы обучения НС--О с различными
случайно выбранными в диапазоне $-\Delta, \Delta$ начальными
значениями весовых коэффициентов.  Для каждого значения $\Delta$
проводилось 10 сеансов обучения.  Были проведены серии сеансов
обучения со значениями $\Delta$: 0.05, 0.1, 0.2, 0.3, 0.4, 0.5.

В эксперименте участвовали нейронные сети с различной внутренней
архитектурой, а именно, однослойная $\mathcal{N}^o_{1+3,1}$,
двухслойная $\mathcal{N}^o_{1+3,4,1}$, трехслойная
$\mathcal{N}^o_{1+3,7,4,1}$.  Длительность сеанса обучения была
выбрана равной 400 эпохам.

В эксперименте исследовалось поведение траектории среднеквадратичной
ошибки на тестовой выборке.  Обучение прекращалось в том случае, если
СО на тестовой выборке начинала возрастать.  В этом случае траектория
выбывала из расчета средней на завершающем участе.  По сумме 10
сеансов обучения рассчитывалась средняя траектория и траектория
выборочного среднеквадратического отклонения.  Результаты
экспериментов в численной форме приведены в таблице \ref{tabl:T5}.

\begin{table}[ht]
\caption{Чувствительность процедуры обучения НС--О к выбору начальной
         точки в пространстве весовых коэффициентов}\label{tabl:T5}
\begin{tabular}{|l|l|c|c|c|c|c|}
\hline
НС--О & $\Delta$ &
\multicolumn{2}{|c|}{среднее $\SE$} &
\multicolumn{2}{|c|}{отклонение $\SE$} & Выбыло \\
\cline{3-6}
 & & $t=0$ & $t=400$ & $t=0$ & $t=400$ & \\
\hline
 & 0.05 & 0.9508 & 0.0510 & 0.0991 & 0.0044 & 0 \\
 & 0.1  & 0.9842 & 0.0497 & 0.3030 & 0.0053 & 0 \\
$\mathcal{N}^o_{1+3,1}$
 & 0.2  & 1.3027 & 0.0569 & 0.4749 & 0.0126 & 0 \\
 & 0.3  & 1.3617 & 0.0572 & 0.6595 & 0.0133 & 0 \\
 & 0.4  & 1.9263 & 0.0458 & 1.0056 & 0.0149 & 0 \\
 & 0.5  & 2.2544 & 0.0622 & 1.4277 & 0.0262 & 0 \\
\hline
 & 0.05 & 1.0013 & 1.0074 & 0.0082 & 0 & 9 \\
 & 0.1  & 1.0325 & 0.0712 & 0.0314 & 0.0076 & 6 \\
$\mathcal{N}^o_{1+3,4,1}}$
 & 0.2  & 1.0987 & 0.0687 & 0.1047 & 0.0089 & 0 \\
 & 0.3  & 1.2854 & 0.0681 & 0.2345 & 0.0129 & 0 \\
 & 0.4  & 1.2554 & 0.0598 & 0.2631 & 0.0229 & 0 \\
 & 0.5  & 1.6581 & 0.0804 & 0.6398 & 0.0213 & 0 \\
\hline
 & 0.05 & 0.9997 & 1.0261 & 0.0078 & 0 & 9 \\
 & 0.1  & 1.0106 & 1.0290 & 0.0162 & 0 & 9 \\
$\mathcal{N}^o_{1+3,7,4,1}$
 & 0.2  & 1.0705 & 1.0375 & 0.0461 & 0 & 9 \\
 & 0.3  & 1.2134 & 0.0947 & 0.2154 & 0.0048 & 6 \\
 & 0.4  & 1.2788 & 0.0981 & 0.2218 & 0.0207 & 6 \\
 & 0.5  & 1.7474 & 0.0823 & 0.7961 & 0.0550 & 6 \\
\hline
\end{tabular}
\end{table}

Результаты эксперимента можно обобщить в следующих зависимостях.

Во-первых, больший диапазон разброса значений начальных весов в
среднем приводит к более хорошим результатам в обучении.

Во-вторых, ограничение диапазона распределения начальных весов может
привести к проблеме переобучения НС, то есть, уменьшение СО на
обучающей выборке сопровождается увеличением СО на тестовой.  Это
явление зависит от сложности архитектуры сети.  В частности, оно
совсем не наблюдалось на однослойной сети, на двухслойной сети оно
имело место при $\Delta=0.05$ и $\Delta=0.1$, на трехслойной сети
переобучение наблюдалось при всех значениях $\Delta$.

\begin{figure}
\begin{tabular}{cc}
\vbox{%
\hbox{\psfig{figure=T5_mse_mean_1+3_1.ps,angle=270,width=0.46\textwidth}}
\hbox to 0.46\textwidth{\hfil а) средняя траектория СО\hfil}}&
\vbox{%
\hbox{\psfig{figure=T5_mse_stddev_1+3_1.ps,angle=270,width=0.46\textwidth}}
\hbox to 0.46\textwidth{\hfil б) разброс траекторий СО\hfil}}
\end{tabular}
\caption{Графики обучения $\mathcal{N}^o_{1+3,1}$ при разных величинах
         начального разброса весовых коэффициентов НС}\label{fig:T5-1+3_1}
\end{figure}

\begin{figure}
\centerline{\hbox{%
\psfig{figure=T5_mse_mean_1+3_1.ps,angle=270,height=8cm,width=1\textwidth}}}
\caption{Графики средних траекторий СО при обучении $\mathcal{N}^o_{1+3,1}$
         при разных величинах начального разброса весовых коэффициентов НС}
\label{fig:T5mean-1+3_1}
\end{figure}

\begin{figure}
\centerline{\hbox{%
\psfig{figure=T5_mse_mean_1+3_41.ps,angle=270,height=8cm,width=1\textwidth}}}
\caption{Графики средних траекторий СО при обучении $\mathcal{N}^o_{1+3,4,1}$
         при разных величинах начального разброса весовых коэффициентов НС}
\label{fig:T5mean-1+3_41}
\end{figure}

\begin{figure}
\centerline{\hbox{%
\psfig{figure=T5_mse_mean_1+3_731.ps,angle=270,height=8cm,width=1\textwidth}}}
\caption{Графики средних траекторий СО при обучении $\mathcal{N}^o_{1+3,7,3,1}$
         при разных величинах начального разброса весовых коэффициентов НС}
\label{fig:T5mean-1+3_731}
\end{figure}

%\begin{figure}
%\centerline{\hbox{%
%\psfig{figure=T5_mse_stddev_1+3_41.ps,angle=270,width=1\textwidth}}}
%\caption{Графики обучения $\mathcal{N}^o_{1+3,4,1}$ при разных величинах
%         начального разброса весовых коэффициентов НС}\label{fig:T5stddev-1+3_41}
%\end{figure}

% Были проведены численные эксперименты с 

%% показать, что поверхность достаточно гладкая или найти проблемы

\subsubsection{Структура и число входов НС--О}

Поскольку в рамках данной главы рассматриваются стационарные линейные
объекты управления, предлагается методика расчета числа входов
нейросетевой модели, основанная на предположении о линейности объекта.

%Это не означает, что рассматриваемый метод ограничен сугубо линейным

Линейный объект управления полностью характеризуется имульсной
переходной характеристикой.  Пример отклика приведен на
\figref{step-response}.  Времена $T_{delay}$ и $T_{perehod}$
характеризуют чистое запаздывание и длительность переходного процесса.

Выбор числа входов для НС--О должен делаться на основе свойства
отсутствия памяти состояния в нейросети.  Поэтому нейросеть должна
быть обеспечена всей необходимой информацией для имитации объекта.

В случае наличия в объекте чистого запаздывания информация о
воздействии, породившем отклик объекта, должна иметься у нейронной
сети к моменту появления этого отклика на выходе объекта.  То есть,
достаточное число повторов управляющего воздействия на входе НС--О
должно быть не больше $1+T_{delay}/\Delta T$, где $\Delta T$ --- шаг
квантования времени в системе.

Переходный процесс является характерным проявлением динамических
свойств объекта управления.  Время его завершения является мерой
инерционности объекта и оно должно имитироваться нейросетевой моделью.
Для описания инерционности объекта статической нейросетью требуется не
больше чем $1+T_{perehod}/\Delta T$ повторений прошлых состояний
объекта управления.

Таким образом, получены верхние оценки необходимого числа входов для
нейросетевой модели объекта управления:

\begin{equation}\label{eq:nnp-inputs-number}
\begin{array}{rcl}
  D_u & = & T_{delay}/\Delta T \\
  D_y & = & T_{perehod}/\Delta T
\end{array}
\end{equation}

%Поскольку
%этап подгонки модели соответствует процессу обучения НС--О, для выбора
%структуры входов нейросетевой модели достаточно воспользоваться
%методами, основанными на построении выборочной взаимной корреляционной
%функции, описанными в литературе~\cite{ostrem73}\cite{boxjenk74}.


\subsubsection{Влияние выбора начальной точки в пространстве весовых
               коэффициентов}

Известно, что процесс настройки нейронной сети аналогичен градиентному
методу оптимизации.  В том случае, если оптимизируемый функционал
имеет сложную поверхность с локальными минимумами, успех отыскания
глобального с помощью градиентного спуска зависит от выбора начальной
точки.  Если точка выбрана ``неправильно'', то классический
градиентный метод привед\"ет в локальный минимум.  Выбор начальной
точки также сказывается на скорости сходимости.

В случае с обучением нейросетевой модели объекта управления
пространство настраиваемых параметров образуется весовыми
коэффициентами нейронов.  Традиционно их начальное значение задается
случайно с равномерным распределением в окрестности нуля.
Представляется важным выяснить чувствительность процедуры обучения
НС--О к выбору начальной точки.  Поскольку оптимизируемый функционал
включает в себя данные обучающей выборки, а его вид определяется
архитектурой нейронной сети, исследование целесообразно провести для
различных реализаций обучающих данных и различных архитектур сети.

Для выяснения зависимости сходимости алгоритма обучения от выбора
начальной точки был проведен вычислительный эксперимент, в рамках
которого при заданной обучающей выборке и архитектуре нейросети
варьировались начальные значения весовых коэффициентов.

Были зафиксированы:

\begin{itemize}
  \item Объект управления: $G(z)=\frac{0.25z}{z-0.75}$
  \item Помеха: белый шум с параметрами $\{0, 0.1\}$
  \item Регулирующее воздействие: белый шум с параметрами $\{0, 1\}$
  \item Длина обучающей выборки: 250
  \item Длина тестовой выборки: 500
  \item Число и номенклатура входов нейронной сети:
  $\mathcal{N}^o(u_k, y_k, y_{k-1}, y_{k-2})$
\end{itemize}

В ходе эксперимента проводились сеансы обучения НС--О с различными
случайно выбранными в диапазоне $(-\Delta, \Delta)$ начальными
значениями весовых коэффициентов.  Для каждого значения $\Delta$
проводилось 10 сеансов обучения.  Были проведены серии сеансов
обучения со значениями $\Delta$: 0.05, 0.1, 0.2, 0.3, 0.4, 0.5.

В эксперименте участвовали нейронные сети с различной внутренней
архитектурой, а именно, однослойная $\mathcal{N}^o_{1+3,1}$,
двухслойная $\mathcal{N}^o_{1+3,4,1}$, трехслойная
$\mathcal{N}^o_{1+3,7,4,1}$.  Длительность сеанса обучения была
выбрана равной 400 эпохам.

В эксперименте исследовалось поведение траектории среднеквадратичной
ошибки в процессе обучения на тестовой выборке, причем в качестве
объекта измерения были взяты СО в начальный и конечный момент времени.
Для каждой архитектуры нейросети и значения $\Delta$ по результатам 10
сеансов обучения определялось среднее значение СО и разброс (среднее
квадратическое отклонение).  Если СО на тестовой выборке начинала
возрастать, то сеанс обучения прекращался и траектория выбывала из
финального расчета для конечного момента времени.

Результаты эксперимента представлены на \figref{fig:initial-weights} в
виде графиков, причем диаграммы (а) и (б) демонстрируют зависимость
среднего значения СО от диапазона разброса весов в начальный и
конечный моменты времени, а (в) и (г) демонстрируют зависимость
среднеквадратического отклонения СО соответственно.

\begin{figure}
\begin{tabular}{p{0.46\textwidth}p{0.46\textwidth}}
\psfig{figure=T5_mse_mean_t0.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T5_mse_mean_t400.ps,angle=270,width=0.46\textwidth}\\[0pt]
а) среднее значение СО в начале обучения &
б) среднее значение СО в конце обучения\\[16pt]
\psfig{figure=T5_mse_stddev_t0.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T5_mse_stddev_t400.ps,angle=270,width=0.46\textwidth}\\[0pt]
в) разброс СО в начале обучения &
г) разброс СО в конце обучения\\[16pt]
\end{tabular}
\caption{Чувствительность процедуры обучения НС--О к выбору начальной
         точки в пространстве весовых коэффициентов}\label{fig:initial-weights}
\end{figure}

Результаты эксперимента дают основание следующим обобщениям:

\begin{enumerate}
  \item Б\'ольший диапазон разброса значений начальных весов в среднем
        приводит к более хорошим результатам в обучении независимо от
        сложности архитектуры нейросети.  Однако для сложных
        архитектур это приводит к относительно б\'ольшему разбросу
        результатов обучения.
  \item Ограничение диапазона распределения начальных весов может
        привести к проблеме переобучения НС, то есть, уменьшение СО на
        обучающей выборке сопровождается увеличением СО на тестовой.
        Это явление зависит от сложности архитектуры сети.  В
        частности, оно совсем не наблюдалось на однослойной сети, на
        двухслойной сети оно имело место при $\Delta=0.05$ и
        $\Delta=0.1$, на трехслойной сети переобучение наблюдалось при
        всех значениях $\Delta$.
\end{enumerate}
