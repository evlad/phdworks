% $Id: Part2_NNP.tex,v 1.1 2001-11-04 15:03:55 vlad Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Синтез нейросетевой модели объекта управления}\label{nnpsynthesis}

При построении нейросетевой модели реального объекта управления
возникает задача конкретизации архитектуры нейросети и условий её
настройки.  Очевидно, этот этап синтеза нейрорегулятора существенно
зависит от многих факторов: объекта управления, свойств помехи, длины
и прочих свойств имеющихся экспериментальных выборок.  Исследование
этих зависимостей представляет существенный интерес и должно послужить
более ясному представлению о применимости нейросетей в системах
управления.

Нейросетевая модель играет важную роль в обучении НС--Р: она работает
в качестве вычислителя якобиана объекта управления.  Известно, что для
целенаправленного синтеза нейросетевого регулятора достаточно знать
знак якобиана~\cite[с.94]{sigom00}~\cite{wangbao00}; при этом
сходимость алгоритма обучения существенно замедляется.  Однако в
сложных случаях (нестационарный или существенно нелинейный объект)
получить оценку знака якобиана непросто, а ошибка в знаке может
привести к неадекватному управлению и потере устойчивости в
контуре~\cite{wangbao00}.  Учитывая стратегическую важность НС--О,
следует достаточно подробно рассмотреть ее архитектуру, методику
синтеза и особенности функционирования.

\subsubsection{Структура входов нейросети}\label{nnp_inputs}

Как уже отмечалось, выбранная базовая архитектура нейронной сети
не обладает свойством сохранения состояния, а потому нейросеть,
реализующая зависимость $\hat{y}_{k+1}=\mathcal{N}^o(u_k)$
непосредственно не позволит создавать модели, адекватные
динамическим объектам.

Рассмотрим задачу построения нейросетевой модели некоторого
одномерного линейного динамического объекта управления.  В
дискретном времени в терминах пространства состояний объект
управления можно представить следующей системой разностных
уравнений:
\begin{equation}\label{eq:1d-ss}
\left\{\begin{array}{rcl}
  \mathbf{x}_{k+1} & = & F \mathbf{x}_k + G u_k \\
  y_k & = & H \mathbf{x}_k
\end{array}\right.
\end{equation} где $y_k$ и $u_k$ --- скаляры, а $\mathbf{x}$ --- вектор
состояния.

Статическая нейросеть описанной в разделе~\ref{nnarch} архитектуры,
реализующая функцию $\hat{y}_{k+1} = \mathcal{N}^o(u_k)$,
принципиально не может решить задачу имитации поведения динамического
объекта \eqref{eq:1d-ss}, так как нейросеть не обладает памятью: в
любой момент выход нейронной сети прямого распространения полностью
определяется е\"е актуальными входами и не зависит от состояния
нейросети в предыдущие моменты времени, а также от прошлых входов.

Для построения адекватной динамической модели следует снабдить
нейросеть информацией о прошлых состояниях.  Можно предложить
несколько способов решения этой проблемы.  Наиболее очевидный способ
состоит в добавлении внешних обратных связей к базовой нейросети.
Другой вариант предполагает непосредственное повторение нескольких
прошлых наблюдений с целью ``напомнить'' нейросети о состоянии
моделируемого объекта в предыдущие моменты времени.  Третьим вариантом
является подход, объединяющий два предыдущих.

\subbbsection{Внешние обратные связи}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:nnp-feedback}
% Рисунок с обратной связью %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Нейросетевая модель объекта в рамках данного подхода оснащается
дополнительным входом, на который подается выход модели,
полученный в предыдущий момент времени:
$$ \hat{y}_{k+1}=\mathcal{N}^o(u_k, \hat{y}_k) $$

Задержанный сигнал обратной связи $\hat{y}_k$ имеет смысл памяти
состояния.  Схема модели приводится на~\figref{fig:nnp-feedback}.

\begin{figure}[h]
  \centering
  \input nnp_feedback.pic
  \caption{Модель с внешней обратной связью.}
  \label{fig:nnp-feedback}
\end{figure}

Для обучения нейронных сетей с внешними обратными связями можно
использовать метод обратного распространения в времени ({\em
backpropagation through time --- BPTT})~\cite{gibb96}~\cite{sigom00}.

Применительно к рассматриваемой задаче данный подход имеет то
преимущество, что для обучения НС--О требуется только выборка
обучающих пар $(u_k, y_k)$, записанных при управлении объектом в
замкнутом контуре.  Сам объект при обучении и при функционировании
модели не используется.  Это означает, что время и методы настройки
(проверки) модели ничем не ограничены.  Нейросетевая модель объекта в
данном случае является полностью автономной.  Эта нейросетевая модель
имитирует {\it поведение }объекта.

%Однако в случае непредсказуемой ситуации, не учтенной в обучающих
%данным (например, сильная пиковая помеха), могут сказаться
%нелинейные свойства объекта и его состояние по сравнению с
%нейросетевой моделью

Однако BPTT, наиболее универсальный и мощный метод обучения
многослойных нейронных сетей с внешними обратными связями,
обладает существенным недостатком.  Это так называемый эффект
исчезающего градиента ({\em vanishing gradient}), проявляющийся в
том, что нейросеть выявляет короткие зависимости в обучающей
последовательности, но не может научиться длинным в силу
многократного ослабления информации о зависимости в обратной
связи в процессе обратного распространения ошибки~\cite{linetal}.

Применительно к задаче нейросетевой имитации объекта управления
проблема исчезающего градиента будет возникать в двух случаях:
\begin{itemize}\label{simple-feedback-defects}
  \item значительное чистое запаздывание в динамике объекта
  управления;
  \item шаг квантования времени слишком мал по сравнению с
  характерным временем наступления установившегося режима.
\end{itemize}

Поскольку оба случая представляются достаточно распространенными,
решено отказаться от применения данного подхода к моделированию
объекта управления.  В противном случае, разрабатываемый метод
синтеза квазиоптимального нейрорегулятора имел бы более узкую
область применения.

\subbbsection{Повторение прошлых состояний}

% repeated past state
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:nnp-past-states}
% Рисунок с прошлыми состояниями %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Обратной связи вокруг НС--О можно избежать, если использовать для
нейросетевого моделирования динамики объекта несколько прошлых его
состояний, которые непосредственно наблюдались в предыдущие
моменты времени.  В этом случае прогноз выхода объекта нейросетью
каждый раз строится только на основе реальной информации из
контура управления:
\begin{equation}\label{eq:past-states}
  \hat{y}_{k+1}=\mathcal{N}^o(u_k, u_{k-1},\ldots,u_{k-D_u}, y_k,
                              y_{k-1},\ldots, y_{k-D_y})
\end{equation}

Схема одной из возможных моделей с повторением прошлых состояний
приводится на~\figref{fig:nnp-past-states}.

\begin{figure}[h]
  \centering
  \input nnp_paststates.pic
  \caption{Пример модели с повторением прошлых состояний
  $\hat{y}_{k+1}=\mathcal{N}^o(u_k, y_k, y_{k-1})$.}
  \label{fig:nnp-past-states}
\end{figure}

Обучение этой модели осуществляется вне контура управления на
некоторой тестовой выборке, включающей временные ряды $u_k$ и $y_k$.
Нейронная сеть $\mathcal{N}^o$ обучается делать прогноз состояния
объекта максимально близко к реально наблюдавшемуся значению.
Поскольку в данной схеме обратная связь отсутствует, возможно
использование любого из методов обучения статических нейронных сетей,
например, стандартного метода обратного распространения.

После сеанса обучения настроенная нейросеть может использоваться в
контуре управления для предсказания выхода объекта и для настройки
нейрорегулятора.

Такая модель не является автономной.  Она будет функционировать только
вместе с объектом.  Это утверждение было проверено на вычислительном
эксперименте, в котором настроенная по прошлым состояниям модель была
включена с обратными связями, подобно~\figref{fig:nnp-feedback}:
\begin{equation}\label{eq:bad-past-states}
  \hat{y}_{k+1}=\mathcal{N}^o(u_k, u_{k-1},\ldots,u_{k-D_u}, \hat{y}_k,
                              \hat{y}_{k-1},\ldots, \hat{y}_{k-D_y})
\end{equation}

В эксперименте на вход линейной модели объекта управления подавалось
управляющее воздействие, представлявшее собой окрашенный случайный
временной ряд.  Параллельно с объектом была включена по схеме
\eqref{eq:bad-past-states} модель, обученная по схеме с повторением
прошлых состояний.  Эксперимент показал, что модель
\eqref{eq:bad-past-states} сразу ``уходит'' с траектории выхода
объекта управления и выход модели нисколько не повторяет ожидаемую
траекторию.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:bad-past-states}
% График с результатами неправильного использования модели rps %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Как видно, нейросетевая модель объекта управления с повторением
прошлых состояний опирается на информацию об истинном, а не
предсказанном на предыдущих шагах состоянии объекта.  Иными словами,
это модель {\it предсказания }выхода объекта управления.

%Постоянная связь с объектом управления, имеющая место в данной
%нейросетевой модели, в некоторых случаях может оказаться полезной.
%В частности, в том случае,

Изложенный подход к построению нейросетевой модели объекта управления
требует решения вспомогательной задачи --- определения, с какой
задержкой и в каком количестве будут подаваться на входы НС--О
значения $u_k, u_{k-1},\ldots,u_{k-D_u}$ и $y_k, \hat{y}_{k-1},\ldots,
\hat{y}_{k-D_y}$.  Очевидно, величина задержки зависит от динамических
свойств объекта управления.  Далее вопрос выбора задержки будет
подробно исследован (п.~\ref{select_DuDy}).

%\paragraph{Инвертирование модели повторения прошлых состояний}

В целом, результаты, полученные в разделе \ref{nnplearning}, сохраняют
свою силу для модели повторения прошлых состояний.  Однако следует
уточнить \eqref{eq:invobj2} в соответствии с \eqref{eq:past-states}:
\begin{equation}\label{eq:invobj3}
  u^*_k=\mathcal{B}^o(u_k,
                      \mathcal{N}^o(u_k,\ldots,u_{k-D_u},
                                    y_k,\ldots,y_{k-D_y}),
                      r_{k+1})
\end{equation}

Видим, что следствием неавтономности модели предсказания является
использование наблюдаемых состояний объекта управления для его
инвертирования и, значит, для обучения нейрорегулятора.  Иными
словами, обучение нейросетевого регулятора должно осуществляться в
контуре управления в режиме рабочего функционирования.

\subbbsection{Гибридная модель}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%~\figref{fig:nnp-hybrid}
% Рисунок гибридной модели %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Следует отметить, что возможно объединение обеих моделей в рамках
единого гибридного подхода, схема которого представлена
на~\figref{fig:nnp-hybrid}.  То есть, в модели реализуется функция:
\begin{equation}\label{eq:nnp-hybrid}
  \hat{y}_{k+1}=\mathcal{N}^o(u_k, u_{k-1},\ldots,u_{k-D_u}, \hat{y}_k,
                              \hat{y}_{k-1},\ldots, \hat{y}_{k-D_y})
\end{equation}

\begin{figure}[h]
  \centering
  \input nnp_hybrid.pic
  \caption{Пример гибридной модели
  $\hat{y}_{k+1}=\mathcal{N}^o(u_k, \hat{y}_k, \hat{y}_{k-1})$.}
  \label{fig:nnp-hybrid}
\end{figure}

Для обучения нейросети необходимо использовать усложненный алгоритм
обратного распространения во времени, учитывающий задержки.

В данной модели ослаблено влияние недостатков модели с внешними
обратными связями (см.~с.~\pageref{simple-feedback-defects}).  В
частности, задержанные на величину чистого запаздывания входы
регулирующего воздействия должны помочь преодолеть первый недостаток,
а обратная связь с повторением нескольких задержанных выходов НС--О
--- второй.

По сравнению с моделью повторения прошлых состояний объекта управления
гибридная модель, во-первых, является автономной, во-вторых, нейросеть
становится более гибкой в части обучения динамике объекта.

Однако необходимо упомянуть также еще один существенный практический
недостаток моделей с внешними обратными связями (в том числе и
гибридной).  Это медленная скорость обучения нейросети, на порядки
уступающая скорости обучения нейросети без обратных связей.

Таким образом, в ряде случаев, когда динамические свойства объекта
управления приблизительно известны и имеется возможность реализовать
обучение нейрорегулятора в темпе реального времени в системе, вполне
достаточно ограничиться простой моделью повторения прошлых состояний.
В дальнейшем будем использовать именно эту модель объекта управления.

\subsubsection{Критерий и цель обучения}

\label{criteria_and_goal}
Критерий обучения нейросетевой модели объекта управления --- это
минимизация ошибки предсказания.  Однако цель обучения --- инверсия
объекта управления --- отличается от критерия.  Это несовпадение
приводит к тому, что не всегда уменьшение ошибки предсказания ведет к
лучшей инверсии.

Это может произойти в том случае, если мощность НС--О недостаточна для
представления объекта в виде зависимости
$\hat{y}_{k+1}=\hat{f}(u_k,\ldots,y_k,\ldots)$.  Экспериментально
установлено, что если НС--О состоит из одного нейрона (архитектура
$\mathcal{N}^o_{D_u+D_y,1}$), то ошибка предсказания после обучения
достаточно мала.  Однако анализ обученной НС--О показывает, что
весовые коэффициенты на входах $u_k,\ldots$ на порядки меньше весовых
коэффициентов на входах $y_k,\ldots$.  Это говорит о том, что в
процессе обучения НС--О столь простой архитектуры оказалось
невозможным построить зависимость $\hat{y}_{k+1}$ от управляющего
воздействия с опорой на предыдущее состояние объекта.  Вместо этого
была построена более простая зависимость от предыдущих состояний
объекта $\hat{y}_{k+1}=\hat{f}_1(y_k,\ldots)$, не позволяющая по
вполне очевидным причинам получить желаемую инверсию.

Данный пример показывает, что сложность архитектуры нейросети
(количество нейронов) важна при построении нейросетевой модели объекта
управления и должна выбираться сообразно сложности задачи.

Эффект пренебрежения управляющими входами в пользу прошлых наблюдений
также может наблюдаться при слишком большом отношении инерционности
объекта к шагу квантования времени в системе.  Если за время шага
квантования изменение наблюдаемого состояния объекта, вызванное
воздействием регулятора, мало по сравнению с уровнем помехи в канале
наблюдения, то алгоритм обучения НС--О не может выявить зависимость
выхода объекта от управляющего входа и настраивает нейросеть
реагировать только на прошлые состояния объекта.

{\bf Выяснить насколько влияет на качество обучения НС--Р сложность
архитектуры сети }

\subsubsection{Выбор архитектуры нейросети}

Многослойная нейронная сеть рассматриваемого в настоящей работе вида
полностью описывается количеством слоев и числом нейронов в них с
указанием типа нейронов последнего слоя.  Приведем некоторые правила
выбора архитектуры нейронной сети.

\subbbsection{Общее число нейронов}
Известная теорема \marginpar{Какая теорема?} о представительной
способности сети прямого распространения с двумя слоями нейронов с
сигмоидальной функцией активации~(\figref{fig:nn-classic}) приводит к
следующему граничному определению количества нейронов скрытого слоя:
\begin{equation}\label{eq:neuron-number}
\displaystyle\frac{mN}{(n+m)(1+\log_2N)} \le k \le
m(N/n+1)+\displaystyle\frac{m}{n+m}(N/n+2)
\end{equation} где $n$ --- число входов нейросети, $m$ --- число
выходов (выходных нейронов), $k$ --- число нейронов в скрытом слое,
$N$ --- количество образов в обучающей выборке.  Количество нейронов,
меньшее, чем нижний предел, не позволит нейросети успешно распознать
все образы даже из обучающей выборки.  Слишком большое число нейронов
(больше верхнего предела), приведет к потере сетью обобщающей
способности, то есть, вне обучающей выборки результат распознавания
станет резко хуже, чем для образов из обучающей выборки.

\begin{figure}[h]
  \centering
  \input nn_classic.pic
  \caption{Классическая архитектура многослойного перцептрона.}
  \label{fig:nn-classic}
\end{figure}

Однако при малом числе входов и выходов относительно объема обучающей
выборки имеет место достаточно широкий диапазон значений $k$.
Рассмотрим типичные величины параметров, входящих
в~\eqref{eq:neuron-number}, в задаче синтеза нейросетевой модели
объекта управления.  Например, $n=4$, $m=1$ и $N=500$ дает диапазон
$10\le k\le227$.

Столь широкий разброс допустимого количества нейронов должен означать
слабую зависимость представительной способности сети от количества
нейронов.  Имитационные эксперименты, проведенные с нейросетевой
моделью управления, подтверждают этот тезис.  Однако всегда следует
учитывать специфику обучающего множества и уровень ошибки в минимуме,
полученном в процессе обучения.  Количество весовых коэффициентов
нейронов и их взаимное расположение влияет на размерность и форму
поверхности ошибки, по которой проводится градиентный спуск в процессе
обучения.  Поэтому может оказаться полезным экспериментально
варьировать число нейронов в сети до получения удовлетворительного
результата обучения --- нахождения более глубокого локального
минимума.

\subbbsection{Количество слоев}
Исследования архитектуры сетей прямого распространения показали, что
увеличение количества слоев нейронной сети во многих случаях позволяет
ускорить процесс обучения, а также, увеличить точность работы ИНС.
Использование нейросетей с двумя и более скрытыми слоями ставит задачу
распределения нейронов по ним.

Увеличение числа скрытых слоев становится необходимым также в том
случае, если выходные нейроны имеют линейную функцию активации.
Нейросеть является универсальным аппроксиматором любых, в том числе,
нелинейных функций только если число слоев с нелинейной функцией
активации не меньше двух.

\subbbsection{Распределение нейронов в слоях}
Известен следующий эвристический метод решения данной задачи.  Скрытый
слой, получающий данные непостредственно с входов ИНС, оснащают числом
нейронов, превышающим число входов (в 1.5--3 раза).  Следующий за ним
скрытый слой имеет меньшее число нейронов, следующий --- еще меньше, и
так далее до последнего скрытого слоя, граничащего с выходным.
Количество нейронов в слоях следует выбирать так, чтобы последний
скрытый слой имел число нейронов больше или равное числу выходных
нейронов.  Общее число нейронов рекомендуется сделать несколько
большим, чем в классической двухслойной нейросети с аналогичными
параметрами.

Первый слой нейронов за счет своего значительного размера позволяет
получить большое число комбинаций исходных признаков.  Последующие
слои последовательно уменьшают число производных признаков, приближая
их к целевому образу.  При рассмотрении нейросети как системы
распознавания, прямое распространение можно интерпретировать как
процесс абстрагирования от всего второстепенного, причем каждый слой
выполняет роль уровня абстракции.  Последний слой является высшим
уровнем абстракции --- он формирует целевой признак, являющийся
результатом распознавания.


\subsubsection{Выбор количества и номенклатуры входов нейросети}

\label{select_DuDy}
Выбор модели повторения прошлых состояний~\eqref{eq:past-states} в
качестве базовой ставит перед нами проблему выбора чисел $D_u$ и
$D_y$, задающих размер ``входной памяти'', используемой нейросетевой
моделью для предсказания выхода объекта.  Исследуем с помощью
имитационного эксперимента влияние $D_u$ и $D_y$ на качество обучения
нейросетевой модели линейного объекта управления и зависимость
результата обучения от инерционности объекта.

Условия проведения эксперимента:
\begin{itemize}

\item Объект управления: $G^*(z)=\displaystyle\frac{z}{z-d}$, где $d=e^{-1/T}$
      определяет степень инерционности объекта

\item Управляющее воздействие --- н.б.ш. \GaDi{0}{1}
\item Помеха наблюдения --- н.б.ш. \GaDi{0}{0.1}

\item Длина обучающей выборки 250
\item Длина тестовой выборки 500

\item Архитектура НС--О: $\mathcal{N}^o_{D_u+D_y,8,3,1}$
\item Продолжительность обучения 400 эпох

\end{itemize}

Было проведено $9\times 4\times 4=144$ сеанса обучения со следующими
параметрами объекта и НС--О:

\begin{itemize}
\item $d$ принимает значения 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,
      что соответствует времени установления переходного процесса от
      0.43 до 9.49 дискретных отсчетов времени.
\item $D_u$ принимает значения 1, 2, 3, 4
\item $D_y$ принимает значения 1, 2, 3, 4
\end{itemize}

Результаты эксперимента, сгруппированные по одинаковым значениям
$D_y$, приведены на \figref{fig:nnp_error_DuDy}.  Их анализ позволяет
сделать следующие заключения:

\begin{enumerate}

\item Соблюдение условия $D_u\le D_y$ приводит к меньшей ошибке (в 2--3 раза).

\item При $D_y=1$ зависимость ошибки от инерционности объекта на рассмотренном
      интервале $d$ не проявляется.

\item При $D_y>1$ ошибка увеличивается с увеличением инерционности объекта.

\end{enumerate}

\begin{figure}[h]
\begin{tabular}{p{0.46\textwidth}p{0.46\textwidth}}
\psfig{figure=T1u_D_Du+1_831.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T1u_D_Du+2_831.ps,angle=270,width=0.46\textwidth}\\[0pt]
\hfil а) $D_y=1$\hfil & \hfil б) $D_y=2$\hfil \\[16pt]
\psfig{figure=T1u_D_Du+3_831.ps,angle=270,width=0.46\textwidth} &
\psfig{figure=T1u_D_Du+4_831.ps,angle=270,width=0.46\textwidth}\\[0pt]
\hfil в) $D_y=3$\hfil & \hfil г) $D_y=4$\hfil \\[16pt]
\end{tabular}
\caption{Зависимость ошибки модели предсказания НС--О от $D_u$ и $d$}
\label{fig:nnp_error_DuDy}
\end{figure}

Очевидно, что увеличение емкости ``входной памяти'' (определяемой
числами $D_u$ и $D_y$) не сказывается существенно на улучшении
качества предсказания нейросетевой моделью выхода объекта управления.
Дальнейшие исследования траектории ошибки в процессе обучения
показали, что добиться меньшей ошибки в 2--3 раза возможно простым
увеличением продолжительности обучения (см. п.\ref{nnp_stat_stability}
и \figref{fig:nnp_case_infl}).  Эксперименты проводились на белом
шуме, используемом в качестве пробного сигнала.  При ином виде
пробного сигнала зависимости, представленные на
\figref{fig:nnp_error_DuDy}, будут несколько иными при сохранении
отмеченных закономерностей.

Обычно вполне достаточным оказывается выбор нейросетевой модели с
$D_u=1$ и $D_y=1$.  Единственный случай, когда можно рекомендовать
$D_y>1$, --- это построение нейросетевой модели объекта управления с
чистым запаздыванием.  В этом случае рекомендуется выбрать величину
$D_y$ не меньше, чем величина чистого запаздывания объекта управления
в дскретах.


\subsubsection{Требования к обучающей и контрольной выборкам}

По предлагаемой методике обучение нейросетевого имитатора объекта
управления должно осуществляться вне контура управления на выборке,
полученной экспериментальным путем.  Очевидно, временные ряды должны
нести достаточно информации для того, чтобы обучить нейросетевую
модель функционировать с приемлемым качеством.  Встает вопрос о
необходимых требованиях к обучающей и тестовой выборкам $\{u_k,
y_k\}_N$.

В общем случае, выбор идентифицирующего сигнала $u_k$, позволяющего
``изучить'' объект управления, во многом зависит от свойств самого
объекта, а также помехи, неизбежно присутствующей в любой реальной
системе.  Однако реалии функционирующей САУ ограничивают инженера в
выборе идентифицирующего сигнала требованиями допустимости и/или
реализуемости тех или иных возмущающих воздействий.  Как правило,
сложные системы управления имеют встроенные генераторы допустимых
пробных сигналов, используемых при настройке контуров.  Методика
построения промышленных нейросетевых регуляторов должна опираться на
имеющиеся средства, для чего следует изучить, насколько традиционные
пробные сигналы применимы для нейросетевой идентификации.

Детерминистский подход в традиционной теории управления предлагает в
качестве пробных сигналов некоторые ``удобные'' формы, легко
реализуемые физически: гармонический сигнал и ступенчатое воздействие.

С точки зрения линейной теории автоматического управления
гармоническое воздействие позволяет исследовать поведение объекта
только на одной частоте.  Ступенька позволяет получить отклик объекта,
теоретически содержащий все частоты, то есть, исчерпывающе
характеризующий обследуемый объект.  В обоих случаях длина выборки,
содержащей всю полезную информацию, определяется инерционными
свойствами объекта.  Амплитуда (мощность) входного воздействия обычно
берется значительно больше уровня шумов, имеющихся в системе
управления.

Статистические методы исследования линейных систем базируются на
идентифицирующих свойствах случайных сигналов.  Идеальный пробный
сигнал --- белый шум --- на практике недостижим и не всегда применим
из-за физических ограничений на амплитуду возмущающего воздействия.
Обычно бывает достаточно сигнала с известным спектром.

Идентификация объекта управления основывается на коррелировании
входного и выходного сигналов.  Для повышения помехозащищенности
рекомендуется увеличивать длину выборки.  Повышение мощности входного
сигнала также способствует этой цели.

Очевидно, что перечисленные методы идентификации с чистом виде не
применимы к нейронным сетям в силу различия подходов.  Однако имеет
смысл отталкиваться от известных подходов с целью выработки новых.

С целью исследования применимости традиционных пробных сигналов при
обучении нейросетевой модели объекта были проведены многочисленные
имитационные эксперименты со ступенчатым, гармоническим и
стохастическим управляющим воздействием.
%  Обобщая полученный опыт,
%можно сделать некоторые выводы качественного плана.
В качестве примера рассмотрим серию экспериментов с дискретным
объектом управления с передаточной функцией
$G(z)=\frac{0.5z^2}{z^2-0.7}$.  Была выбрана архитектура НС--О
$\mathcal{N}^o_{1+1,8,3,1}(u_k,y_k)$ с линейной функцией активации
последнего слоя и масштабированием $(-3,3)\to(-1,1)$ на входах и
$(-1,1)\to(-15,15)$ на выходе.

\subbbsection{Ступенчатый пробный сигнал}
Длина обучающей выборки $L=100$.  Форма $0\to 1\to -1$.  Имеются
некоторые особенности, которые необходимо учитывать для успешного
обучения нейросетевой модели:
\begin{itemize}
\item
Длительность обучения $\approx 10^3$ эпох с большим базовым
коэффициентом скорости обучения ($\eta\approx0.1$).
\item
Для того, чтобы нейросеть ``изучила'' как положительную, так и
отрицательную области отклика объекта, рекомендуется использовать
пробный сигнал вида $0\to 1\to -1$
(\figref{fig:nnp_step_training}а).  В случае простой ступеньки с
единственным фронтом $0\to 1$ НС--О будет плохо функционировать в
области отрицательных управляющих воздействий.
\item
В том случае, если амплитуда управляющего сигнала значительно
превышает амплитуду обучающего ступенчатого (в 5--10 раз), качество
функционирования нейросетевой модели резко падает.  На
\figref{fig:nnp_step_training}б заметна потеря качества уже при уровне
сигнала $\approx 4$, а при уровне $\approx 7$ НС--О функционирует
недопустимо плохо.  Таким образом, надежность по амплитуде на примере
составила 4 (максимальное превышение уровня контрольного сигнала над
обучающим при сохранении качества предсказания).
\end{itemize}

\begin{figure}[h]
\begin{tabular}{cc}
\hbox{\psfig{figure=nnp_step_training.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} &
\hbox{\psfig{figure=nnp_step_trained.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} \\
а) & б) \\
\end{tabular}
\caption{Обучение НС--О по ступенчатому управляющему воздействию (а)
         и контрольный пример большой амплитуды (б).}
\label{fig:nnp_step_training}
\end{figure}

\subbbsection{Гармонический пробный сигнал}
Длина обучающей выборки $L=100$.  Период $T=20$.  Амплитуда 1.
Имеются некоторые особенности, которые необходимо учитывать для
успешного обучения нейросетевой модели:
\begin{itemize}
\item
Длительность обучения $\approx 10^3$ эпох с большим базовым
коэффициентом скорости обучения ($\eta\approx0.1$).
\item
Поскольку пробный сигнал имел амплитуду 1, а в качестве теста
подавался сигнал с б\'ольшим размахом (от $-15$ до 8), был обнаружен
эффект падения качества функционирования нейросетевой модели.
Коэффициент надежности по амплитуде примено равен 2.5.
\item
Обучение носит частотно-зависимый характер, то есть, наилучшие
результаты тестирования достигаются на гармоническом сигнале обучающей
частоты.
\item
На ступенчатом возмущении НС--О, построенная по гармоническому
сигналу, дает ошибку коэффициента передачи.
\end{itemize}

\begin{figure}[h]
\begin{tabular}{cc}
\hbox{\psfig{figure=nnp_sin20_training.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} &
\hbox{\psfig{figure=nnp_sin20_trained.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} \\
а) & б) \\
\end{tabular}
\caption{Обучение НС--О по моногармоническому воздействию (а)
         и контрольный пример большой амплитуды (б).}
\label{fig:nnp_sin_training}
\end{figure}

\subbbsection{Стохастический пробный сигнал}
Длина обучающей выборки $L=200$.  Формирующий фильтр
$U(z)=\frac{z}{z-0.95}$.  Имеют место слудеющие особенности процедуры
обучения и качества функционирования НС--О:
\begin{itemize}
\item
Длительность обучения $\approx 10^3$ эпох с малым базовым
коэффициентом скорости обучения ($\eta\approx0.01$).
\item
Как и с предыдущими пробными сигналами, обучение носит
{амп\-ли\-туд\-но}-зависимый характер.  Коэффициент надежности по амплитуде
примерно равен 1, то есть, нейронная сеть строго ограничена рамками
обучающего множества (\figref{fig:nnp_bad_range}).
\item
В отличие от НС--О, обученных по детерминированным пробным сигналам,
нейросетевая модель, полученная по стохастическому ряду может быть не
выровнена по нулю, то есть, при нулевых входах выход НС--О отличен от
нуля.  Назовем этот отрицательный эффект {\it усилением нуля.}
\item
Со значительной ошибкой может определяться коэффициент передачи на
ступенчатом возмущении.
\end{itemize}

\begin{figure}[h]
\centerline{\hbox{\psfig{figure=nnp_bad_range.ps,%
angle=270,width=0.8\textwidth,height=0.3\textheight}}}
\caption{Контрольная выборка выходит за пределы области гарантированного
         качества НС--О.}
\label{fig:nnp_bad_range}
\end{figure}

В двумя последними недостатками настройки НС--О по стохастическому
обучающему множеству можно бороться, выбирая ряды $\{u_k\}_N$ и
$\{y_k\}_N$ так, чтобы $\bar{u}\approx0$ и $\bar{y}\approx0$.  Однако
данный способ не позволяет устранить эти недостатки полностью.

\subbbsection{Частотные свойства полученных нейросетевых моделей}
Учитывая, что моделируемый объект обладает частотными свойствами,
исследуем влияние частоты на качество предсказания выхода нейросетевой
модели.  Будем подавать возмущающий моногармонический сигнал
длительности $L=100$ на вход предсказывающей нейросетевой модели,
полученной по одному из рассмотренных опорных сигналов.  Качество
предсказания будем оценивать по величине среднеквадратичной ошибки
(СО).  Зависимость качества (СО) от частоты, полученная в результате
имитационного эксперимента, приведена на
\figref{fig:nnp_mse_freq}.

\begin{figure}[h]
\centerline{\hbox{\psfig{figure=nnp_mse_freq.ps,%
                         angle=270,width=0.8\textwidth,%
                         height=0.3\textheight}}}
\caption{Зависимость среднеквадратичной ошибки предсказания
         нейросетевых моделей от частоты.}
\label{fig:nnp_mse_freq}
\end{figure}

Нейросетевая модель, обученная по гармоническому пробному сигналу без
помехи имеет частотную характеристику качества в форме несимметричной
параболы с минимумом в точке обучающей частоты.  Начиная с некоторого
уровня помехи ($\sigma=0.1$) данное свойство теряется и частотная
характеристика приобретает монотонно возрастающую форму
(\figref{fig:nnp_freq_test}а).

НС--О, обученная по отклику объекта на ступенчатое возмущение,
проявляет приблизительно линейное ухудшение качества с ростом частоты.
Данное свойство практически не зависит от уровня помехи в канале
наблюдения в изученном диапазоне $\sigma=0\ldots0.3$
(\figref{fig:nnp_freq_test}б).  Интересно отметить, что небольшая
помеха $\sigma=0.05\ldots0.1$ при прочих равных условиях улучшила
качество предсказания гармонического сигнала на низких частотах.

Стохастическая нейросетевая модель обладает аналогичными частотными
свойствами, что и полученная по ступенчатому пробному сигналу.
Качество предсказания моногармонического сигнала практически не
зависит от наличия и мощности помехи при обучении (в диапазоне
$\sigma=0.05\ldots0.3$).

\begin{figure}[h]
\begin{tabular}{cc}
\hbox{\psfig{figure=step_freq_test.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} &
\hbox{\psfig{figure=sine_freq_test.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} \\
а) & б)\\
\end{tabular}
\caption{Зависимость среднеквадратичной ошибки предсказания НС--О,
         обученной по ступенчатому (а) и гармоническому (б) пробному
         сигналу, от частоты $f$ и помехи н.б.ш. \GaDi{0}{\sigma} в
         обучающем сигнале.}
\label{fig:nnp_freq_test}
\end{figure}

\subbbsection{Обобщение результатов экспериментов}
В целом можно отметить, что все три традиционных пробных сигнала
применимы для обучения нейросетевой модели объекта управления.
Естественно, каждый из них имеет свои недостатки и достоинства.

Может показаться, что ступенчатое возмущающее воздействие является
идеальным для нейросетевой идентификации.  Рассмотрим типичный вид
обучающего множества при ступенчатом пробном сигнале на плоскости
(\figref{fig:nnp_ss_map_uy}).  Ромбами на графике обозначаются
обучающие пары $\{u_k, y_k\}$.  Используя метафору обучения нейронной
сети как апроксимацию функции легко увидеть главный недостаток
ступенчатого сигнала --- отсутствие опорных точек в диапазонах $u$ от
$-1$ до $0$ и от $0$ до $1$.  Эксперимент показал, что для выбранного
линейного объекта управления интерполяция его поведения нейронной
сетью избранной архитектуры оказалась достаточно хорошей.  Более того,
оказалась достаточно хорошей и экстраполяция (надежность по амплитуде
равна 4), что искусственным нейронным сетям несвойственно.  Трудно
сказать, является ли это случайным совпадением или закономерностью.
Однако представляется сомнительным, что объект управления с выраженной
нелинейностью будет хорошо идентифицирован нейросетью на основе
отклика на ступенчатое возмущение.

Единственный способ быть уверенным в поведении НС--О для некоторой
пары $\{u_k, y_k\}$ --- это обучить нейросеть в этой точке.  На
\figref{fig:nnp_ss_map_uy} треугольниками обозначены обучающие пары
стохастического пробного сигнала.  Видно, что в этом случае область
гарантированного при обучении качества предсказания объекта управления
несравненно больше.  Есть уверенность, что при достаточно плотном
покрытии интересующей области в плоскости $u\times y$ окажется
возможным обучать НС--О для нелинейных объектов.

\begin{figure}[h]
\centerline{\hbox{\psfig{figure=nnp_ss_map_uy.ps,%
angle=270,width=0.8\textwidth,height=0.3\textheight}}}
\caption{Обучающие множества при ступенчатом и стохастическом
         пробных сигналах.}
\label{fig:nnp_ss_map_uy}
\end{figure}

Гармонический сигнал с точки зрения равномерности распределения
амплитуд на плоскости $u\times y$ является промежуточным между
ступенчатым и стохастическим.  Обучающие пары распределены по эллипсу
с почти ``пустым'' центром.

% Область гарантированного качества
Итак, наиболее важным моментом при выборе обучающего множества для
построения нейросетевой модели предсказания объекта управления
является правильный выбор амплитуд возмущения и отклика.  Чтобы
нейросеть могла работать в каком-либо диапазоне амплитуд возмущающего
воздействия и наблюдаемого выхода объекта необходимо взять исходную
выборку, охватывающую и заполняющую целевые диапазоны.  Назовем
область, охватываемую обучаемым множеством {\it областью
гарантированного качества.}

% Коэффициент надежности по амплитуде
В зависимости от многих факторов (вид обучающей выборки, архитектура
нейросети) обученная нейросеть может обладать способностью без потери
качества функционировать за пределами области гарантированного
качества.  Способность нейросети к экстраполяции можно
охарактеризовать отношением максимальной амплитуды сигнала за
пределами области гарантированного качества, при котором еще не
происходит существенного увеличения ошибки предсказания к максимальной
амплитуде на границе области.  Назовем этот коэффициент {\it
надежностью по амплитуде.}

\subbbsection{Требования к длине выборок}

Длина обучающей выборки, очевидно, должна быть не короче времени
затухания переходных процессов на объекте.  Данное требование созвучно
линейной теории идентификации.  Вместе с тем, должны быть наложены
дополнительные условия, специфичные для обучения НС--О.

Если есть возможность, желательно сформировать обучающую выборку так,
чтобы реализация содержала амплитуды необходимой величины (то есть,
обеспечивалась желаемая область гарантированного качества) и среднее
значение по амплитуде было возможно близко к нулю.  Последнее
требование, как уже упоминалось выше, может в некоторой степени
устранить ненулевое предсказание выхода объекта при нулевых входах
модели (эффект усиления нуля).

При значительном уровне шумов в системе можно несколько увеличить
длину выборок с целью повышения помехоустойчивости, однако при
высокочастотном шуме и достаточно инерционном объекте ординарной длины
выборки будет вполне достаточно.  Следует предостеречь от чрезмерного
увеличения длины выборки, так как при большем размере обучающего
множества сходимость алгоритма обратного распространения может
существенно уменьшиться и даже прекратиться в локальном минимуме.
Рассмотрим, в каком случае это может произойти; для этого вернемся к
\figref{fig:nnp_ss_map_uy}.

Каждая точка на плоскости имеет значение следующего наблюдаемого
выхода объекта: $(u_k, y_k)\to y_{k+1}$.  Если окажется, что
вследствие шумов близкие точки на плоскости $(u_i, y_i)$ и $(u_j,
y_j)$ будут отображаться в сильно различающиеся значения $y_{i+1}$ и
$y_{j+1}$, то алгоритм обучения будет вынужден сделать негладкую
функцию нейросети в окрестности этих точек, чтобы результирующая
ошибка была минимальна.  При большом объеме зашумленных обучающих
данных число подобных конфликтных областей будет значительным.
Эмпирически известно, что каждая такая область будет требовать
б\'ольших ресурсов сети, чем для воспроизведения гладкой зависимости.
При большом количестве конфликтных областей на определенном шаге
обучающий алгоритм не сможет уменьшить ошибку, так как будет исчерпана
``емкость памяти'' нейронной сети.

К сожалению, на настоящий момент не существует удовлетворительной
количественной теории емкости памяти искусственных нейронных сетей,
поэтому приходится довольствоваться качественными оценками.  Тем не
менее, знание качественных закономерностей позволит инженеру,
проектирующий нейросетевую систему управления, подобрать
удовлетворительную обучающую выборку экспериментальным путем.

В то время, как обучающая выборка должна нести по возможности
исчерпывающую информацию об объекте управления, требования к
контрольной выборке несколько иные.  В частности, ее длина может быть
любой.  Распределение амплитуд пробного сигнала тоже может быть любым,
что позволяет при желании оценить надежность НС--О по амплитуде,
диагностировать величину усиления нуля и прочие нежелательные эффекты.
Главное назначение теста --- это независимая оценка производительности
НС--О в штатных устовиях функционирования объекта.  Рекомендуется
проводить тестирование НС--О после каждого обновления весовых
коэффициентов сети в течение всего процесса обучения.  Для оценки
производительности НС--О по контрольной выборке могут применяться
любые критерии, не только среднеквадратичная ошибка.  При начале роста
ошибки на контрольной выборке процесс обучения следует остановить и
считать достигнутое качество функционирования НС--О финальным.

\subsubsection{Статистическая устойчивость процесса обучения}%
\label{nnp_stat_stability}

Исследуем, насколько зависит процесс обучения от реализации обучающей
выборки в том случае, когда пробный сигнал --- случайный.  Для этого
были проведены вычислительные эксперименты, в ходе которых
варьировались исследуемые параметры обучающей и тестовой выборок, а
процесс обучения оценивался по графику среднеквадратичной ошибки (СО)
тестовой выборки.

Эксперименты проводились на НС трех архитектур: однослойной
$\mathcal{N}^o_{1+3,1}$ (один нейрон), двухслойной
$\mathcal{N}^o_{1+3,4,1}$ и трехслойной $\mathcal{N}^o_{1+3,7,3,1}$.
Как видно, на вход НС--О в каждом случае подавались задержанные в
течение трех тактов сигналы с выхода объекта управления $y_k, y_{k-1},
y_{k-2}$ и текущий сигнал управляющего воздействия $u_k$.

В качестве объекта управления было взято инерционное звено с
дискретной передаточной функцией $G(z)=\frac{0.25z}{z-0.75}$.

В эксперименте участвовали 10 различных реализаций выборки
управляющего воздействия и помехи.  И управляющее воздействие, и
помеха, являлись реализациями нормально распределенного псевдобелого
шума с параметрами \GaDi{0}{1} и \GaDi{0}{0.1} соответственно.

Каждая из представленных нейросетей обучалась в течение 400 эпох.  Для
оценки влияния реализации на обучение нейросетевой модели объекта
управления рассматривались траектории СО на тестовой выборке в
процессе обучения.  Длина обучающей и тестовой выборки была взята
равной 500.  Данный объем выборок значительно превышает необходимый
для решения задачи оценивания параметров процесса АРСС и по
соображениям аналогии может считаться достаточным для обучения НС--О.
Равенство длин обучающей и тестовой выборок, а также значительное
превышение их объема над числом настраиваемых параметров нейросети
(весовых коэффициентов) позволяет быть уверенным в отсутствии эффекта
переобучения.

Результаты эксперимента представлены на \figref{fig:nnp_case_infl}.
Графики наглядно демонстрируют слабую зависимость процесса обучения
НС--О от реализации выборок.  Полученные результаты позволяют сделать
следующие эмпирические заключения:

\begin{figure}[h]
\centerline{\hbox{\psfig{figure=T6_mse_1+3_1.eps,%
angle=270,width=0.8\textwidth,height=0.2\textheight}}}
\centerline{а)}
\centerline{\hbox{\psfig{figure=T6_mse_1+3_41.eps,%
angle=270,width=0.8\textwidth,height=0.2\textheight}}}
\centerline{б)}
\centerline{\hbox{\psfig{figure=T6_mse_1+3_731.eps,%
angle=270,width=0.8\textwidth,height=0.2\textheight}}}
\centerline{в)}
\caption{Графики траекторий СО 10 сеансов обучения НС--О с архитектурой
$\mathcal{N}^o_{1+3,1}$ (а), $\mathcal{N}^o_{1+3,4,1}$ (б) и
$\mathcal{N}^o_{1+3,7,3,1}$ (в).}
\label{fig:nnp_case_infl}
\end{figure}

\begin{enumerate}
  \item Форма графика СО (число и положение точек перегиба) не
  зависит от реализации выборки, а зависит от архитектуры НС--О.

  \item С увеличением числа слоев НС--О форма графика СО усложняется
  и влияние реализации выборки на процесс обучения увеличивается.

  \item В худшем случае (трехслойная сеть) отличие минимальной СО от
  максимальной на траектории обучения не превышает 5 раз.  В случае
  монотонного уменьшения СО (при отсутствии эффекта переобучения) эта
  разница может быть устранена более продолжительным обучением.

  \item С усложнением архитектуры нейронной сети финальная ошибка при
  равной длительности обучения увеличивается.
\end{enumerate}

Закономерный вывод, следующий из результатов экспериментов, ---
использовать настолько простые архитектуры НС--О, насколько это
возможно.
