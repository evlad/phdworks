% -*-coding: cp1251;-*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Глава 3 - Синтез нейросетевого оптимального регулятора

Предложенная в главе \ref{linear_to_neural} методика замены линейного
регулятора на нейросетевой обладает одним существенным недостатком ---
эта замена не ставит целью улучшение качества управления.  Критерием
обучения нейросетевого регулятора в этой методике является минимизация
ошибки имитации исходного регулятора, а не минимизация ошибки
управления объектом.

В то же время, в ряде работ (например, в~\cite{park96}) предлагаются
различные схемы с нейросетевым регулятором, приводящие к уменьшению
ошибки управления.  Многие из них основаны на нейросетевой оценке
якобиана объекта управления.  Зная якобиан можно осуществить инверсию,
то есть, рассчитать управляющее воздействие, приводящее объект
управления к желаемому состоянию, то есть, выполнить заданную уставку.
Рассмотрим метод синтеза нейросетевого регулятора, использующего
нейросетевую инверсию объекта для минимизации ошибки управления.

\section{Постановка задачи}

Будем рассматривать систему автоматического регулирования с обратной
связью, изображенную на \figref{fig:nncctrlloop}, в которой в качестве
регулятора выступает нейросеть.  Такая система может возникнуть,
например, в результате замены линейного регулятора на нейросетевой
(см. главу \ref{linear_to_neural}).
\begin{figure}[h]
  \centering
  \input{nncctrlloop.eps_t}
  \caption{Исходная система управления с нейросетевым регулятором.}
  \label{fig:nncctrlloop}
\end{figure}

Как и в случае имитации линейного регулятора нейросетевым, на систему
действует случайная помеха $n(t)$.  Объект не меняет своих свойств во
времени.  Рассмотрим задачу синтеза такой нейронной сети $\NN^p$,
чтобы она обеспечивала управляющее воздействие $u(t)$, минимизирующее
ошибку управления $e(t)$.  При этом будем использовать квадратичный
критерий:
\begin{equation}\label{eq:noc_synthesis_task}
  \sum\limits_k\big(r_k-g(u_k,\mathbf{s})-n_k\big)^2\rightarrow\min
\end{equation}

\noindent где $u_k=\NN^p(\mathbf{i}_k)$ --- управляющее воздействие
НС--Р, $\mathbf{i}_k$ --- информация, подаваемая на вход НС--Р
(например, $\mathbf{i}_k=[r_k, e_k]$), $\mathbf{s}$ --- выход объекта
управления, $g(.)$ --- функция, определяющая наблюдаемый выход объекта
по управляющему воздействию регулятора и текущему состоянию объекта,
$r_k$ --- уставка, а $n_k$ --- аддитивная помеха, искажающая
наблюдаемый выход объекта.

Для случая стохастических сигналов $r(t)$ и $n(t)$ с известными
корреляционными свойствами описанная постановка
задачи~\eqref{eq:noc_synthesis_task} по сути является винеровской.  В
классе линейных систем решение называется винеровским оптимальным
регулятором $f(.)$, который обеспечивает необходимое управляющее
воздействие $u_k=f(e_k)$.  По аналогии назовем синтезируемый $\NN^p$
нейросетевым оптимальным регулятором (НОР), имея в виду оптимальность
по ошибке управления, а не по структуре НС.

Винеровская оптимальная фильтрация подробно описана в литературе
\cite{tsipkin58,solod60,medv82}.  Однако хорошо известные
недостатки данного подхода (необязательная физическая осуществимость
регулятора, неробастность), а также потребность в предварительной
идентификации параметров объекта управления, уставки и помехи делают
проведение синтеза оптимального линейного регулятора по Винеру делом
достаточно сложным и требующим в каждом случае индивидуального подхода
с использованием аналитических расчетов.

При синтезе НОР будем учитывать недостатки винеровского оптимального
регулятора с тем, чтобы избежать их.  Для удобства сопоставления
нейросетевого и винеровского оптимального регуляторов вычислительные
эксперименты будем проводить на линейном объекте, однако нигде ниже
предположение о линейности не используется для синтеза НОР явно.

%\section{Проблема эталона при обучении нейрорегулятора}

\label{noc-problem}% Проблема обучения --- нужна инверсная модель
Как уже отмечалось, к наиболее распространенным методам обучения
искусственных нейронных сетей относится семейство градиентных
алгоритмов, называемых также обратным распространением ошибки ({\em
  backpropagation of error}). Это так называемые методы обучения с
учителем ({\em supervised learning}), то есть, нейросеть обучается на
эталонных парах {\em вход--выход.}  Будем использовать для обучения
нейросетевого оптимального регулятора метод обратного распространения
ошибки.  Получение эталонной пары в рассматриваемой задаче
представляет определенную проблему.

По условию задачи исходный регулятор не является оптимальным, а
значит, пара {\em вход--выход}, измеренная на регуляторе, не может
являться эталоном для настройки нейросетевого оптимального регулятора.
Эталонная (то есть, ведущая к оптимальному закону управления)
обучающая пара известна лишь для всей системы --- это уставка как вход
системы и одновременно как её целевой выход.  Очевидно, что условие
$y(t) = r(t)$ является идеалом управления системой и оно удовлетворяет
условию минимума среднеквадратической ошибки
управления~\eqref{eq:noc_synthesis_task}.

Таким образом, для обучения нейросетевого оптимального регулятора возникает
задача получения целевого сигнала управления $u^*(t)$ по эталонному
выходу объекта $y^*(t) \equiv r(t)$. Покажем, что это достигается
построением инверсной функции объекта управления.  Запишем зависимость
выхода объекта управления от его входа как
$$y=g(u)$$

Тогда оптимальное управляющее воздействие даст желаемый выход
$$y^*=g(u^*)$$

Желаемый выход объекта (уставка) известен, следовательно для
вычисления оптимального управляющего воздействия $u^*$ достаточно
найти $g^{-1}(.)$ --- инверсную функцию объекта
управления.\footnote{Конечно, данная задача может рассматриваться
только в том случае, когда $g^{-1}(.)$ однозначная.}  Тогда
$$u^* = g^{-1}(y^*) \equiv g^{-1}(r)$$

Поскольку реальный объект управления в любом случае не допускает
решения данной задачи, то необходима его инверсная модель.  В качестве
инверсной модели можно использовать нейросетевую модель объекта
управления, работающую в обратном направлении в режиме распространения
ошибки с выхода на вход без обучения (коррекции весовых
коэффициентов). Эта нейронная сеть должна быть предварительно обучена
функционировать подобно объекту управления.  В отличие от
нейросетевого регулятора она по завершении его настройки может быть
отключена, так как в рабочем режиме и стационарных условиях НС--Р
может функционировать без инверсной модели.

Покажем, как можно использовать нейросетевую модель объекта управления
для обучения нейросетевого оптимального регулятора.

\section{Принцип обучения нейрорегулятора с использованием инверсной
модели}

\label{nnc_optimal_training} Будем считать, что имеется уже настроенная
нейросетевая модель объекта управления (НС--О) --- $\NN^o$,
предсказывающая наблюдаемый выход объекта в следующий момент времени.
Для простоты возьмем одномерный объект.  Пока будем считать, что выход
объекта в каждый момент времени полностью определяется его входом в
настоящий момент времени (позже данное ограничение будет снято).
Положим, что помеха в системе отсутствует, то есть, $n(t)=0$.

Пусть на вход нейросети регулятора подается только сигнал ошибки:
$$
\mathbf{i}_k=e_k
$$

Нейронная сеть регулятора имеет архитектуру $\NN^p_{1,\ldots,1}$ с
$m_p$ слоями. Тогда движение системы в пространстве состояний из
момента времени $t_k$ в следующий момент $t_{k+1}$ будет описываться
следующими уравнениями:
$$ \left\{\begin{array}{rcl}
  e_k & = & y_k-r_k \\
  u_k & = & \NN^p(e_k) \\
  y_{k+1} & = & g(u_k)
\end{array}\right. $$ причем $y_k=\mathsf{z}^{-1}(y_{k+1})$.

Кроме того, параллельно с объектом управления включена его
нейросетевая модель, реализуемая сетью с архитектурой
$\NN^o_{1,\ldots,1}$ ($m_o$ слоев) и осуществляющая
прогноз выхода объекта:
\begin{equation}\label{eq:nnp-principle}
  \hat{y}_{k+1} = \NN^o(u_k)
\end{equation}

Система управления в этом случае принимает вид как на
\figref{fig:noclearnloop}
\begin{figure}[h]
  \centering
  \input{noclearnloop.eps_t}
  \caption{Система управления с нейросетевым регулятором и нейросетевой
моделью объекта управления.}\label{fig:noclearnloop}
\end{figure}

%\subsection{Приведение ошибки с выхода НС--О на выход НС--Р}

Для наглядности перегруппируем блоки в контуре управления так, чтобы
нейронные сети регулятора и модели располагались последовательно, а
помеху $n(t)=0$ не будем изображать вообще (\figref{fig:noclearnloop2}).
Тогда обе нейронных сети можно рассматривать как одну с $m=m_p+m_o$
слоями и архитектурой $\NN_{1,\ldots,1,\ldots,1} = \NN^p_{1,\ldots,1}
\cdot \NN^o_{1,\ldots,1}$, причем с выхода слоя $m_p$ снимается сигнал
$u_k$ и подается на вход объекта. Данная конструкция на
\figref{fig:noclearnloop2} обведена пунктиром.
\begin{figure}[h]
  \centering
  \input{nnplearn.eps_t}
  \caption{Обучение нейросетевого регулятора с помощью инвертирования
  модели объекта.}\label{fig:noclearnloop2}
\end{figure}

Распространение информации в прямом направлении через слой $d$
нейросети происходит по алгоритму, определяемому
формулами~\eqref{eq:sigm_neuron_output_parts}.  Для комбинированной
сети вход $q^0_1=e_k$, промежуточный выход $q^{m_p}_1=u_k$ и выход
$q^{m}_1=\hat{y}_{k+1}$.

Прогнозируемая ошибка управления равна $\hat{e}_k=\hat{y}_k-r_k$.  Её
можно рассматривать как ошибку воспроизведения комбинированной
нейросети $\NN$.  Для уменьшения этой ошибки должен быть сделан шаг
алгоритма обучения.  По условию считаем, что НС--О повторяет выход
объекта $\hat{y}_k=y_k$, следовательно прогнозируемая и реальная
ошибки управления совпадают: $e_k=\hat{e}_k$.  То есть, настройка
управляющей части $\NN^p$ комбинированной нейросети с целью уменьшить
ошибку прогноза приведет к уменьшению ошибки управления реальным
объектом.  Итак, эталонной обучающей парой комбинированной нейросети
является $e_k$ (вход НС--Р) и $r_k$ (желаемый выход НС--О).

Определим суммарную среднеквадратическую ошибку управления на
траектории уставки $r$ как
$$ \hatMSE\DEF\frac{1}{2}\sum_k\hat{e}_k^2 =
\frac{1}{2}\sum_k(y_k-r_k)^2 $$

Задача обучения нейросети $\NN$ ставится как минимизация
$\hatMSE$ путем подбора весовых коэффициентов $w^d_{ij}$. Поскольку
по условию $\NN^o$ уже обучена, следовательно ошибка
управления может быть устранена только соответствующей настройкой
$\NN^p$.  Поэтому весовые коэффициенты должны
корректироваться только в части $\NN^p$, а именно, в слоях
$1\le d\le m_p$.

В соответствии с алгоритмом обратного распространения обобщенная
ошибка распространяется от выхода к входу обратно прямому
распространению информации в нейросети и может вычисляться без
коррекции весовых коэффициентов.  Её расчет ведется по следующей
формуле и различается для выходного и скрытых слоев:
\begin{equation}\label{eq:deltaprop}
  \delta^d_i=\left\{\begin{array}{ll}
    \fa'(z^d_i)\sum\limits_h\delta^{d+1}_h w^{d+1}_{hi} & 1\le d<m \\
    \fa'(z^d_i)(y_k-r_k) & d=m \\
  \end{array}\right.
\end{equation}

Выход слоя $m_p$ используется как управляющее воздействие
$u_k=q^{m_p}_1$. В том случае, если этот слой рассматривать как
выходной у НС--Р, то вычисление обобщенной ошибки для него
формально определялось бы уравнением
\begin{equation}\label{eq:deltapropp-out}
  \delta^{m_p}_i=\fa'(z^{m_p}_i)(u_k-u^*_k),
\end{equation}

\noindent где $u^*_k$ --- некоторое целевое значение управляющего
воздействия.  Но в рамках комбинированной нейросети обобщенная
ошибка равна
\begin{equation}\label{eq:deltapropp-hid}
  \delta^{m_p}_i=\fa'(z^{m_p}_i)\sum_h\delta^{m_p+1}_h w^{m_p+1}_{hi}
\end{equation}

Здесь слой $m_p+1$ является входным у НС--О.  Сопоставляя
\eqref{eq:deltapropp-out} и \eqref{eq:deltapropp-hid}, выводим, что
для уменьшения ошибки воспроизведения данной эталонной пары {\em
вход--выход} комбинированной нейросетью выход слоя $m_p$ (то есть,
управляющее воздействие $u_k$) следовало бы сделать равным
\begin{equation}\label{eq:desired-u}
  u^*_k=u_k-\sum_h\delta^{m_p+1}_h w^{m_p+1}_{hi}
\end{equation}

Данное выражение вместе с уравнениями~\eqref{eq:deltaprop} для
вычисления $\delta^m_n$ определяет способ вычисления ошибки на выходе
нейросетевого регулятора по ошибке на выходе нейросетевой модели
объекта управления.

Следует отметить, что если в прямом направлении ошибка вычисляется с
использованием оператора задержки наблюденного выхода объекта
$y_k\equiv\mathsf{z}^{-1}(y_{k+1})$:
\begin{equation}\label{eq:past-time}
  e_k=\mathsf{z}^{-1}(y_{k+1})-r_k,
\end{equation} то при её распространении в обратном направлении через
НС--О мы получаем как-бы прошлое значение желаемого управляющего
воздействия.  То есть, \eqref{eq:desired-u} описывает, какое
управляющее воздействие должно было быть, чтобы текущее значение
ошибки управления уменьшилось.  Поскольку из практических соображений
шаг дискретного времени всегда выбирается гораздо меньше
времени переходных процессов в системе, далее будем считать разницу
между прошлым и текущим желаемым управляющими воздействиями
несущественной.

Приведенные рассуждения применимы к более широкому классу нейронных
сетей регулятора и модели объекта чем одновходовые $\NN^p(e_k)$ и
$\NN^o(u_k)$.  В частности, возможно использование НС--Р вида
$\NN^p(r_k,e_k)$ и $\NN^p(e_k,e_{k-1},...,e_{k-d})$.

В случае использования нейросетевой модели объекта с несколькими
входами (например, $\NN^o(u_k,u_{k-1},y_k,y_{k-1})$) комбинированную
нейросеть следует строить только через текущее управляющее воздействие
регулятора, то есть $\NN=\NN^o(\NN^p,u_{k-1},y_k,y_{k-1})$.  В
этом случае обратное распространение ошибки из НС--О в НС--Р
осуществляется только через вход $u_k$ нейросетевой модели.  Остальные
входы в обратном направлении не используются, так как они нужны только
для моделирования динамических свойств.

%\subsection{Инверсная модель объекта управления}

Можно обобщить уравнения \eqref{eq:deltaprop} и
\eqref{eq:desired-u} в единой функциональной зависимости,
реализующей метод обратного распространения ошибки в нейросетевой
модели объекта управления без коррекции весовых коэффициентов:
\begin{equation}\label{eq:invobj}
  u^*_k=\mathcal{B}^o(u_k, y_{k+1}, r_{k+1})
\end{equation}

В том случае, если НС--О функционирует абсолютно подобно объекту
управления, то есть, $g\equiv \NN^o$, следует ожидать, что
$g^{-1}\equiv {\NN^o}^{-1}=\mathcal{B}^o$.

Другими словами, метод обратного распространения ошибки может
использоваться как вычислительная процедура для инвертирования
функции объекта:
\begin{equation}
  \mathcal{B}^o: r_{k+1} \rightarrow u^*_k
\end{equation}

В случае непрерывного времени идеальная континуальная нейросетевая
модель объекта будет инвертировать желаемый выход объекта в
требуемое управляющее воздействие без задержки, то есть:
$$ \mathcal{B}^o: r(t) \rightarrow u^*(t) $$

Исследуем свойства полученной инверсии.  Поскольку прямая $\NN^o$ и
обратная $\mathcal{B}^o$ функции реализуются с помощью одного и того
же набора параметров $w^d_{ij}$, качество прогноза выхода объекта
напрямую связано с качеством инверсии.

В качестве параметров функции $\mathcal{B}^o$ выступают также $u_k$ и
$y_{k+1}$.  Их наличие вызвано тем, что обратное распространение
опирается на информацию, полученную во время прямого распространения.
То есть, более корректно следует записать
\begin{equation}\label{eq:invobj2}
  u^*_k=\mathcal{B}^o(u_k, \NN^o(u_k), r_{k+1})
\end{equation} считая, что $y_{k+1}\approx\hat{y}_{k+1}=\NN^o(u_k)$.

Данное представление функции $\mathcal{B}^o$ можно интерпретировать
как инверсию уставки $r_{k+1}$ в некоторой окрестности управляющего
воздействия $u_k$.  То есть, инвертирование объекта управления с
помощью НС--О осуществляется не во всей области определения $g(.)$, а
в некоторой локальной окрестности опорного управляющего воздействия,
задающего оценку состояния объекта управления.  Локальность
осуществляемого обратного преобразования позволяет использовать
искусственные нейронные сети для отображения многозначных функций,
однозначных на некоторых интервалах.

Подчеркнём связь нейросетевой инверсии и якобиана объекта управления.
Как известно, якобиан --- матрица скалярных частных производных
переменных состояния по входам --- является мерой реакции объекта на
изменение управляющих воздействий в заданной точке пространства
состояний.  Для простого объекта с одним управляющим входом и одной
переменной состояния, наблюдаемой на выходе, якобиан упрощается до
обычной производной:
\begin{equation}\label{eq:jacobian}
  J(t)=\Biggl(\frac{\partial y_i}
		   {\partial u_j}\Biggr)_{i,j}=\frac{d y(t)}{d u}
\end{equation}

Дискретную линейную оценку якобиана~\eqref{eq:jacobian} в окрестности
номинальной траектории можно рассчитать по формуле
$$
  J_k=\frac{\Delta y_{k+1}}{\Delta u_{k}}
$$ откуда следует, что для получения желаемого состояния объекта
$y_{k+1}=r_{k+1}$ следует приложить управление $u^*_k$:
$$
  r_{k+1}=y_k+J_k(u^*_k-u_{k-1})
$$ следовательно
\begin{equation}\label{eq:jacobinv}
  u^*_k=u_{k-1}+(r_{k+1}-y_k)/J_k
\end{equation}

Объединяем формулы \eqref{eq:jacobinv} и \eqref{eq:invobj} и получаем:
\begin{equation}\label{eq:nn-jacobinv}
  \mathcal{B}^o(u_k, y_{k+1}, r_{k+1})=\mathsf{z}^{-1}(u_k)+(r_{k+1}-y_k)/J_k
\end{equation}

Таким образом, нейросетевая функция $\mathcal{B}^o$ обратного
распространения ошибки через НС--О включает в себя оценку якобиана
объекта управления.

%
%{\bf На рисунке приводится пример инверсии функции sin().}

%\subsection{Обучение нейрорегулятора по инверсной модели}

В реальных условиях всегда присутствует помеха.  Из-за неё НС--О не
может быть идеально обучен, то есть, всегда $y_{k+1}\ne\hat{y}_{k+1}$.
Вследствие этого инверсия объекта, задаваемая
формулой~\eqref{eq:invobj}, рассчитывается с ошибкой.  Однако при
правильном выборе параметров обучения (см. п.\ref{nnc_final_training})
статистически НС--Р будет обучаться в сторону уменьшения ошибки
управления, достигая поставленной в п.~\ref{noc-problem} задачи.

Вопрос сходимости алгоритма обучения с обратным распространением
ошибки к оптимальному решению теоретически решается выбором
бесконечно малого шага $\eta$ при отсутствии локальных минимумов в
процессе обучения.  На практике проблема локальных минимумов не
решена ни для одного из градиентных методов оптимизации, поэтому
обычно удовлетворяются первым же достаточно подходящим минимумом,
а неподходящих минимумов избегают с помощью различных
эвристических подходов \cite{wasser92,gibb96}. Мера того,
является ли решение (набор весовых коэффициентов сети) подходящим,
определяется значением ошибки регулирования, получаемым на
контрольной выборке.

Для улучшения сходимости широко используются градиентные методы
второго порядка, развитые на основе алгоритма обратного
распространения~\cite{gibb96}.  Применение этих методов не меняет
логики изложенного метода нейросетевой инверсии объекта управления для
обучения нейросетевого регулятора.

\section{Синтез нейросетевой модели объекта управления}%
\label{nnpsynthesis}

При построении нейросетевой модели реального объекта управления
возникает задача конкретизации архитектуры нейросети и условий её
настройки.  Очевидно, этот этап синтеза нейросетевого оптимального
регулятора существенно зависит от многих факторов: объекта управления,
свойств помехи, длины и прочих свойств имеющихся экспериментальных
выборок.  Исследование этих зависимостей представляет существенный
интерес и должно послужить более эффективному применению нейросетей в
системах управления.

Нейросетевая модель играет важную роль в обучении НОР: она работает в
качестве вычислителя якобиана объекта управления.  Известно, что для
целенаправленного синтеза нейросетевого регулятора достаточно знать
знак якобиана~\cite{sigom00,wangbao00}, при этом сходимость алгоритма
обучения достаточно медленная.  Однако в сложных случаях
(нестационарный или существенно нелинейный объект) получить оценку
даже знака якобиана непросто, а ошибка в знаке может привести к
неадекватному управлению и потере устойчивости в
контуре~\cite{wangbao00}.  Учитывая стратегическую важность НС--О,
следует достаточно подробно рассмотреть ее архитектуру, методику
синтеза и особенности функционирования.

Критерий обучения нейросетевой модели объекта управления --- это
минимизация среднеквадратической ошибки предсказания.  Однако цель
обучения --- инверсия объекта управления --- отличается от критерия.
Это несовпадение в общем случае может приводить к тому, что не всегда
уменьшение ошибки предсказания будет вести к лучшей инверсии.  В
последующих параграфах будут рассматриваться различные аспекты
достижения критерия обучения НС--О.  Вопрос о том, насколько
построенная согласно критерию нейросетевая модель объекта управления будет
справляться с инверсией объекта, будет поставлен в
п.~\ref{nnp_on_nnc_influence}, так как он связан с задачей синтеза
нейросетевого регулятора.  Там же будут даны дополнительные
рекомендации по выбору архитектуры НС--О.\label{nnp_criteria_and_goal}

%\subsection{Архитектура нейросетевой модели объекта управления}

%\subsubsection{Структура входов нейросети}%
\label{nnp_inputs}
Как уже отмечалось, сеть прямого распространения не обладает свойством
сохранения состояния, а потому нейросеть, реализующая зависимость
$\hat{y}_{k+1}=\NN^o(u_k)$ непосредственно не позволит создавать
модели, адекватные динамическим объектам.

Для построения динамической нейросетевой модели объекта управления
воспользуемся архитектурой с повторением прошлых состояний.  Этот
подход требует решения вспомогательной задачи --- определения, с какой
задержкой и в каком количестве будут подаваться на входы НС--О
значения $u_k, u_{k-1},\ldots,u_{k-D_u}$ и $y_k, y_{k-1},\ldots,
y_{k-D_y}$.  Очевидно, величина задержки зависит от динамических
свойств объекта управления.

%Далее вопрос выбора задержки будет подробно исследован
%(с.~\pageref{select_DuDy}).

%\subsection{Выбор количества и номенклатуры входов нейросети}

%\cite[109,118]{sigom00} - выбор Du, Dy

%Выбор модели повторения прошлых состояний~\eqref{eq:past-states} в
%качестве базовой ставит проблему выбора чисел $D_u$ и
%$D_y$, задающих размер ``входной памяти'', используемой нейросетевой
%моделью для предсказания выхода объекта.

\label{select_DuDy}%
Исследуем с помощью имитационного эксперимента влияние $D_u$ и $D_y$
на качество обучения нейросетевой модели линейного объекта управления
и зависимость результата обучения от инерционности объекта.

Условия проведения эксперимента:
\begin{itemize}

\item Объект управления: $G^*(z)=\displaystyle\frac{z}{z-d}$, где $d=e^{-1/T}$
      определяет степень инерционности объекта

\item Управляющее воздействие --- нормально распределенный белый шум \GaDi{0}{1}
\item Помеха наблюдения --- нормально распределенный белый шум \GaDi{0}{0.1}

\item Длина обучающей выборки 250
\item Длина тестовой выборки 500

\item Архитектура НС--О: $\NN^o_{8,3,1}(u_k,...,u_{k-D_u},y_k,...,y_{k-D_y})$ (далее для краткости обозначаемая как $\NN^o_{D_u+D_y,8,3,1}$
\item Продолжительность обучения 400 эпох

\end{itemize}

Было проведено $9\times 4\times 4=144$ сеанса обучения со следующими
параметрами объекта и НС--О:

\begin{itemize}
\item $d$ принимает значения 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,
      что соответствует времени установления переходного процесса от
      0.43 до 9.49 дискретных отсчетов времени.
\item $D_u$ принимает значения 1, 2, 3, 4
\item $D_y$ принимает значения 1, 2, 3, 4
\end{itemize}

Результаты эксперимента, сгруппированные по одинаковым значениям
$D_y$, приведены на \figref{fig:nnp_error_DuDy}.  Их анализ позволяет
сделать следующие заключения:

\begin{enumerate}

\item Соблюдение условия $D_u\le D_y$ приводит к меньшей ошибке (в 2--3 раза).

\item При $D_y=1$ зависимость ошибки от инерционности объекта на рассмотренном
      интервале $d$ не проявляется.

\item При $D_y>1$ ошибка увеличивается с увеличением инерционности объекта.

\end{enumerate}
\begin{figure}[h]
\begin{tabular}{p{0.46\textwidth}p{0.46\textwidth}}%
\includegraphics[width=0.46\textwidth]{T1u_D_Du+1_831} &
\includegraphics[width=0.46\textwidth]{T1u_D_Du+2_831}\\[0pt]
\hfil а) $D_y=1$\hfil & \hfil б) $D_y=2$\hfil \\[16pt]
\includegraphics[width=0.46\textwidth]{T1u_D_Du+3_831} &
\includegraphics[width=0.46\textwidth]{T1u_D_Du+4_831}\\[0pt]
\hfil в) $D_y=3$\hfil & \hfil г) $D_y=4$\hfil \\[16pt]
\end{tabular}
\caption{Зависимость ошибки модели предсказания НС--О от $D_u$ и $d$}
\label{fig:nnp_error_DuDy}
\end{figure}

Очевидно, что увеличение емкости ``входной памяти'' (определяемой
числами $D_u$ и $D_y$) не сказывается существенно на улучшении
качества предсказания нейросетевой моделью выхода объекта управления.
Дальнейшие исследования траектории ошибки в процессе обучения
показали, что добиться меньшей ошибки в 2--3 раза возможно простым
увеличением продолжительности обучения (см. п.\ref{nnp_stat_stability}
и \figref{fig:nnp_case_infl}).  Эксперименты проводились на белом
шуме, используемом в качестве пробного сигнала.  При ином виде
пробного сигнала зависимости, представленные на
\figref{fig:nnp_error_DuDy}, будут несколько иными при сохранении
отмеченных закономерностей.

Обычно вполне достаточным оказывается выбор нейросетевой модели с
$D_u=1$ и $D_y=1$.  Единственный случай, когда можно рекомендовать
$D_y>1$, --- это построение нейросетевой модели объекта управления с
чистым запаздыванием.  В этом случае рекомендуется выбрать величину
$D_y$ не меньше, чем величина чистого запаздывания объекта управления
в дискретах времени.


%\subsubsection{Внутренняя структура нейросети}

Многослойная нейронная сеть рассматриваемого в настоящей работе вида
полностью описывается количеством слоев и числом нейронов в них с
указанием типа нейронов последнего слоя.  Отметим некоторые
особенности выбора архитектуры нейронной сети.

\begin{itemize}

\item {\it Количество слоев}

Исследование архитектуры сетей прямого распространения показало, что
увеличение количества слоев нейронной сети во многих случаях позволяет
ускорить процесс обучения, а также, увеличить точность работы ИНС.
Использование нейросетей с двумя и более скрытыми слоями ставит задачу
распределения нейронов по ним.

Увеличение числа скрытых слоев становится необходимым также в том
случае, если выходные нейроны имеют линейную функцию активации.
Нейросеть является универсальным аппроксиматором любых, в том числе,
нелинейных функций только если число слоев с нелинейной функцией
активации не меньше двух.

\item {\it Распределение нейронов в слоях}

Известен следующий эвристический метод решения данной задачи.  Скрытый
слой, получающий данные непосредственно с входов ИНС, оснащают числом
нейронов, превышающим число входов (в 1.5--3 раза).  Следующий за ним
скрытый слой имеет меньшее число нейронов, следующий --- еще меньше, и
так далее до последнего скрытого слоя, граничащего с выходным.
Количество нейронов в слоях следует выбирать так, чтобы последний
скрытый слой имел число нейронов больше или равное числу выходных
нейронов.  Общее число нейронов рекомендуется сделать несколько
большим, чем в классической двухслойной нейросети с аналогичными
параметрами.

Первый слой нейронов за счет своего значительного размера позволяет
получить большое число комбинаций исходных признаков.  Последующие
слои последовательно уменьшают число производных признаков, приближая
их к целевому образу.  При рассмотрении нейросети как системы
распознавания, прямое распространение можно интерпретировать как
процесс абстрагирования от всего второстепенного, причем каждый слой
выполняет роль уровня абстракции.  Последний слой является высшим
уровнем абстракции --- он формирует целевой признак, являющийся
результатом распознавания.

\end{itemize}

%\subsection{Требования к обучающей и контрольной выборкам}%
\section{Данные для обучения нейросетевой модели}%
\label{nnp_series_req}
По предлагаемой методике обучение нейросетевого имитатора объекта
управления должно осуществляться вне контура управления на выборке,
полученной экспериментальным путем.  Очевидно, временные ряды должны
нести достаточно информации для того, чтобы обучить нейросетевую
модель функционировать с приемлемым качеством.  Встает вопрос о
необходимых требованиях к обучающей и тестовой выборкам $\{u_k,
y_k\}_N$.

В общем случае, выбор идентифицирующего сигнала $u_k$, позволяющего
``изучить'' объект управления, во многом зависит от свойств самого
объекта, а также помехи, неизбежно присутствующей в любой реальной
системе.  Однако реалии функционирующей САУ ограничивают инженера в
выборе идентифицирующего сигнала требованиями допустимости и/или
реализуемости тех или иных возмущающих воздействий.  Как правило,
сложные системы управления имеют встроенные генераторы допустимых
пробных сигналов, используемых при настройке контуров.  Методика
построения промышленных нейросетевых регуляторов должна опираться на
имеющиеся средства, для чего следует изучить, насколько традиционные
пробные сигналы применимы для нейросетевой идентификации.

Детерминистский подход в традиционной теории управления предлагает в
качестве пробных сигналов некоторые ``удобные'' формы, легко
реализуемые физически: гармонический сигнал и ступенчатое воздействие.

С точки зрения линейной теории автоматического управления
гармоническое воздействие позволяет исследовать поведение объекта
только на одной частоте.  Ступенька позволяет получить отклик объекта,
теоретически содержащий все частоты, то есть, исчерпывающе
характеризующий обследуемый объект.  В обоих случаях длина выборки,
содержащей всю полезную информацию, определяется инерционными
свойствами объекта.  Амплитуда (мощность) входного воздействия обычно
берется значительно больше уровня шумов, имеющихся в системе
управления, но в физически допустимых пределах.

Статистические методы исследования линейных систем базируются на
идентифицирующих свойствах случайных сигналов.  Идеальный пробный
сигнал --- белый шум --- на практике недостижим и не всегда применим
из-за физических ограничений на амплитуду возмущающего воздействия.
Обычно бывает достаточно сигнала с достаточно широким спектром.

Идентификация объекта управления в статистических методах основывается
на корреляции входного и выходного сигналов.  Для повышения
помехозащищенности рекомендуется увеличивать длину выборки.  Повышение
мощности входного сигнала также способствует этой цели.

Очевидно, что перечисленные методы идентификации с чистом виде не
применимы к нейронным сетям в силу различия подходов.  Однако имеет
смысл отталкиваться от известных подходов с целью выработки новых.

С целью исследования применимости традиционных пробных сигналов при
обучении нейросетевой модели объекта были проведены многочисленные
имитационные эксперименты со ступенчатым, гармоническим и
стохастическим управляющим воздействием.  В качестве примера
рассмотрим серию экспериментов с дискретным объектом управления с
передаточной функцией $G(z)=\frac{0.5z^2}{z^2-0.7}$.  Была выбрана
архитектура НС--О $\NN^o_{8,3,1}(u_k,y_k)$ (кратко ---
$\NN^o_{1+1,8,3,1}$) с линейной функцией активации последнего слоя и
масштабированием $(-3,3)\to(-1,1)$ на входах и $(-1,1)\to(-15,15)$ на
выходе.

%\subsubsection{Ступенчатый пробный сигнал}
\paragraph{Ступенчатый пробный сигнал}
Длина обучающей выборки $L=100$.  Форма $0\to 1\to -1$.  Имеются
некоторые особенности, которые необходимо учитывать для успешного
обучения нейросетевой модели:
\begin{itemize}
\item
Длительность обучения $\approx 10^3$ эпох с большим базовым
коэффициентом скорости обучения ($\eta\approx0.1$).
\item
Для того, чтобы нейросеть ``изучила'' как положительную, так и
отрицательную области отклика объекта, рекомендуется использовать
пробный сигнал вида $0\to 1\to -1$
(\figref{fig:nnp_step_training}а).  В случае простой ступеньки с
единственным фронтом $0\to 1$ НС--О будет плохо функционировать в
области отрицательных управляющих воздействий.
\item
В том случае, если амплитуда управляющего сигнала в процессе
эксплуатации САУ значительно превышает амплитуду обучающего
ступенчатого (в 5--10 раз), качество функционирования нейросетевой
модели резко падает.  На \figref{fig:nnp_step_training}б заметна
потеря качества уже при уровне сигнала $\approx 4$, а при уровне
$\approx 7$ НС--О функционирует недопустимо плохо.  Таким образом,
надежность по амплитуде на примере составила 4 (максимальное
превышение уровня контрольного сигнала над обучающим при сохранении
качества предсказания).
\end{itemize}
\begin{figure}[h]
\centering
\begin{tabular}{lclc}
  \begin{sideways}
    {\hspace{2cm}\small Выход объекта}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{nnp_step_training}
  &
  \begin{sideways}
    {\hspace{2cm}\small Выход объекта}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{nnp_step_trained}
  \\
  & {\small Время} & & {\small Время}\\
  & а) & & б)\\
\end{tabular}
\caption{Обучение НС--О по ступенчатому управляющему воздействию (а)
         и контрольный пример большой амплитуды (б).}
\label{fig:nnp_step_training}
\end{figure}


%\subsubsection{Гармонический пробный сигнал}
\paragraph{Гармонический пробный сигнал}
Длина обучающей выборки $L=100$.  Период $T=20$.  Амплитуда 1.
Имеются некоторые особенности, которые необходимо учитывать для
успешного обучения нейросетевой модели:
\begin{itemize}
\item
Длительность обучения $\approx 10^3$ эпох с большим базовым
коэффициентом скорости обучения ($\eta\approx0.1$).
\item
Поскольку пробный сигнал имел амплитуду 1, а в качестве теста
подавался сигнал с большим размахом (от $-15$ до 8), был обнаружен
эффект падения качества функционирования нейросетевой модели.
Коэффициент надежности по амплитуде примерно равен 2.5.
\item
Обучение носит частотно-зависимый характер, то есть, наилучшие
результаты тестирования достигаются на гармоническом сигнале обучающей
частоты.
\item
На ступенчатом возмущении НС--О, построенная по гармоническому
сигналу, дает заметную ошибку коэффициента передачи.
\end{itemize}
\begin{figure}[h]
\centering
\begin{tabular}{lclc}
  \begin{sideways}
    {\hspace{2cm}\small Выход объекта}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{nnp_sin20_training}
  &
  \begin{sideways}
    {\hspace{2cm}\small Выход объекта}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{nnp_sin20_trained}
  \\
  & {\small Время} & & {\small Время}\\
  & а) & & б)\\
\end{tabular}
\caption{Обучение НС--О по моногармоническому воздействию (а)
         и контрольный пример большой амплитуды (б).}
\label{fig:nnp_sin_training}
\end{figure}


%\subsubsection{Стохастический пробный сигнал}
\paragraph{Стохастический пробный сигнал}
Длина обучающей выборки $L=200$.  Формирующий фильтр
$U(z)=\frac{z}{z-0.95}$.  Имеют место следующие особенности процедуры
обучения и качества функционирования НС--О:
\begin{itemize}
\item
Длительность обучения $\approx 10^3$ эпох с малым базовым
коэффициентом скорости обучения ($\eta\approx0.01$).
\item
Как и с предыдущими пробными сигналами, обучение носит
{амп\-ли\-туд\-но}-зависимый характер.  Коэффициент надежности по амплитуде
примерно равен 1, то есть, нейронная сеть строго ограничена рамками
обучающего множества (\figref{fig:nnp_bad_range}).
\item
В отличие от НС--О, обученных по детерминированным пробным сигналам,
нейросетевая модель, полученная по стохастическому ряду может быть не
выровнена по нулю, то есть, при нулевых входах выход НС--О отличен от
нуля.  Назовем этот отрицательный эффект {\it усилением
нуля.}\label{amplify-zero}
\item
Со значительной ошибкой может определяться коэффициент передачи на
ступенчатом возмущении.
\end{itemize}
\begin{figure}[h]
\centering
\begin{tabular}{lc}
  \begin{sideways}
    {\hspace{2.6cm}\small Выход объекта}
  \end{sideways}
  &
  \includegraphics[width=0.8\textwidth,%
    totalheight=0.3\textheight]{nnp_bad_range} \\
  & Время
\end{tabular}
\caption{Контрольная выборка значительно выходит за пределы области
         гарантированного качества НС--О.}
\label{fig:nnp_bad_range}
\end{figure}

С двумя последними недостатками настройки НС--О по стохастическому
обучающему множеству можно бороться, выбирая ряды $\{u_k\}_N$ и
$\{y_k\}_N$ так, чтобы $\bar{u}\approx0$ и $\bar{y}\approx0$.  Однако
данный способ не позволяет устранить эти недостатки полностью.

%\subsubsection{Частотные свойства полученных нейросетевых моделей}
Учитывая, что моделируемый объект обладает частотными свойствами,
исследуем влияние частоты на качество предсказания выхода нейросетевой
модели.  Будем подавать возмущающий моногармонический сигнал
длительности $L=100$ на вход предсказывающей нейросетевой модели,
полученной по одному из рассмотренных опорных сигналов.  Качество
предсказания будем оценивать по величине среднеквадратической ошибки.
Зависимость качества от частоты, полученная в результате имитационного
эксперимента, приведена на \figref{fig:nnp_mse_freq}.
\begin{figure}[h]
\begin{tabular}{lc}
  \begin{sideways}
    {\hspace{4.5cm}\small$\MSE$}
  \end{sideways}
  &
  \includegraphics[width=0.8\textwidth,%
    totalheight=0.35\textheight]{nnp_mse_freq}
\end{tabular}
\caption{Зависимость среднеквадратической ошибки предсказания
         нейросетевых моделей, обученных на пробных сигналов разного вида,
         от частоты.}
\label{fig:nnp_mse_freq}
\end{figure}

Нейросетевая модель, обученная по гармоническому пробному сигналу без
помехи, имеет частотную характеристику качества в виде несимметричной
параболы с минимумом в точке обучающей частоты.  Начиная с некоторого
уровня помехи ($\sigma=0.1$) данное свойство теряется и частотная
характеристика приобретает монотонно возрастающую форму
(\figref{fig:nnp_freq_test}а).

НС--О, обученная по отклику объекта на ступенчатое возмущение,
проявляет приблизительно линейное ухудшение качества с ростом частоты.
Данное свойство практически не зависит от уровня помехи в канале
наблюдения в изученном диапазоне $\sigma=0\ldots0.3$
(\figref{fig:nnp_freq_test}б).  Интересно отметить, что небольшая
помеха $\sigma=0.05\ldots0.1$ при прочих равных условиях улучшила
качество предсказания гармонического сигнала на низких частотах.

Стохастическая нейросетевая модель обладает аналогичными частотными
свойствами, что и полученная по ступенчатому пробному сигналу.
Качество предсказания моногармонического сигнала практически не
зависит от наличия и мощности помехи при обучении (в диапазоне
$\sigma=0.05\ldots0.3$).
\begin{figure}[h]
\begin{tabular}{cc}
\includegraphics[width=0.45\textwidth,%
             totalheight=0.25\textheight]{step_freq_test} &
\includegraphics[width=0.45\textwidth,%
             totalheight=0.25\textheight]{sine_freq_test} \\
а) & б)\\
\end{tabular}
\caption{Зависимость среднеквадратической ошибки предсказания НС--О,
         обученной по ступенчатому (а) и гармоническому (б) пробному
         сигналу, от частоты $f$ и нормально распределенной помехи
         \GaDi{0}{\sigma} в обучающем сигнале.}
\label{fig:nnp_freq_test}
\end{figure}

%\subsection{Обобщение результатов экспериментов}%
В целом можно отметить, что все три традиционных пробных сигнала
применимы для обучения нейросетевой модели объекта управления.
Естественно, каждый из них имеет свои недостатки и
достоинства.\label{nnp_map_uy}

Может показаться, что ступенчатое возмущающее воздействие является
идеальным для нейросетевой идентификации.  Рассмотрим типичный вид
обучающего множества при ступенчатом пробном сигнале на плоскости
(\figref{fig:nnp_ss_map_uy}).  Ромбами на графике обозначаются
обучающие пары $\{u_k, y_k\}$.  Используя метафору обучения нейронной
сети как аппроксимацию функции легко увидеть главный недостаток
ступенчатого сигнала --- отсутствие опорных точек в диапазонах $u$ от
$-1$ до $0$ и от $0$ до $1$.  Эксперимент показал, что для выбранного
линейного объекта управления интерполяция его поведения нейронной
сетью избранной архитектуры оказалась достаточно хорошей.  Более того,
оказалась достаточно хорошей и экстраполяция (надежность по амплитуде
равна 4), что искусственным нейронным сетям несвойственно.  Трудно
сказать, является ли это случайным совпадением или закономерностью.
Однако представляется сомнительным, что объект управления с выраженной
нелинейностью будет хорошо идентифицирован нейросетью на основе
отклика на ступенчатое возмущение.

Единственный способ быть уверенным в поведении НС--О для некоторой
пары $\{u_k, y_k\}$ --- это обучить нейросеть в этой точке.  На
\figref{fig:nnp_ss_map_uy} треугольниками обозначены обучающие пары
стохастического пробного сигнала.  Видно, что в этом случае область
гарантированного при обучении качества предсказания объекта управления
несравненно больше.  Есть уверенность, что при достаточно плотном
покрытии интересующей области в плоскости $u\times y$ окажется
возможным обучать НС--О для нелинейных объектов.
\begin{figure}[h]
\centerline{\includegraphics[width=0.8\textwidth,%
    totalheight=0.3\textheight]{nnp_ss_map_uy}}
\caption{Обучающие множества при ступенчатом и стохастическом
         пробных сигналах.}
\label{fig:nnp_ss_map_uy}
\end{figure}

Гармонический сигнал с точки зрения равномерности распределения
амплитуд на плоскости $u\times y$ является промежуточным между
ступенчатым и стохастическим.  Обучающие пары распределены по эллипсу
с почти ``пустым'' центром.

% Область гарантированного качества
Итак, наиболее важным моментом при выборе обучающего множества для
построения нейросетевой модели предсказания объекта управления
является правильный выбор амплитуд возмущения и отклика.  Чтобы
нейросеть могла работать в каком-либо диапазоне амплитуд возмущающего
воздействия и наблюдаемого выхода объекта необходимо взять исходную
выборку, охватывающую и заполняющую целевые диапазоны.  Назовем
область, охватываемую обучаемым множеством {\it областью
гарантированного качества.}\label{nnp_guarantee_quality_area}

% Коэффициент надежности по амплитуде
В зависимости от многих факторов (вид обучающей выборки, архитектура
нейросети) обученная нейросеть может обладать способностью без потери
качества функционировать за пределами области гарантированного
качества.  Способность нейросети к экстраполяции можно
охарактеризовать отношением максимальной амплитуды сигнала за
пределами области гарантированного качества, при котором еще не
происходит существенного увеличения ошибки предсказания к максимальной
амплитуде на границе области.  Назовем этот коэффициент {\it
надежностью по амплитуде.}

%\subsection{Требования к длине выборок}

Длина обучающей выборки, очевидно, должна быть не короче времени
затухания переходных процессов на объекте.  Данное требование созвучно
линейной теории идентификации.  Вместе с тем, должны быть наложены
дополнительные условия, специфичные для обучения НС--О.

Если есть возможность, желательно сформировать обучающую выборку так,
чтобы реализация содержала амплитуды $y_k$ необходимой величины (то
есть, обеспечивалась желаемая область гарантированного качества) и
среднее значение по амплитуде было возможно близко к нулю (при
масштабировании области значений $y_k$ в симметричный относительно
нуля диапазон).  Последнее требование, как уже упоминалось выше, может
в некоторой степени устранить ненулевое предсказание выхода объекта
при нулевых входах модели (эффект усиления нуля).

При значительном уровне шумов в системе можно несколько увеличить
длину выборок с целью повышения помехоустойчивости, однако при
высокочастотном шуме и достаточно инерционном объекте обычной длины
выборки будет вполне достаточно.  Следует предостеречь от чрезмерного
увеличения длины выборки, так как при большом размере обучающего
множества сходимость алгоритма обратного распространения может
существенно уменьшиться и даже прекратиться в локальном минимуме.
Рассмотрим, в каком случае это может произойти; для этого вернемся к
\figref{fig:nnp_ss_map_uy}.

Каждой точке на плоскости соответствует значение следующего наблюдаемого
выхода объекта: $(u_k, y_k)\to y_{k+1}$.  Если окажется, что
вследствие шумов близкие точки на плоскости $(u_i, y_i)$ и $(u_j,
y_j)$ будут отображаться в сильно различающиеся значения $y_{i+1}$ и
$y_{j+1}$, то алгоритм обучения будет вынужден сделать негладкую
функцию нейросети в окрестности этих точек, чтобы результирующая
ошибка была минимальна.  При большом объеме зашумленных обучающих
данных число подобных конфликтных областей будет значительным.
Эмпирически известно, что каждая такая область будет требовать больших
ресурсов сети (то есть, задействованных нейронов), чем для
воспроизведения гладкой зависимости.  При большом количестве
конфликтных областей на определенном шаге обучающий алгоритм не сможет
уменьшить ошибку, так как будет исчерпана ``емкость памяти'' нейронной
сети.

Имеющийся в наличии аппарат оценки информационной емкости нейронной
сети с помощью размерности Вапника-Червоненкиса~\cite{haykin2008}
ориентирован на задачу классификации образов, что делает его неудобным
для задач предсказания временных рядов, поэтому приходится
довольствоваться качественными оценками.  Тем не менее, знание
качественных закономерностей позволит инженеру, проектирующий
нейросетевую систему управления, подобрать удовлетворительную
обучающую выборку экспериментальным путем.

В то время, как обучающая выборка должна нести по возможности
исчерпывающую информацию об объекте управления, требования к
контрольной выборке несколько иные.  В частности, ее длина может быть
любой.  Распределение амплитуд пробного сигнала тоже может быть любым,
что позволяет при желании оценить надежность НС--О по амплитуде,
диагностировать величину усиления нуля и прочие нежелательные эффекты.
Главное назначение теста --- это независимая оценка производительности
НС--О в номинальных условиях функционирования объекта.  Рекомендуется
проводить тестирование после каждого обновления весовых
коэффициентов  НС--О в течение всего процесса обучения.  Для оценки
производительности НС--О по контрольной выборке могут применяться
любые критерии, не только среднеквадратическая ошибка.  При начале
роста ошибки на контрольной выборке процесс обучения следует
остановить и считать достигнутое качество функционирования НС--О
финальным.

%\subsection{Статистическая устойчивость процесса обучения}%
\label{nnp_stat_stability}
Исследуем, насколько зависит процесс обучения от реализации обучающей
выборки в том случае, когда пробный сигнал --- случайный.  Для этого
были проведены вычислительные эксперименты, в ходе которых
варьировались исследуемые параметры обучающей и тестовой выборок, а
процесс обучения оценивался по графику среднеквадратической ошибки
тестовой выборки.

Эксперименты проводились на НС трех архитектур: однослойной
$\NN^o_{1+3,1}$ (один нейрон), двухслойной
$\NN^o_{1+3,4,1}$ и трехслойной $\NN^o_{1+3,7,3,1}$.
Как видно, на вход НС--О в каждом случае подавались задержанные в
течение трех тактов сигналы с выхода объекта управления $y_k, y_{k-1},
y_{k-2}$ и текущий сигнал управляющего воздействия $u_k$.

В качестве объекта управления было взято инерционное звено с
дискретной передаточной функцией $G(z)=\frac{0.25z}{z-0.75}$.

В эксперименте участвовали 10 различных реализаций выборки
управляющего воздействия и помехи.  И управляющее воздействие, и
помеха, являлись реализациями нормально распределенного псевдобелого
шума с параметрами \GaDi{0}{1} и \GaDi{0}{0.1} соответственно.

Каждая из представленных нейросетей обучалась в течение 400 эпох.  Для
оценки влияния реализации на обучение нейросетевой модели объекта
управления рассматривались траектории среднеквадратической ошибки на
тестовой выборке в процессе обучения.  Длина обучающей и тестовой
выборки была взята равной 500.  Данный объем выборок значительно
превышает необходимый для решения задачи оценивания параметров
процесса авторегрессии -- скользящего среднего (АРСС)\cite{boxjenk74}
и по соображениям аналогии может считаться достаточным для обучения
НС--О в качестве модели линейного объекта.  Равенство длин обучающей и
тестовой выборок, а также значительное превышение их объема над числом
настраиваемых параметров нейросети (весовых коэффициентов) позволяет
быть уверенным в отсутствии эффекта переобучения.
\begin{figure}
\centering
\begin{tabular}{lc}
  \begin{sideways}
    {\hspace{1.8cm}\small$\MSE$}
  \end{sideways}
  &
  \includegraphics[width=0.8\textwidth,%
    totalheight=0.15\textheight]{T6_mse_1+3_1} \\
  & {\small Эпохи} \\
  & а) \\
  \begin{sideways}
    {\hspace{1.8cm}\small$\MSE$}
  \end{sideways}
  &
  \includegraphics[width=0.8\textwidth,%
    totalheight=0.15\textheight]{T6_mse_1+3_41} \\
  & {\small Эпохи} \\
  & б) \\
  \begin{sideways}
    {\hspace{1.8cm}\small$\MSE$}
  \end{sideways}
  &
  \includegraphics[width=0.8\textwidth,%
    totalheight=0.15\textheight]{T6_mse_1+3_731} \\
  & {\small Эпохи} \\
  & в)
\end{tabular}
\caption{Графики траекторий среднеквадратической ошибки 10 сеансов
        обучения НС--О с архитектурой $\NN^o_{1+3,1}$ (а),
        $\NN^o_{1+3,4,1}$ (б) и $\NN^o_{1+3,7,3,1}$ (в).}
\label{fig:nnp_case_infl}
\end{figure}

Результаты эксперимента представлены на \figref{fig:nnp_case_infl}.
Графики наглядно демонстрируют слабую зависимость процесса обучения
НС--О от реализации выборок.  Полученные результаты позволяют сделать
следующие эмпирические заключения:

\begin{enumerate}
\item Форма графика ошибки (число и положение точек перегиба) не
      зависит от реализации выборки, а зависит от архитектуры НС--О;
\item С увеличением числа слоев НС--О форма графика ошибки усложняется
      и влияние реализации выборки на процесс обучения увеличивается.
\item В худшем случае (трехслойная сеть) отличие минимальной ошибки от
      максимальной на траектории обучения не превышает 5 раз; в случае
      монотонного уменьшения ошибки (при отсутствии эффекта переобучения) эта
      разница может быть устранена более продолжительным обучением;
\item С усложнением архитектуры нейронной сети финальная ошибка при
      равной длительности обучения увеличивается.
\end{enumerate}

Закономерный вывод, следующий из результатов экспериментов, ---
использовать настолько простые архитектуры НС--О, насколько это
возможно.

\section{Анализ процесса обучения нейросетевого оптимального регулятора}%
\label{nnc_final_training}

Обучение НС--Р в контуре управления представляет собой оптимизационную
процедуру с критерием минимизации среднеквадратической ошибки
управления.  Настроенная подобно линейному регулятору вне контура,
нейросеть регулятора (глава~\ref{linear_to_neural}), во-первых,
является начальным приближением для оптимизационного алгоритма,
во-вторых, поддерживает устойчивость в системе управления.
Оптимизация осуществляется с помощью алгоритма обратного
распространения через нейросетевую модель объекта управления,
функционирующую в процессе дообучения.  Алгоритм оптимизации описан в
п.~\ref{nnc_optimal_training}.  Нейросетевая модель объекта управления
должна быть заранее обучена вне контура (п.~\ref{nnpsynthesis}).

В реальной системе управления дообучение осуществляется в процессе ее
штатной эксплуатации.  В каждый дискретный момент времени
рассчитываются величины коррекции весовых коэффициентов НС--Р.
Весовые коэффициенты корректируются на каждом шаге или с некоторым
периодом (пакетное обновление).  В последнем случае величины коррекции
каждого весового коэффициента за прошедшие в периоде моменты времени
суммируются и по окончании периода изменяют нейросеть кумулятивно.
Данная техника позволяет обновлять нейросеть регулятора статистически
устойчивыми на периоде величинами коррекции.  Это позволяет уменьшить
влияние помех на процесс обучения нейросетевого регулятора и сделать
его более устойчивым.

Процесс дообучения НС--Р в описанных условиях существенно зависит от
уставки и помехи в канале наблюдения.  Даже в том случае, если сделать
уставку периодичной с периодом обновления весовых коэффициентов НС--Р,
наличие случайной помехи придает процессу обучения стохастический
характер.  График среднеквадратической ошибки в этом случае изобилует
участками с возрастанием и убыванием ошибки при общей тенденции к
уменьшению.  На \figref{fig:cerr_trace}а сплошной линией показан
график среднеквадратической ошибки в процессе обучения, а пунктиром ---
приближение тренда экспонентой.

\begin{figure}[h]
\centering
\begin{tabular}{lclc}
  \begin{sideways}
    {\hspace{2.6cm}\small Ошибка}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{cerr_trace_1000}
  &
  \begin{sideways}
    {\hspace{2.6cm}\small Ошибка}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{cerr_trace}
  \\
  & {\small Эпоха} & & {\small Эпоха}\\
  & а) & & б)\\
\end{tabular}
\caption{Графики среднеквадратической ошибки управления при обучении
         НС--Р в реальных (а) и идеальных (б) условиях.}
\label{fig:cerr_trace}
\end{figure}

Влияние случайных факторов затрудняет определение момента достижения
регулятором требуемого качества функционирования, что мешает
исследованию его свойств и проведению сравнительных испытаний с иными
регуляторами.  Поэтому целесообразно в рамках имитационного
эксперимента искусственно сделать процесс обучения стационарным и
рассмотреть свойства полученного в таких условиях нейросетевого
регулятора.

%\subsubsection{Дообучение в стационарных условиях}

{\em Идеальными условиями обучения} назовем процесс настройки
нейросетевого регулятора с пакетным обновлением весовых коэффициентов
при котором в каждой эпохе повторяются одни и те же ряды уставки и
помехи.  Как показано на \figref{fig:ctrlloop}, эти два ряда полностью
определяют траекторию системы управления.  В реальных условиях ряд
$n(t)$ недоступен не только для формирования, но даже для измерения.
Однако в условиях имитационного эксперимента, проводимого на цифровом
компьютере, возможно сгенерировать и многократно использовать любой
псевдослучайный числовой ряд.  Пример графика среднеквадратической
ошибки в процессе обучения в идеальных условиях приведен на
\figref{fig:cerr_trace}б.  По форме графика видно, что влияние
случайных факторов на процесс обучения в таких условиях устранено
полностью, что делает идеальные условия обучения удобными для
проведения исследований.

График имеет характер убывающей экспоненты.  Он наглядно демонстрирует
недостижимость нулевой ошибки, поскольку асимптота графика
среднеквадратической ошибки всегда больше нуля.  Предсказать, какого
значения ошибки удастся добиться в процессе настройки искусственной
нейронной сети данной архитектуры на заданном обучающем множестве
невозможно.  По этой причине критерием завершения обучения
нейросетевого регулятора в идеальных условиях наиболее логично сделать
достижение некоторого порога уменьшения дискретной производной
$\Delta\MSE(t)$.  Порог выбирается так, чтобы дальнейшее продолжение
обучения перестало значимо уменьшать $\MSE$.

%\subsection{Влияние свойств нейросетевой модели}%
\label{nnp_on_nnc_influence}
В идеальных условиях дообучения НС--Р становится возможным в
имитационном эксперименте исследовать, как влияет нейросетевая модель
объекта управления на скорость и качество дообучения.  Степень этого
влияния осталась нерешенным вопросом методики синтеза НС--О
(п.~\ref{nnp_criteria_and_goal}).

Серия имитационных экспериментов проводилась с предварительно
настроенными нейросетевыми регуляторами и нейросетевыми моделями
объекта управления.  Для исследования влияния сложности архитектуры
НС--О на обучение НС--Р были взяты нейросети
$\NN^o_{1}(u_k,y_k,...,y_{k-D_y})$,
$\NN^o_{5,1}(u_k,y_k,...,y_{k-D_y})$,
$\NN^o_{5,3,1}(u_k,y_k,...,y_{k-D_y})$ с различным количеством входов
прошлых наблюдений объекта: $1\le D_y\le 3$.  В экспериментах
принимали участие нейросетевые регуляторы следующих архитектур:
$\NN^p_{1}(r_k,e_k)$, $\NN^p_{5,1}(r_k,e_k)$,
$\NN^p_{5,3,1}(r_k,e_k)$.  Для краткости будем далее использовать
обозначение $\NN^p_{r+e}$ вместо $\NN^p(r_k,e_k)$ и $\NN^o_{1+Dy}$
вместо $\NN^o_{1}(u_k,y_k,...,y_{k-D_y})$.

Эксперимент заключался в дообучении НС--Р в идеальных условиях по
одной из моделей.  Обучение завершалось при снижении скорости
уменьшения $\MSE$ ниже $10^{-5}$.  Длина эпохи (и обучающего временного
ряда) была равна 500.  Коэффициенты скорости обучения для скрытых и
выходных нейронов были взяты равными 0.005 и 0.0001 соответственно.

В качестве оценки скорости обучения НС--Р при различных НС--О было
взято количество эпох до завершения обучения.  Результаты представлены
на~\figref{fig:noc_epochs} в виде трех прозрачных поверхностей,
координата $z$ которых показывает длительность обучения в эпохах НС--Р
некоторой архитектуры, заданной парой $(x, y)$.  На горизональных осях
отложены изменяемые параметры архитектуры НС--О --- количество скрытых
слоев (0, 1, 2) и количество прошлых наблюдений $D_y$ (1, 2, 3),
подаваемых на вход нейросетевой модели объекта управления.  Данный
график показывает следующие закономерности:

\begin{figure}[h]
\centering
\begin{tabular}{rl}
  \begin{sideways}
    {\hspace{5.6cm}Эпохи}
  \end{sideways}
  &
  \includegraphics[width=0.8\textwidth,%
    totalheight=0.35\textheight]{noc_epochs}\\
\end{tabular}
\caption{Длительность дообучения НС--Р различных архитектур при различных
         архитектурах НС--О, использовавшихся для инверсии объекта управления.}
\label{fig:noc_epochs}
\end{figure}

\begin{enumerate}

\item
количество прошлых наблюдений $D_y$, подаваемых на вход НС--О, не
оказывает влияния на скорость обучения НС--Р;

\item
для простейшей архитектуры НС--Р $\NN^p_{r+e,1}$ скорость
обучения тем выше, чем проще архитектура НС--О;

\item
для более сложных архитектур НС--Р с одним или двумя скрытыми слоями
скорость обучения не зависит от сложности модели;

\item
более сложные архитектуры НС--Р обучаются быстрее, чем простые.

\end{enumerate}

Следует отметить, что в анализируемом графике приведены только данные
длительности обучения.  Как уже отмечалось, критерием завершения
обучения являлось не достижение некоторого желаемого уровня ошибки, а
снижение скорости сходимости оптимизационного алгоритма ниже заданного
порога.  Достигнутый же уровень ошибки в конце обучения на графике не
отражен.

Среднеквадратические ошибки, достигнутые при обучении, приводятся в
\tablref{tabl:noc_mse}.

\begin{table}[ht]
\centering
\caption{Качество дообучения НС--Р при различных НС--О.}
\label{tabl:noc_mse}
\begin{tabular}{|l|r|c|c|c|}
\hline
Нейросетевой & \multicolumn{4}{|l|}{ Нейросетевая модель } \\
\cline{3-5}
регулятор &  & $D_y=1$ & $D_y=2$ & $D_y=3$ \\[3pt]
\hline
          & $\NN^o_{1+Dy,1}$    & 0.0029 & 0.0029 & 0.0029 \\
$\NN^p_{r+e,1}$
          & $\NN^o_{1+Dy,5,1}$  & 0.0029 & 0.0029 & 0.0029 \\
          & $\NN^o_{1+Dy,5,3,1}$& 0.0029 & 0.0029 & 0.0029 \\[3pt]
\hline
          & $\NN^o_{1+Dy,1}$    & 0.0068 & 0.0068 & 0.0068 \\
$\NN^p_{r+e,5,1}$
          & $\NN^o_{1+Dy,5,1}$  & 0.0068 & 0.0068 & 0.0068 \\
          & $\NN^o_{1+Dy,5,3,1}$& 0.0068 & 0.0068 & 0.0068 \\[3pt]
\hline
          & $\NN^o_{1+Dy,1}$    & 0.0155 & 0.0155 & 0.0155 \\
$\NN^p_{r+e,5,3,1}$
          & $\NN^o_{1+Dy,5,1}$  & 0.0155 & 0.0155 & 0.0155 \\
          & $\NN^o_{1+Dy,5,3,1}$& 0.0155 & 0.0155 & 0.0155 \\[3pt]
\hline
\end{tabular}
\end{table}

Из данных, приведенных в таблице, видно, что достигаемый при
дообучении НС--Р уровень среднеквадратической ошибки зависит только от
архитектуры самого нейросетевого регулятора.  Зависимость от
архитектуры НС--О в экспериментах не была обнаружена.

%\subsection{Коэффициент скорости обучения}%
\label{batch_eta}
Коэффициент скорости обучения в классическом алгоритме обратного
распространения обычно подбирается эвристически, хотя и может быть
строго рассчитан~\cite[с.82--97]{terehov99}.  Следует отметить, что
часто применяемое пакетное обновление весовых коэффициентов ({\it
batch training}) требует иного значения коэффициента скорости
обучения, чем при обучении в тех же условиях, но классическим
алгоритмом обратного распространения:
Это уравнение определяет принцип обратного распространения и в нем нет
обучающей составляющей, так как весовые коэффициенты в нем неизменны.
Уравнение~\eqref{eq:deltaprop} справедливо для всех градиентных
методов обучения, в том числе для простейшего из них --- метода
обратного распространения ошибки.  В нем для обучения, то есть,
коррекции весовых коэффициентов, используется дельта-правило
\begin{equation}
\label{eq:weightchange}
  w^d_{ij}(k+1)=w^d_{ij}(k)-\eta\delta^d_i q^{d-1}_j
\end{equation} где $\eta$ --- коэффициент скорости обучения.  При
пакетном обновлении значения коррекции весовых коэффициентов
\begin{equation}\label{eq:weight-delta}
\Delta w^d_{ij}(k) = \eta\delta^d_i(k) q^{d-1}_j(k)
\end{equation}

\noindent рассчитываются на каждом шаге, но сами весовые коэффициенты
обновляются реже.  Шаг обновления называется эпохой ({\it epoch}).
Таким образом, при длительности эпохи $L$
уравнение~\eqref{eq:weightchange} будет выглядеть так:
\begin{equation}\label{eq:batch-weightchange}
w^d_{ij}(k+L)=w^d_{ij}(k)-\sum\limits_{p=1}^L \Delta w^d_{ij}(k+p-1)
\end{equation}

При постоянном в течение эпохи коэффициенте скорости обучения
кумулятивная коррекция весового коэффициента получается умножением
коэффициента скорости обучения на сумму произведений обобщенной ошибки
на выход нейрона:
$$
w^d_{ij}(k+L)=w^d_{ij}(k)-\eta\sum\limits_{p=1}^L
	\delta^d_i(k+p-1) q^{d-1}_j(k+p-1)
$$

Предположим, что коэффициент скорости обучения $\eta$ выбран
оптимально и что величины коррекции весовых коэффициентов на
протяжении эпохи постоянны: 
\begin{equation}\label{eq:equal-weights}
\Delta w^d_{ij}(k)=\Delta w^d_{ij}(k+1)=\ldots=\Delta w^d_{ij}(k+L-1)
\end{equation}

В этом случае выражение для кумулятивной величины коррекции
упрощается:
\begin{equation}\label{eq:product-weightchange}
w^d_{ij}(k+L)=w^d_{ij}(k)-\eta L \delta^d_i(k) q^{d-1}_j(k)
\end{equation}

Видно, что в этом случае коррекция веса $w^d_{ij}$ при том же
коэффициенте $\eta$ будет в $L$ раз больше, чем в классическом
алгоритме~\eqref{eq:weightchange}.  В случае продолжительной эпохи
($L=10^2\ldots 10^3$) это будет означать очень большое изменение
весового коэффициента, что обычно приводит к насыщению нейрона и
потере им способности к обучению.  Чтобы сохранить скорость и
устойчивость обучения классического алгоритма обратного
распространения в случае~\eqref{eq:equal-weights} следует взять
коэффициент $\eta$ меньшим в $L$ раз.

На практике различные обучающие пары дают различные величины коррекции
весовых коэффициентов.  Более того, эти величины могут иметь различные
знаки как из-за характера целевой функции, так и из-за наличия шумов в
обучающих данных.  Поэтому для сохранения желаемой динамики процесса
обучения нейронной сети достаточно уменьшить оптимальный коэффициент
$\eta$ в меньшее число раз, чем длительность эпохи $L$.

Уменьшение коэффициента скорости при пакетном обучении способствует
устойчивости алгоритма обратного распространения.  Это особенно важно
в тех случаях, когда обучение нейронной сети производится одновременно
с ее рабочим функционированием, как, например, при обучении
нейросетевого регулятора в контуре управления по инверсной модели.

При обучении многослойных нейронных сетей в задачах стохастического
оптимального управления оказалось целесообразным применять меньший
коэффициент скорости обучения в выходном слое сети по сравнению со
скрытыми слоями.  В результате анализа процесса обучения на многих
экспериментах было обнаружено, что коррекция весовых коэффициентов
выходных нейронов с линейной функцией активации оказывает наибольшее
влияние на устойчивость обучения.  Изменения этих весовых
коэффициентов должны осуществляться наиболее осторожно.  В то же
время, малые изменения в скрытых слоях приводят к слишком медленной
сходимости.  Практика показала, что изменения весовых коэффициентов в
скрытых слоях могут быть гораздо большими без потери алгоритмом
устойчивой сходимости.

Для небольших нейронных сетей (не более 10 нейронов в слое)
оптимальное соотношение коэффициента скорости обучения в скрытых слоях
$\eta_h$ к коэффициенту скорости обучения в выходном слое $\eta_o$
находится в диапазоне $2\ldots 10$.

%\subsection{Длительность эпохи в процессе дообучения}%
\label{nnc_final_epoch_length}
Одним из важных параметров методики обучения искусственных нейронных
сетей является длительность эпохи, в течении которой изменения весовых
коэффициентов не вносятся в нейросеть, а накапливаются (суммируются).
Обновление осуществляется только в конце эпохи.  Особенности выбора
коэффициента скорости обучения и его связь с длиной эпохи обсуждались
на с.~\pageref{batch_eta}.  Исследуем в имитационном эксперименте влияние
длительности эпохи на процесс дообучения нейросетевого регулятора в
случае стохастических $r(t)$ и $n(t)$.  Для этого были обучены НС--Р
при различных значениях длины эпохи $L$.  Сообразно длине эпохи были
выбраны коэффициенты скорости обучения в скрытых слоях $\eta_h=\eta/L$
и в выходном слое $\eta_o=\eta/2L$, причем базовое значение
коэффициента $\eta=1$ во всех сеансах обучения было взято одинаковым.

В случае проведения эксперимента в условиях, максимально приближенных
к реальным (постоянно изменяющиеся $r(t)$ и $n(t)$), выявить
устойчивые зависимости проблематично.  Для того, чтобы снизить влияние
случайных факторов, во-первых, эксперимент проводился в идеальных
условиях, во-вторых, каждый сеанс обучения повторялся при различных
выборках уставки и помехи 10 раз.

Условия проведения эксперимента:\label{nnc-final-case-cond}
\begin{itemize}
\item
Объект управления: $P^*(z)=\displaystyle\frac{z}{z-0.5}$

\item
Исходный регулятор: $C_{PID}^*(z)=0.4 +
		     0.5\displaystyle\frac{z}{z-1} +
		     0.05\displaystyle\frac{z^2-2z+1}{z(z-1)}$

\item
Формирующий фильтр уставки: $R^*(z)=\displaystyle\frac{0.625z}{z-0.779}$
\item
Помеха наблюдения: нормально распределенный белый шум \GaDi{0}{0.1}

\item
Архитектура НС--О: $\NN^o_{1+1,1}$
\item
Архитектура НС--Р: $\NN^p_{r+e,5,3,1}$

\item
Длительности эпохи: 5, 10, 25, 50, 100, 250, 500, 1000, 2500
\item
Длина тестовой выборки: 5000
\end{itemize}

Обучение проводилось с помощью одной и той же нейросетевой модели
объекта управления.  В качестве начального приближения был взят
предварительно настроенный подобно ПИД регулятору нейросетевой.

Критерием завершения процесса обучения считалось уменьшение
среднеквадратической ошибки управления за эпоху меньше чем на $10^{-5}$.
После завершения обучения все экземпляры НС--Р тестировались на одной
и той же тестовой выборке.

График финальной среднеквадратической ошибки в зависимости от
длительности эпохи приведен на \figref{fig:noc_mse(epochlen)}а.  На
нем представлены среднее значение (сплошная линия) и стандартное
отклонение (пунктирная линия) среднеквадратической ошибки управления
$\MSE_{final}$, на которой обучение было остановлено.  В силу малости
зафиксированного значения $\Delta\MSE<10^{-5}$ и экспоненциального
характера снижения ошибки дальнейшее обучение нецелесообразно, так как
оно уже не даст существенного улучшения качества управления.

На \figref{fig:noc_mse(epochlen)}б изображены графики среднего
значения (сплошная линия) и стандартного отклонения (пунктирная линия)
среднеквадратической ошибки управления $\MSE_{test}$, полученные на
длинной тестовой выборке.
\begin{figure}[h]
\centering
\begin{tabular}{lclc}
  \begin{sideways}
    {\hspace{0.7cm}\small Финальная ошибка управления}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{noc_c_tr_mse_L}
  &
  \begin{sideways}
    {\hspace{2.6cm}\small Ошибка}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{noc_test_mse_L} \\
  & {\small Длина эпохи} & & {\small Длина эпохи} \\
  & а) & & б)\\
\end{tabular}
\caption{Зависимость $\MSE$ от длительности эпохи по завершении обучения (а)
         и на тестовой выборке (б).}
\label{fig:noc_mse(epochlen)}
\end{figure}

При идеальных условиях обучения и малом размере обучающей выборки
(размер равен длине эпохи $L$) нейронная сеть проявляет свойство
адаптации к конкретной выборке в противоположность обобщающей
способности.  Это проявляется в том, что при $L<20$ имеет место
$\MSE_{final}<\MSE_{test}$.  Адаптированность НС--Р к конкретной
реализации обучающей выборки также подчеркивается высоким значением
стандартного отклонения при малых длинах эпохи.

Рассматривая график стандартного отклонения $\MSE_{test}$, полученный
по 10 сеансам обучения, следует отметить, что с увеличением длины
эпохи статистическая устойчивость результата обучения НС--Р
увеличивается (стандартное отклонение уменьшается), в то время как
начиная с $L=200$ среднее значение ошибки стабилизируется.  Очевидно,
это минимальное значение ошибки управления которого можно добиться при
выбранной архитектуре НС--Р и заданных внешних условиях.  Критичным
параметром, влияющим на уровень ошибки нейросетевого управления,
является уровень помехи.  Кроме того, свой вклад вносит неточность
оценки якобиана нейросетевой моделью.

Зависимость финальной ошибки идентификации от длины эпохи,
представленная на \figref{fig:id_err(epochlen)} средним значением и
стандартным отклонением, демонстрирует увеличение статистической
устойчивости нейросетевой идентификации с ростом $L$.  В целом,
большая длина эпохи способствует более точной оценке якобиана объекта
управления и, следовательно, более эффективному обучению НС--Р.
Однако, при увеличении $L$ больше 400 не наблюдалось
улучшения качества идентификации.
\begin{figure}[h]
\centering
\begin{tabular}{rc}
  \begin{sideways}
    {\hspace{1.8cm}\small Финальная ошибка идентификации}
  \end{sideways}
  &
  \includegraphics[width=0.8\textwidth,%
    totalheight=0.35\textheight]{noc_id_tr_mse_L} \\
  & Длина эпохи\\
\end{tabular}
\caption{Зависимость среднеквадратической ошибки идентификации в последней
  обучающей эпохе от длительности эпохи.}
\label{fig:id_err(epochlen)}
\end{figure}

Важной характеристикой процесса обучения является его суммарная
продолжительность.  На \figref{fig:training_dur(epochlen)}
представлена зависимость продолжительности обучения в дискретах
времени от длины эпохи.  Выявленный линейный характер зависимости
продолжительности (сплошная линия) от длины эпохи определяет временные
затраты на дообучение в среднем.  При $L=250$ линейный рост
стандартного отклонения (пунктирная линия), являющийся признаком
слабой статистической устойчивости, прекращается.  При продолжающемся
линейном росте среднего значения продолжительности это свидетельствует
о меньшем влиянии случайных факторов на процесс сходимости к
оптимальному нейросетевому управлению.
\begin{figure}[h]
\centering
\begin{tabular}{rc}
  \begin{sideways}
    {\hspace{2.5cm}\small Длительность обучения}
  \end{sideways}
  &
  \includegraphics[width=0.8\textwidth,%
    totalheight=0.35\textheight]{noc_tr_dur_L}\\
  & {\small Длина эпохи}
\end{tabular}
\caption{Зависимость продолжительности обучения от длительности эпохи.}
\label{fig:training_dur(epochlen)}
\end{figure}

Подводя итоги проведенного эксперимента можно рекомендовать длину
эпохи при дообучении НС--Р в пределах от 200 до 500.  При меньших
значениях $L$ качество нейросетевого регулятора и статистическая
устойчивость его достижения оставляют желать лучшего.  При больших
значениях $L$ увеличение суммарной продолжительности обучения уже не
приводит к существенному улучшению получаемого в результате НС--Р.
Выявленные качественные зависимости позволяют подобрать оптимальное
значение длительности эпохи в каждом конкретном случае.

%\subsection{Дообучение в реальных условиях}
\section{Обучение нейросетевого оптимального регулятора в реальных условиях}

Выбор параметров алгоритма обучения НС--Р в контуре управления
(длительность эпохи, коэффициент скорости обучения) обсуждался в
предыдущих параграфах.  Наиболее актуальными задачами, требующими
разрешения при дообучении НС--Р в реальных условиях, представляются:
\begin{itemize}

\item
исследование поведения среднеквадратической ошибки управления и
идентификации в процессе дообучения с целью выяснения характера и
пределов их изменения;

\item
зависимость качества управления НС--Р после дообучения от качества
управления исходного ПИД регулятора;

\item
определение момента достижения нейросетевым регулятором наилучшего
качества управления с целью остановки процесса дообучения.

\end{itemize}

%\subsection{Поведение среднеквадратической ошибки}%

\label{noc_cmse_online}%
Продолжим серию имитационных экспериментов в условиях, описанных на
\pgref{nnc-final-case-cond}.  Теперь будем проводить дообучение
НС--Р в контуре управления в реальных условиях, то есть, при постоянно
изменяющихся в соответствии с условленными спектрами сигналах уставки
и помехи.  В соответствии с выводами п.~\ref{nnc_final_epoch_length},
длительность эпохи обучения возьмем равной 500 дискретным отсчетам
времени.  Используя возможности, имеющиеся в имитационном, но
недоступные в физическом эксперименте, по окончании каждой эпохи
обучения будем проверять качество управления на одной и той же
достаточно длинной тестовой выборке (5000 дискретных отсчетов
времени).

Учитывая отличие в способности к обучению нейросетевых архитектур
различной сложности, обнаруженное при настройке НС--О и НС--Р вне
контура управления, будем проводить имитационные эксперименты с
нейросетевыми регуляторами $\NN^p_{r+e,1}$,
$\NN^p_{r+e,5,1}$, $\NN^p_{r+e,5,3,1}$.\label{nnc-pid1-pid2}

Предварительное обучение НС--Р вне контура управления будем проводить
по двум исходным ПИД регуляторам с заведомо различным качеством
управления.  Первый ПИД регулятор $PID_1$ имеет параметры,
подобранные для минимизации времени переходного процесса и
перерегулирования.  Второй ПИД регулятор $PID_2$, напротив,
приводит к длительному переходному процессу со значительным
перерегулированием.  Параметры этих регуляторов приводятся ниже:

$$
C^*_{PID_1}(z)=0.4 + 0.5\displaystyle\frac{z}{z-1} +
               0.05\displaystyle\frac{z^2-2z+1}{z(z-1)}
$$

$$
C^*_{PID_2}(z)=0.5 + 0.8\displaystyle\frac{z}{z-1} +
               0.1\displaystyle\frac{z^2-2z+1}{z(z-1)}
$$

Траектории среднеквадратической ошибки управления, характеризующие
процесс дообучения НС--Р в течение 200 эпох ($200\times500=10^5$
дискретных отсчетов времени), представлены на
\figref{fig:noc_cerr_online_training}.  Слева показаны графики для
НС--Р, предварительно настроенного по $PID_1$, справа --- по
$PID_2$.  На каждом из графиков горизонтальная линия обозначает
уровень $\MSEmin=0.00975$, обеспечиваемый винеровским оптимальным
регулятором.
\begin{figure}
\centering
\begin{tabular}{cc}
%\multicolumn{2}{c}{Среднеквадратическая ошибка на эпохе обучения ($L=500$)} \\
\includegraphics[width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_ol_cerr_train} &
\includegraphics[width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_bad_ol_cerr_train} \\
{\small Эпохи} & {\small Эпохи}\\
а) & б)\\
%\multicolumn{2}{c}{Среднеквадратическая ошибка на тестовой выборке (длина 5000)} \\
\includegraphics[width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_ol_cerr_test} &
\includegraphics[width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_bad_ol_cerr_test} \\
{\small Эпохи} & {\small Эпохи}\\
в) & г)\\
\end{tabular}
\caption{Траектории среднеквадратической ошибки управления при дообучении НС--Р
         различных архитектур и двух исходных ПИД регуляторах:
         субоптимальном $PID_1$ (а,в), заведомо неоптимальном $PID_2$ (б,г).}
\label{fig:noc_cerr_online_training}
\end{figure}

На верхних графиках \figref{fig:noc_cerr_online_training} представлены
траектории среднеквадратической ошибки на эпохе ($\MSE_{epoch}(t)$).
Случайный характер траекторий объясняется случайным сигналом уставки и
помехи.  Каждая эпоха представляет собой новое обучающее множество, по
которому алгоритм обучения рассчитывает коррекцию весовых
коэффициентов.  Траектория $\MSE_{epoch}(t)$ может быть получена в
физическом эксперименте.

На нижних графиках \figref{fig:noc_cerr_online_training} изображены
траектории среднеквадратической ошибки ($\MSE_{test}(t)$), рассчитанной
по длинной тестовой выборке $(r_k,n_k)_{5000}$ после обновления весовых
коэффициентов в конце эпохи.  Для этого пары значений $r_k,n_k$
последовательно подаются на вход независимой копии контура управления
с актуальными весовыми коэффициентами НС--Р.  Ввиду того, что тестовый
набор данных один и тот же, траектория среднеквадратической ошибки не
имеет заметных случайных флуктуаций.  Данная траектория не может быть
получена в физическом эксперименте.  Она отражает качество
функционирования НС--Р в том случае, если бы дообучение было
прекращено в эпоху $t$.

Анализ процесса дообучения НС--Р в физических условиях позволяет сделать
следующие выводы:
\begin{enumerate}

\item
Нейросетевой регулятор в входами $r_k,e_k$ может обеспечить лучшее
качество управления, чем линейный оптимальный регулятор, дополняющий
контур управления до винеровского фильтра.  Архитектура нейронной сети
регулятора может быть как очень простой ($\NN^p_{r+e,1}$), так
и достаточно сложной ($\NN^p_{r+e,5,3,1}$).

\item
Значение среднеквадратической ошибки на эпохе $\MSE_{epoch}(t)$ в
процессе дообучения не дает представления о качестве управления,
реализуемым текущим состоянием НС--Р.

\item
Время достижения заданного уровня $\MSE$ при дообучении НС--Р тем
больше, чем сложнее архитектура нейронной сети регулятора.

\item
Чем ближе исходный линейный регулятор к винеровскому оптимальному, тем
менее заметен процесс дообучения НС--Р на траектории
$\MSE_{epoch}(t)$.  В частности, в приведенном на
\figref{fig:noc_cerr_online_training}а примере, тренд уменьшения
$\MSE_{epoch}(t)$ совсем незаметен, так как исходный ПИД регулятор
имеет параметры, близкие к оптимальным.

\item
Скорость уменьшения $\MSE_{test}(t)$ ниже определенного значения
становится незаметной на траектории $\MSE_{epoch}(t)$.

\end{enumerate}

Траектории среднеквадратической ошибки идентификации в процессе
дообучения НС--Р приводятся на
~\figref{fig:noc_iderr_online_training}.  Очевидна связь с
траекториями $\MSE_{epoch}(t)$, так как уменьшение среднеквадратической
ошибки идентификации происходит одновременно с уменьшением
$\MSE_{epoch}(t)$.  Аналогично, фаза дообучения, характеризующаяся
статистически постоянным уровнем $\MSE_{epoch}(t)$, имеет постоянную в
среднем величину среднеквадратической ошибки идентификации
(\figref{fig:noc_cerr_online_training}).

\begin{figure}[h]
\centering
\begin{tabular}{cc}
\includegraphics[width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_ol_iderr_train} &
\includegraphics[width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_bad_ol_iderr_train} \\
{\small Эпохи} & {\small Эпохи}\\
а) & б)\\
\end{tabular}
\caption{Траектории среднеквадратической ошибки идентификации при дообучении НС--Р
         различных архитектур и двух исходных ПИД регуляторах:
         субоптимальном $PID_1$(а), заведомо неоптимальном $PID_2$(б).}
\label{fig:noc_iderr_online_training}
\end{figure}

%\subsection{Влияние качества исходного НС--Р}

Обобщение результатов проведенных экспериментов с различными исходными
ПИД регуляторами и различными архитектурами НС--Р позволяет сделать
вывод о значительном влиянии качества предварительной настройки
нейросетевого регулятора как на скорость дообучения, так и на качество
обученного НОР.  В частности, отмечено, что близость исходного
регулятора к винеровскому оптимальному позволяет отказаться от этапа
дообучения НС--Р с простой архитектурой (варианты
$\NN^p_{r+e,1}$ и $\NN^p_{r+e,5,1}$).  Дообучение в
этих случаях лишь незначительно улучшает качество управления системой.

В то же время, нейросетевой регулятор со сложной трехслойной
архитектурой (вариант $\NN^p_{r+e,5,3,1}$) требует дообучения,
так как после этапа предварительного обучения качество нейросетевого
управления может оказаться все еще хуже винеровского
(\figref{fig:noc_cerr_online_training}в).  Предварительно настроенный
по почти оптимальному линейному, нейросетевой регулятор демонстрирует
медленную сходимость.  Это вызвано тем, что начальная точка в
пространстве весовых коэффициентов, соответствующая имитации исходного
регулятора, оказывается далеко от минимума, достижимого нейронной
сетью в процессе дообучения.  Основной причиной эффекта плохой
дообучаемости НС--Р начиная с линейного субоптимального решения
является различие между линейным и нейросетевым оптимальным решением
задачи управления в одних и тех же условиях.

В случае значительной неоптимальности исходного регулятора, очевидно,
качество нейросетевого управления после этапа предварительно обучения
оставляет желать лучшего (\figref{fig:noc_cerr_online_training}г).
Однако, полученная нейронная сеть за достаточно короткое время,
зависящее от сложности архитектуры, достигает качества управления
винеровского регулятора.  Нейросетевые регуляторы с простой
архитектурой достаточно быстро достигают того же уровня ошибки
управления, что и НС--Р, обучавшиеся с имитации оптимального ПИД
регулятора.  НС--Р трехслойной архитектуры закономерно обучается
медленнее простых нейросетей, но, сравнивая траектории
$\MSE_{test}(t)$ в случаях $PID_1$ и $PID_2$, видно, что
во втором случае скорость сходимости выше, чем в первом.

Опираясь на результаты проведенных имитационных экспериментов, а
также, анализируя обучение нейросетевого регулятора в контуре
управления мобильным роботом (глава~\ref{mobile_robot}), можно
утверждать, что оптимальное линейное управление или близкое к нему
является худшим стартом для дообучения нейросетевого регулятора, чем
управление значительно худшего качества.  Данное утверждение
обосновывает приоритетное применение нейросетевого управления именно в
тех случаях, когда объект управляется по закону, далекому от
оптимального.

Этот феномен может быть объяснен тем, что линейное оптимальное решение
для нейросетевого регулятора является локальным минимумом на
многомерной поверхности ошибки из которого ему трудно выбраться с
помощью градиентных методов обучения.  Неоптимальное решение,
напротив, расположено далеко от этого минимума и у нейросети есть
гораздо больший простор для поисков нелинейного оптимального решения.

С практической точки зрения получается, что лучше всего внедрять
нейросетевое оптимальное управление там, где не проводилась
систематическая работа по оптимизации параметров линейного регулятора.
Это достаточно разумная практика, поскольку автоматическая оптимизация
вряд ли окажется лучше, чем выполненная вручную с привлечением всех
возможностей человеческого интеллекта включая аналитические методы и
использование вспомогательной информации о системе управления.

%\subsection{Критерий завершения дообучения в реальных условиях}

Естественным критерием завершения процесса синтеза НОР является
достижение заданного качества регулирования, то есть,
среднеквадратической ошибки.  Однако, как уже отмечалось, траекторию
$\MSE_{test}(t)$, дающую представление об актуальном качестве
управления нейросетевого регулятора, в физическом эксперименте
получить невозможно.  Доступная в физических условиях траектория
$\MSE_{epoch}(t)$ не дает представления о достигнутом нейросетевым
регулятором качестве управления.  Тем не менее, результаты
имитационного исследования позволяют сформулировать рациональный
критерий завершения процесса дообучения.

Перечислим некоторые априорные соображения, дополняющие эмпирические
гипотезы.
Во-первых, отметим, что априорно заданная целевая среднеквадратическая
ошибка нейросетевого управления может оказаться недостижимой в силу
высокого уровня помех.  Аналитический расчет минимально достигаемого
значения ошибки для произвольно взятой архитектуры НС--Р невозможен
из-за неразвитости теоретического базиса нейросетевого и нелинейного
стохастического управления.  Поэтому, наиболее реалистичной
постановкой задачи нейросетевого оптимального управления в винеровских
условиях является {\it улучшение} качества управления {\it до
возможного предела} без числовой конкретизации требуемых результатов.

Во-вторых, учитывая экспоненциальный характер траектории эффективной
среднеквадратической ошибки $\MSE_{test}(t)$, стремление к
асимптотическому значению потребует бесконечно длительного обучения.
Поэтому разумно остановить дообучение тогда, когда его продолжение не
даст значительного снижения уровня ошибки.

Обобщая выявленные эмпирические зависимости и приведенные выше
соображения, предлагается использовать в качестве критерия завершения
обучения НОР в контуре управления постоянство среднего значения
$\MSE_{epoch}(t)$ на некотором интервале обучающих эпох.

Траектория $\MSE_{epoch}(t)$ рассматривается как временной ряд.  В
основе предложенного критерия лежит гипотеза о том, что этот ряд
образован аддитивным влиянием двух факторов: долговременного и
случайного.  Экспоненциально убывающий характер среднеквадратической
ошибки управления в процессе обучения НОР является долговременным
фактором, которым можно пренебречь в случае приближения эффективной
$\MSE$ к асимптотическому значению.  При отсутствии заметного тренда
усреднение $\MSE_{epoch}(t)$ станет постоянным.

Для проверки гипотезы $H_{const}$ постоянства среднего значения
временного ряда можно воспользоваться любым из методов, предлагаемых в
литературе по данному вопросу (например,
\cite{jenkwatts71,aivmhit98}).  Рассмотрим применение изложенного
критерия для примера, приведенного на \pgref{nnc-final-case-cond}.
Проверим гипотезу $H_{const}$ с помощью приближенного критерия серий,
основанного на медиане (\cite[с.~797--799]{aivmhit98}).  Уровень
значимости критерия $\alpha$ (вероятность отвергнуть верную гипотезу)
возьмем равным 5\%.

% также \cite[с.~108--109]{jenkwatts71}

Оценку постоянства среднего значения $\MSE_{epoch}(t)$ следует
проводить на интервале последовательных эпох обучения.  Очевидно, чем
длиннее этот интервал, тем меньше вероятность ошибочного принятия
гипотезы.  Однако, более длительный интервал может привести к
малоэффективному обучению вблизи к асимптотического значения ошибки.

Возьмем длину интервала равной 50 эпохам.  Тогда общая длительность
процесса обучения, описанного на \pgref{nnc-pid1-pid2}, делится на 4
интервала.  В \tablref{tabl:nnc_finish_criteria} приведены результаты
проверки гипотезы о постоянстве среднего значения $\MSE_{epoch}(t)$
для всех трех нейросетевых архитектур и обоих исходных регуляторов.
Работоспособность метода оценки момента завершения обучения будем
проверять по известным траекториям $\MSE_{test}(t)$.

\begin{table}[h]
\centering
\caption{Проверка гипотезы о постоянстве среднего значения $\MSE_{epoch}(t)$
         на интервалах обучающих эпох.}
\label{tabl:nnc_finish_criteria}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Исходный & НС--Р &\multicolumn{4}{|c|}{$H_{const}$ в интервалах эпох обучения} \\
\cline{3-6}
регулятор &      & 1\dots50 & 51\dots100 & 101\dots150 & 151\dots200 \\
\hline
   & $\NN^p_{r+e,1}$ & верна & - & - & - \\
$PID_1$ & $\NN^p_{r+e,5,1}$ & верна & - & - & - \\
   & $\NN^p_{r+e,5,3,1}$ & не верна & не верна & не верна & верна \\
\hline
   & $\NN^p_{r+e,1}$ & не верна & не верна & верна & - \\
$PID_2$ & $\NN^p_{r+e,5,1}$ & не верна & не верна & не верна & не верна \\
   & $\NN^p_{r+e,5,3,1}$ & не верна & не верна & не верна & не верна \\
\hline
\end{tabular}
\end{table}

Возвращаясь к \figref{fig:noc_cerr_online_training}, видим, что
гипотеза оказалась верной уже в первом интервале эпох для исходного
регулятора $PID_1$, близкого к оптимальному, и НС--Р простой одно- и
двухслойной архитектуры.  Статистический критерий подтверждает слабую
обучаемость НС--Р в этом случае.  В случае сложной трехслойной
архитектуры гипотеза $H_{const}$ оказалась верной только на четвертом
интервале эпох обучения.

В случае неоптимального исходного регулятора $PID_2$ предложенный
критерий указал на достаточность обучения в третьем интервале для
однослойного НС--Р.  Более сложные нейросетевые регуляторы следует
обучать дальше, так как на траектории $\MSE_{epoch}(t)$ имеется
малозаметный тренд.

Отметим случаи НС--Р $\NN^p_{r+e,5,3,1}$ при различных исходных
регуляторах.  Опираясь на знание траекторий $\MSE_{test}(t)$ можно
было бы сделать вывод о предпочтительности обучения в случае исходного
$PID_1$, так как ошибка управления все еще велика.  Однако, не следует
забывать, что траектория $\MSE_{test}(t)$ получена по одной выборке и
не дает точного значения качества нейросетевого управления $\MSE$ на
всей генеральной совокупности.  Не исключено, что в случае иной
тестовой выборки скорость уменьшения ошибки $\NN^p_{r+e,5,3,1}$ для
$PID_1$ окажется значительно меньше, чем оказалось на
\figref{fig:noc_cerr_online_training}в, а значит, столь незначительный
спад становится уже статистически незаметным на наблюдаемой траектории
$\MSE_{epoch}(t)$.

Проверка предложенного критерия в нескольких подобных имитационных
экспериментах с различными параметрами исходной системы управления
подтвердила эффективность определения момента уменьшения производной
ошибки $\MSE_{test}(t)$ по наблюдаемой траектории $\MSE_{epoch}(t)$.

\section{Пример с линейным объектом третьего порядка}\label{plant_3rd_order}

\input{noc_for_3rd_order_plant.tex}

\section{Сравнение с винеровским оптимальным регулятором}

Известным частным случаем линейной теории автоматического управления
является винеровская фильтрация.  Она позволяет аналитически построить
физически реализуемый оптимальный линейный фильтр для восстановления
сигнала в присутствии помехи, при этом спектральные характеристики
стохастического сигнала и помехи должны быть известны.

Имея заданную переходную функцию объекта управления, несложным
аналитическим преобразованием можно получить переходную функцию
регулятора по отклонению, который дополняет систему с обратной связью
до винеровского оптимального фильтра.  Таким образом, регулятор
обладает свойством оптимальности по среднеквадратическому критерию в
классе линейных систем.

Известны недостатки винеровского оптимального регулятора
\cite{solod60,skliar65,medv82,leondes70}:
\begin{itemize}
\item не для любого объекта управления регулятор физически реализуем;
\item регулятор находится на границе устойчивости, то есть, не обладает свойством робастности;
\item для синтеза необходима аналитическая идентификация сигналов и объекта управления;
\item качество управления существенно зависит от точности идентификации сигналов и объекта управления.
\end{itemize}

Тем не менее, винеровский оптимальный регулятор (ВОР) представляет
собой эталон, с которым целесообразно сравнивать алгоритмы управления.
Представляется важным провести сравнение и с нейросетевым оптимальным
регулятором.  Поскольку при синтезе обоих регуляторов применяется
среднеквадратический критерий, их сопоставление позволит выявить
особенности нейросетевого управления по сравнению с линейным.

Такое сравнение было проведено в ряде имитационных экспериментов.
Номинальные параметры системы управления, использовавшиеся при синтезе
ВОР, а также при имитационном моделировании и обучении нейросетевого
оптимального регулятора приводятся ниже:

Передаточная функция фильтра уставки:
\begin{equation}
R^*(z)=\frac{0.625z}{z-0.779}
\end{equation}

Передаточная функция фильтра помехи:
\begin{equation}
N^*(z)=0.1
\end{equation}

В описанном случае винеровский фильтр имеет переходную функцию:
\begin{equation}
W^*(z)=\frac{0.975z}{z-0.0192}
\end{equation}

%Среднеквадратическая ошибка винеровской фильтрации составляет
%$\MSE=0.00975$.

Для реализации оптимального управления $C_w^*(z)$ заданным объектом с
переходной функцией $P^*(z)$ имеем:
\begin{equation}
W^*(z)=\frac{C_w^*(z)P^*(z)}{1+z^{-1}C_w^*(z)P^*(z)}
\end{equation}
\noindent откуда следует:
\begin{equation}
C_w^*(z)=\frac{W^*(z)}{P^*(z)(1-z^{-1}W^*(z))}
\end{equation}

Если передаточная функция объекта управления:
\begin{equation}
P^*(z)=\frac{z}{z-0.5}
\end{equation}
\noindent то винеровский оптимальный регулятор физически реализуем
и имеет следующую передаточную функцию:
\begin{equation}
C_w^*(z)=\frac{0.975z-0.4875}{z-0.9942}
\end{equation}

Нейросетевой оптимальный регулятор имеет архитектуру
$\NN^p_{5,1}(r_k,e_k)$ и синтезирован по изложенной методике.

Фрагмент графиков уставки и наблюдаемого выхода объекта приводятся
на \figref{fig:woc_vs_noc_stoch_orig_eps_rus}.

\begin{figure}[h]
  \centering
  \begin{tabular}{cc}
    \includegraphics[width=0.47\textwidth,%
      totalheight=0.2\textheight]{woc_stoch_orig_eps_rus}
    &
    \includegraphics[width=0.47\textwidth,%
      totalheight=0.2\textheight]{noc_stoch_orig_eps_rus} \\
    а) & б)
  \end{tabular}
  \caption{Сравнение винеровского (а) и нейросетевого (б) оптимального регуляторов в номинальных стохастических условиях.}%
  \label{fig:woc_vs_noc_stoch_orig_eps_rus}
\end{figure}

Для изучения влияния неточной идентификации параметров уставки был
проведен эксперимент, в котором $R^*(z)=\frac{0.7z}{z-0.9}$.  Графики
уставки и наблюдаемого выхода объекта в этом случае приводятся
на \figref{fig:woc_vs_noc_stoch_diff_eps_rus}.

\begin{figure}[h]
  \centering
  \begin{tabular}{cc}
    \includegraphics[width=0.47\textwidth,%
      totalheight=0.2\textheight]{woc_stoch_diff_eps_rus}
    &
    \includegraphics[width=0.47\textwidth,%
      totalheight=0.2\textheight]{noc_stoch_diff_eps_rus} \\
    а) & б)
  \end{tabular}
  \caption{Сравнение винеровского (а) и нейросетевого (б) оптимального регуляторов в условиях изменившихся параметров стохастической уставки.}%
  \label{fig:woc_vs_noc_stoch_diff_eps_rus}
\end{figure}

Важным практическим случаем является использование нестохастической
уставки.  Были проведены эксперименты с гармоническим сигналом уставки
(\figref{fig:woc_vs_noc_harmonic_eps_rus}) и с уставкой в форме
меандра (\figref{fig:woc_vs_noc_meander_eps_rus}).

\begin{figure}[h]
  \centering
  \begin{tabular}{cc}
    \includegraphics[width=0.47\textwidth,%
      totalheight=0.2\textheight]{woc_harmonic_eps_rus}
    &
    \includegraphics[width=0.47\textwidth,%
      totalheight=0.2\textheight]{noc_harmonic_eps_rus} \\
    а) & б)
  \end{tabular}
  \caption{Сравнение винеровского (а) и нейросетевого (б) оптимального регуляторов при гармонической уставке.}%
  \label{fig:woc_vs_noc_harmonic_eps_rus}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{tabular}{cc}
    \includegraphics[width=0.47\textwidth,%
      totalheight=0.2\textheight]{woc_meander_eps_rus}
    &
    \includegraphics[width=0.47\textwidth,%
      totalheight=0.2\textheight]{noc_meander_eps_rus} \\
    а) & б)
  \end{tabular}
  \caption{Сравнение винеровского (а) и нейросетевого (б) оптимального регуляторов при уставке в форме меандра.}%
  \label{fig:woc_vs_noc_meander_eps_rus}
\end{figure}

Численные результаты сравнения регуляторов по параметру максимального
перерегулирования и среднеквадратической ошибки приведены в
таблице~\ref{tabl:woc_vs_noc_statistics}.  Видно, что в проведенных
экспериментах нейросетевой оптимальный регулятор демонстрирует лучшее
качество управления, чем винеровский, как в номинальных, так и в
отличающихся условиях.  Однако следует иметь в виду, что при выходе
сигналов уставки и ошибки за пределы зоны амплитуд, в которой обучался
нейросетевой регулятор, его качество управления существенно упадет.

\begin{table}
  \centering
  \caption{Качество управление винеровского и нейросетевого регуляторов.}
  \label{tabl:woc_vs_noc_statistics}
  \begin{tabular}{|l|c|c|c|c|}
    \hline
    Параметр & \multicolumn{2}{|c|}{$|e|_{max}$} & \multicolumn{2}{|c|}{$\MSE$} \\
    \hline
    Регулятор                  & ВОР   & НОР   & ВОР   & НОР \\
    \hline
    Номинальные условия        & 2.496 & 1.429 & 0.460 & 0.158 \\
    Другие параметры уставки   & 2.794 & 1.582 & 0.537 & 0.182 \\
    Гармоническая уставка      & 0.721 & 0.492 & 0.068 & 0.027 \\
    Уставка--меандр            & 2.298 & 1.336 & 0.404 & 0.134 \\
    \hline
  \end{tabular}
\end{table}

Также следует особо отметить, что винеровский оптимальный регулятор
был синтезирован аналитически, а нейросетевой --- в результате
настройки с использованием данных, полученных из функционирующей
системы управления.  Единственным несущественным ограничением
предложенной методики синтеза НОР является то, что он не может быть
настроен вне контура управления, так как используется модель
предсказания, а не поведения объекта.  В то же время, модель
предсказания не содержит обратных связей, что делает её принципиально
более устойчивой в отличие от возможных нейросетевых моделей
поведения, имеющих обратные связи.

Таким образом, при лучшем качестве управления и робастности НОР более
удобен для практического применения в реальных системах управления,
чем винеровский, так как он не требует аналитической идентификации
параметров системы.

Учитывая результаты нейросетевого управления нелинейным объектом,
приведенные в п.~\ref{nonlinear_nnc}, есть уверенность, что возможно
применить предложенную методику синтеза НОР и в нелинейном случае, что
существенно превышает возможности винеровской фильтрации.

\section{Выводы}

\begin{enumerate}
\item Разработана методика синтеза нейросетевого оптимального
  регулятора с помощью нейросетевой инверсии объекта управления.  В
  качестве начального приближения используется нейросетевой регулятор,
  который можно обучить по методике, изложенной в
  главе~\ref{linear_to_neural}.
\item Представлена методика синтеза нейросетевой предсказывающей модели объекта
  управления на основе многослойного персептрона, пригодной для
  нейросетевой инверсии по методу обратного распространения ошибки.
  Обучение модели проводится вне контура управления.
\item Рассмотрен ряд методических вопросов, касающихся специфики
  нейросетевой идентификации: выбор номенклатуры и числа входов,
  структуры сети, вида пробного сигнала, частотные свойства
  нейросетевой модели, статистическая устойчивость процесса обучения
  НС--О.
\item Обсуждаются методические вопросы процесса обучения нейросетевого
  оптимального регулятора в контуре управления.  В частности,
  исследовано влияние НС--О на процесс обучения, определены
  закономерности поведения среднеквадратической ошибки управления,
  предложены рекомендации по выбору коэффициента скорости обучения и
  длины эпохи, а также критерий завершения обучения НОР.
\item На примере показана успешная применимость методик синтеза
  нейросетевого аналога ПИД регулятора и нейросетевого оптимального
  регулятора для объекта третьего порядка.
\item Проведено сравнение нейросетевого оптимального регулятора с
  винеровским, показавшее преимущество нейросетевого как в
  номинальных, так и в отличающихся условиях.
\end{enumerate}
