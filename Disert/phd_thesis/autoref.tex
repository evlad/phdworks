% -*-coding: cp1251;-*-
% Содержание работы для автореферата

\textbf{Во Введении} обоснована актуальность диссертационной работы,
сформулирована цель и аргументирована научная новизна исследований,
показана практическая значимость полученных результатов, представлены
выносимые на защиту научные положения.

\textbf{В первой главе} на основе публикаций проведен систематический
анализ областей применения нейронных сетей в системах автоматического
управления (САУ).  Отмечено частое использование нейронных сетей (НС)
для управления промышленными технологическими процессами, а также в
робототехнике.  Ключевыми преимуществами нейронных сетей в этих
случаях являются обучение на примерах, не требующее аналитической
идентификации, и нелинейная природа, адекватная нелинейным объектам.

Основными и наиболее перспективными ролями НС общепризнано считается
их использование в качестве регулятора (в том числе, с регулятором
другого типа) и модели объекта управления.  Прочие варианты (настройка
регулятора другого типа, классификация состояний объекта и пр.), судя
по публикациям, используются существенно реже.

При проектировании нейросетевых систем управления возникают следующие
вопросы:
\begin{enumerate}\label{main-nn-questions}
\item Какие входы и выходы и в каком количестве должны быть у НС?
\item Какова должна быть внутренняя архитектура нейросети?
\item Какими данными должна обучаться нейросеть?
\item Какой метод обучения должен использоваться?
\item Когда целесообразно остановить процедуру обучения?
\end{enumerate}

В целом, эти вопросы характерны и для других областей применения НС,
однако однозначных ответов на них в теории нейронных сетей нет, а
имеющиеся теоретически обоснованные подходы к их решению ориентированы
на задачи распознавания, классификации и ассоциативной памяти, сильно
отличающиеся от динамических САУ.  В частности, существуют разные
варианты наборов входов многослойного персептрона, определяющие его
динамические свойства в качестве регулятора и модели объекта, а
формирование обучающего множества для динамического объекта плохо
формализуется аналогией с распознаванием заданного числа образов.

В дополнение к перечисленным вопросам существует нерешенная задача
систематического сопоставления НС с другими подходами, в частности, с
ПИД регуляторами.  В публикациях данная тема, как правило,
затрагивается только с позиций показа преимуществ нейросетевых
регуляторов, в то же время очевидно, что любой подход должен иметь
свои ограничения и недостатки.

Другим неисследованным объектом сопоставления является линейный
винеровский оптимальный регулятор.  Критерий его синтеза --- минимум
среднеквадратической ошибки управления (СКО) --- совпадает с критерием
обучения нейросетевого регулятора в контуре управления во многих
публикациях как в стационарных, так и нестационарных условиях.  Однако
такого сопоставления никто не проводил, несмотря на его корректность,
а также очевидное научное и практическое значение.

Незавершенность теории НС делает обоснованным использование
разнообразных эвристик, а также применение имитационного эксперимента
как основного метода исследований.  Это характерно для большинства
опубликованных работ.  В то же время, авторы редко аргументируют
причины принятия тех или иных решений, а некоторые аспекты, например,
формирование обучающей выборки, почти всегда остаются за рамками
публикации.

Учитывая эвристический характер проектирования нейросетевых систем
управления, особое значение приобретают программнные инструментальные
средства, позволяющие быстро и удобно настраивать и моделировать такие
системы, а также оценивать качество управления в сравнении с
традиционными подходами.  Для использования в учебном процессе такие
программы должны быть просты в освоении, иметь скромные требования к
производительности компьютера и, что весьма желательно, базироваться
на открытых и бесплатных технологиях.

\textbf{Во второй главе} рассматривается методика синтеза
нейросетевого аналога ПИД регулятора в системе управления с одномерным
линейным объектом.  Пусть $e_k$ --- ошибка управления в момент времени
$t_k$, $u_k$ --- управляющее воздействие на объект, а
$f(e_k,\mathbf{s})$ --- функция ПИД регулятора ($\mathbf{s}$ --- его
состояние).  Для обучения нейросетевого аналога ПИД регулятора
вне контура управления решалась оптимизационная задача вида:
\begin{equation}\label{eq:nnc_synthesis_task}
  \sum\limits_k\big(f(e_k,\mathbf{s})-\NN^p(\mathbf{i}_k)\big)^2
  \rightarrow\min\limits_{\forall\mathbf{i}_k\in\mathbf{I}}
\end{equation}

\noindent где $\NN^p$ --- функция НС со структурой многослойного
персептрона, $\mathbf{i}_k$ --- значения на входах нейросети,
$\mathbf{I}$ --- область возможных значений входов для регулятора.
Данная задача нейросетевой аппроксимации неизвестной таблично заданной
функции $f$ имеет типовое решение градиентным методом (например, {\em
  back-propagation of error}), однако говорить о методике синтеза
можно, только ответив на вопросы, перечисленные
на~\pgref{main-nn-questions}.

Эксперименты с различными наборами входов НС--Р выявили зависимость
ошибки имитации от вида рабочего изменения уставки.  Для постоянной
уставки $r_k=const$ оптимальным выбором являются $e_k\ldots e_{k-d}$ и
$e_k,\Delta e_k$, где $d$ --- длительность переходного процесса в
исходной САУ в отсчетах.  Для переменной уставки наилучший результат
дают входы $r_k,e_k$.  Для кусочно--постоянной уставки наилучшим
является вариант $r_k,e_k\ldots e_{k-d}$.

При использовании правильно подобранной структуры входов зависимости
качества имитации от количества слоев НС--Р и нейронов в них не было
обнаружено.  В этой связи представляется целесообразным использовать
простые двух- и трехслойные сети, теоретически обеспечивающие
аппроксимацию произвольной функции.  Выбор алгоритма обучения НС также
не оказывает существенного влияния на ошибку имитации и управления
НС--Р, а определяет только скорость самого обучения.

В проведенных имитационных экспериментах было обнаружено, что
наилучшим пробным сигналом для формирования обучающего множества
является стохастический ряд, распределенный в диапазоне рабочих
уставок.  Использование моногармонического сигнала дает худший
результат, а ступенчатый пробный сигнал совсем не позволил настроить
НС--Р подобно ПИД.  Важным аспектом при формировании обучающей выборки
является такое распределение амплитуд сигналов на входе и выходе
регулятора, которое охватывает диапазон этих сигналов в основных
рабочих режимах контура.

Анализ результатов экспериментов показал, что малая ошибка имитации
вне контура не всегда обеспечивает малую ошибку управления в контуре
синтезированным НС--Р.  В этом проявляется нелинейная природа НС--Р.
В частности, как уже отмечалось, настройка НС--Р по ступенчатому
пробному сигналу не обеспечивает устойчивое управление в контуре по
причине малой площади покрытия обучающими точками рабочего диапазона.

Отмечено, что синтезированный НС--Р в отличие от ПИД не обеспечивал
нулевую ошибку управления даже по окончании переходного процесса.  Эта
ошибка в проведенных экспериментах не превышала 2\% от ширины рабочего
диапазона уставок.  В то же время, сам переходный процесс под
управлением НС--Р становился короче вследствие отсутствия памяти
состояния и обратных связей у многослойного персептрона.  Также было
отмечено меньшее перерегулирование.

Разработанная методика не опирается на предположение о линейности
объекта, поэтому она была проверена на существенно нелинейном объекте
--- химическом реакторе непрерывного действия с перемешиванием
(continuous stirred-tank reactor).  Синтезованный нейросетевой аналог
ПИД регулятора обеспечил устойчивость контура управления, лучшее
перерегулирование, более короткий переходный процесс, а также меньшую
СКО управления.

\textbf{В третьей главе} предложен метод синтеза нейросетевого
регулятора, минимизирующего СКО управления в контуре.  Данный метод
является развитием косвенного адаптивного управления, однако, в
отличие от него, в качестве начального приближения берется НС--Р,
полученный в результате имитации некоторого линейного регулятора по
методике, изложенной в главе 2.

Критерий синтеза для объекта с наблюдаемой функцией
$g(u_k,\mathbf{s})$ и аддитивной помехой в канале наблюдения $n_k$:
\begin{equation}\label{eq:noc_synthesis_task}
  \sum\limits_k\big(r_k-g(u_k,\mathbf{s})-n_k\big)^2\rightarrow\min
\end{equation}

\noindent где $u_k=\NN^p(\mathbf{i}_k)$ --- управляющее воздействие
НС--Р.  Приведение ошибки управления к выходу НС--Р можно осуществить
с помощью нейросетевой модели объекта (НС--О) по схеме, показанной
на~\figref{arfig:noclearnloop2}.
\begin{figure}[h]
  \centering
  \input{nnplearn.eps_t}
  \caption{Обучение нейросетевого регулятора с помощью инвертирования
  модели объекта.}\label{arfig:noclearnloop2}
\end{figure}

Обратное распространение ошибки управления через НС--О к НС--Р,
обозначаемое как $\mathcal{B}^o(u_k, y_{k+1}, r_{k+1})$, неявно
вычисляет якобиан объекта $J_k$:
\begin{equation}\label{eq:nn-jacobinv}
  \mathcal{B}^o(u_k, y_{k+1}, r_{k+1})=\mathsf{z}^{-1}(u_k)+(r_{k+1}-y_k)/J_k
\end{equation}

Задача сформулирована в предположении фиксированной архитектуры НС--Р.
В этом случае, вопросы со~\pgref{main-nn-questions} решались только
для НС--О.  Поскольку нейросетевая модель объекта с обратными связями
имеет известные сложности в использовании (необходим анализ
устойчивости, существует проблема исчезающего градиента при обучении),
за основу был взят многослойный персептрон, реализующий модель
предсказания выхода объекта за счет информации о прошлых выходах
объекта и управляющем воздействии (\figref{arfig:nnp-past-states}).
\begin{figure}[h]
  \centering
  \input{nnp_paststates.eps_t}
  \caption{Пример модели с повторением прошлых состояний
  $\hat{y}_{k+1}=\NN^o(u_k, y_k, y_{k-1})$.}
  \label{arfig:nnp-past-states}
\end{figure}

Обучение НС--О вне контура управления осуществлялось по критерию:
\begin{equation}\label{eq:nnp_synthesis_task}
  \sum\limits_k\big(g(u_k,\mathbf{s})+n_k-\NN^o(u_k,\ldots,u_{k-n},y_k,\ldots,y_{k-d})\big)^2
  \rightarrow\min\limits
\end{equation}

Эксперименты с устойчивыми минимальнофазовыми линейными объектами
показали, что существенным для обучения НС--О является не порядок
объекта, а его инерционность, то есть, длительность переходного
процесса.  Обучающее множество должно формироваться из временных рядов
длины, не меньшей времени установления переходного процесса объекта.
Глубина регрессии $n=1$, $d=1$ для объектов второго и более высоких
порядков оказалась достаточной, чтобы обеспечить обучение НОР в
контуре.

Увеличение количества слоев с одного до двух и трех в проведенных
экспериментах позволило ускорить обучение НС--О и увеличить точность
имитации.  Число входных нейронов в случае многослойной сети в 1.5--3
раза превышало число входов, а каждый последующий слой содержал
меньшее число нейронов.

Систематически исследовался вопрос формирования выборки для обучения
НС--О.  Было выявлено, что определяющим требованием к выборке является
распределение амплитуд, соответствующее рабочей области возмущений и
наблюдаемых выходов объекта.  Пробный сигнал при этом может быть
ступенчатым, гармоническим или стохастическим.

Для исследования влияния НС--О и параметров обучения нейросетевого
оптимального регулятора в контуре управления был проведен ряд
имитационных экспериментов в специальных {\em идеальных условиях }
повторяющегося псевдослучайного ряда уставки и помехи.  Данный прием
позволил установить ряд закономерностей, в частности, в
противоположность результату из главы 2, было обнаружено, что более
сложные архитектуры нейросетевого оптимального регулятора (НОР)
оптимизируются быстрее, чем простые однослойные.  В случае двух- и
трехслойных НОР скорость обучения не зависит от архитектуры НС модели.
Коэффициент скорости обучения при пакетном обновлении коэффициентов
НОР в контуре управления целесообразно выбирать обратно
пропорционально периоду обновления.

На~\figref{arfig:noc_mse(epochlen)}а показаны среднее значение и
отклонение ошибки для финальной достигнутой СКО (при скорости спада
СКО меньше $10^{-5}$), а на~\figref{arfig:noc_mse(epochlen)}б ---
среднее и отклонение ошибки на тестовой выборке после обучения.
\begin{figure}[h]
\centering
\begin{tabular}{lclc}
  \begin{sideways}
    {\hspace{0.7cm}\small Финальная ошибка управления}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{noc_c_tr_mse_L}
  &
  \begin{sideways}
    {\hspace{2.6cm}\small Ошибка}
  \end{sideways}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{noc_test_mse_L} \\
  & {\small Длина эпохи} & & {\small Длина эпохи} \\
  & а) & & б)\\
\end{tabular}
\caption{Зависимость $\MSE$ от длительности эпохи по завершении обучения (а)
         и на тестовой выборке (б).}
\label{arfig:noc_mse(epochlen)}
\end{figure}

Анализ графиков свидетельствует, что в условиях эксперимента
длительность эпохи (период обновления весов НС--Р при обучении)
целесообрано выбрать в пределах от 200 до 400.  При меньшем значении
обучение НОР подвержено случайным факторам и помехам, а при большем
--- увеличение длительности обучения не дает снижения СКО управления.

Учитывая стохастический характер СКО управления в реальных условиях и
результаты исследований в идеальных условиях, для останова обучения
НОР в контуре проверялась гипотеза постоянства среднего значения с
помощью статистического критерия серий, основанного на медиане.  Также
можно утверждать, что оптимальное линейное управление или близкое к
нему является худшим стартом для синтеза НОР, чем управление
значительно худшего качества.

Предложенные в главах 2 и 3 методики синтеза нейросетевых регуляторов
и модели применены для управления объектом третьего порядка в
присутствии аддитивной помехи в канале наблюдения.  Структура и
параметры объекта $P^*(z)$, исходного ПИД-регулятора $C_{PID}^*(z)$,
формирующего фильтра уставки $R^*(z)$ и помехи $N^*(z)$ перечислены
ниже:
\begin{equation}\label{eq:3rd_order_step_plant}
\begin{array}{rcl}
P^*(z) & = & \displaystyle\frac{z^3-0.1}{(z-0.8)(z^2-0.06z+0.58)}\\
C_{PID}^*(z) & = & 0.01\Bigl(1+\displaystyle\frac{z}{0.05(z-1)}+\displaystyle\frac{z^2-2z+1}{0.1(z^2-z)}\Bigr)\\
R^*(z) & = & \displaystyle\frac{3z}{z-0.7}\\
N^*(z) & = & 0.07\\
\end{array}
\end{equation}

Архитектуры предложенных нейросетей регулятора и модели представлены
на~\figref{arfig:3rd_order_nn_arch}.
\begin{figure}
\centering
\begin{tabular}{cc}
  \includegraphics[width=0.45\textwidth]{3rd_order_nnc_arch} &
  \includegraphics[width=0.45\textwidth]{3rd_order_nnp_arch} \\
  а) & б) \\
\end{tabular}
\caption{Архитектуры нейросетевого регулятора с входами $r_k,e_k$ (а) и модели с входами $u_k,y_k,y_{k-1},y_{k-2}$ (б).}\label{arfig:3rd_order_nn_arch}
\end{figure}

В результате проведенных процедур обучения был получен НОР,
обеспечивший на контрольной выборке снижение среднеквадратической
ошибки управления на 37\%, а максимальной ошибки управления --- на
39\% по сравнению с исходным ПИД регулятором.

Сравнительные эксперименты обученного НОР и винеровского оптимального
регулятора, рассчитанного для заданного объекта и сигналов, показали,
что НОР с входами $r_k,e_k$ обеспечивает меньшую абсолютную и СКО
управления как в номинальных условиях, так и при других видах сигналов
уставки.

\textbf{В четвертой главе} рассматривается задача нейросетевого
управления нестационарным объектом.  В качестве модели
нестационарности было взято ступенчатое изменение параметров объекта.
Предложены и исследованы два подхода адаптации НС--Р к изменившимся
условиям --- метод постоянной адаптации (ПА) и метод адаптации по
обнаружению разладки (АР).  В рамках первого метода реализована схема
косвенного адаптивного управления с постоянно обучающейся моделью
объекта, таким образом, подстраиваются весовые коэффициенты как НС--Р,
так и НС-О независимо от того, изменился объект управления или нет.
Второй подход подразумевает, что НС--Р и НС--О в стационарном режиме
неизменны.  При этом ошибка идентификации нейросетевой модели
используется для обнаружения разладки по дисперсии с помощью алгоритма
кумулятивных сумм (АКС).

При изменении параметров объекта в схеме с постоянной адаптацией под
обеих НС начинается со следующей эпохи.  В схеме с обнаружением
разладки необходимо собрать данные для перенастройки нейросетевой
модели объекта вне контура управления, обучить её и, вернув в контур,
начать обучение НС--Р подобно тому, как это описано в главе 3.  При
этом важно чтобы, с одной стороны, обучающая выборка для модели была
как можно короче, чтобы быстрее начать подстройку НС--Р, с другой
стороны, выборка должна быть достаточного объема для обучения НС--О.
Разработан оригинальный подход, позволяющий сформировать обучающую
выборку оптимального размера и основанный на оценке параметров
двумерного распределения точек $(u_k,y_{k+1})$.

Сравнительные испытания обоих адаптивных подходов проиллюстрированы
на~\figref{arfig:nonst_pa_ma_cmp_rus}.
\begin{figure}[h]
\centering
\begin{tabular}{cc}
  \includegraphics[width=0.45\textwidth,%
    height=0.25\textheight]{nonst_cmp_pa_ma_rus}
  &
  \includegraphics[width=0.45\textwidth,%
    totalheight=0.25\textheight]{perm_adopt_steady_plant_rus} \\
  а) & б)
\end{tabular}
\caption{Среднеквадратическая ошибка управления сразу после изменения параметров объекта (а) и во время длительного периода стационарности (б).}
\label{arfig:nonst_pa_ma_cmp_rus}
\end{figure}

На графиках~\figref{arfig:nonst_pa_ma_cmp_rus}а видно, что при
постоянной адаптации реакция на изменение объекта происзодит быстрее,
не допускается значительного увеличения ошибки управления, однако
уровень СКО снижается достаточно медленно.  Адаптация по разладке
имеет задержку, вызванную сбором данных для перенастройки НС--Р,
однако СКО управления после этого снижается значительно быстрее.
Кроме того, рассмотрение обоих подходов на длительном временном
интервале выявляет неустойчивость подхода с постоянной адаптацией
(периоды роста ошибки на~\figref{arfig:nonst_pa_ma_cmp_rus}б).

\textbf{В пятой главе} рассматривается задача нейросетевого управления
мобильным роботом при движении к неподвижной цели (маяку) и приводится
её решение для реального робота.  Мобильный робот представляет собой
тележку с тремя колесами, два из которых являются ведущими,
расположены спереди и одно рояльное сзади.  Управление движением
робота осуществляется подачей одинакового или различающегося
напряжения на ведущие приводы.  Сенсором выступает датчик отклонения
от направления на маяк.

Задача управления является нелинейной геометрически и динамически,
имеет место ошибка в определении направления на маяк, кроме того,
параметры приводов не известны точно.  В таких условиях имевшийся на
роботе линейный П регулятор давал существенную ошибку попадания в
цель.  По методикам, изложенным в главах 2 и 3 был сначала
синтезирован НС--Р, функционирующий подобно исходному П регулятору, а
потом с помощью настроенной нейросетевой модели НС--Р был обучен в
контуре управления для минимизации СКО.  Поскольку постановка задачи
подразумевает постоянный уровень уставки $r_k=0$, а объект управления
нелинейный, для НС--Р была выбрана трехслойная архитектура с 5-ю и 3-я
нейронами в скрытых слоях и входами $e_k,\Delta e_k$.  Модель объекта
имела в качестве входов $u_k,u_{k-1},y_k,y_{k-1}$ и один скрытый слой
с 5-ю нейронами.

Эксперименты показали, что нейросетевое управление позволило
существенно увеличить точность попадания в цель по сравнению с П
регулятором: средняя ошибка уменьшилась с 49.6мм до 19.1мм, а разброс
уменьшился с 206.6.мм до 33.0мм.  Графики координаты цели по времени
приведены на~\figref{arfig:moby_p_noc_cmp}.

\begin{figure}[h]
  \centering
  \begin{tabular}{rcrc}
    \begin{sideways}
      {\hspace{1.3cm}\small Координата маяка}
    \end{sideways}
    &
    \includegraphics[width=0.45\textwidth,%
                     totalheight=0.25\textheight]{moby_pc_x0-9_explore}
    &
    \begin{sideways}
      {\hspace{1.3cm}\small Координата маяка}
    \end{sideways}
    &
    \includegraphics[width=0.45\textwidth,%
                     totalheight=0.25\textheight]{moby_fnnc_x01-06_test}\\
    & {\small Время, отсчеты} &
    & {\small Время, отсчеты} \\
    & а) & & б)
  \end{tabular}
  \caption{Траектория маяка в поле зрения сенсора под управлением П
    регулятора (а) и нейросетевого регулятора по окончании его
    настройки в контуре (б).}
  \label{arfig:moby_p_noc_cmp}
\end{figure}

\textbf{В шестой главе} описывается программный пакет для
моделирования и обучения методам нейросетевого управления,
разработанный для реализации методик, описанных в главах 2-4 и
использовавшийся при проведении всех экспериментов включая управление
мобильным роботом.  Пакет обеспечивает полный комплекс инструментов
для моделирования САУ включая нелинейные и нестационарные элементы, а
также обладает средствами формирования архитектуры и обучения
нейронных сетей регулятора и модели.

Состав программного обеспечения включает комплекс вычислительных
программ, написанных на языке {\tt C++} и реализующих алгоритмы
моделирования и обучения нейронных сетей, а также интерактивные
программы, написанные на языке {\tt Tcl/Tk}, обеспечивающие простую и
удобную для пользователя среду взаимодействия.  Такая структуризация
обеспечивает максимальную гибкость программного обеспечения при
минимальных требованиях к аппаратной и программной среде выполнения.
В частности, пакет, разработанный для ОС Linux может быть легко
адаптирован для ОС Windows и MacOS X.

Для моделирования САУ и обучения нейронных сетей в различных схемах их
использования в рамках пакета разработана объекто-ориентированная
библиотека, использующая в качестве базовой абстракции сети Петри.

Программный пакет открыт для интеграции с другими программами, так как
использует текстовый формат для представления данных, параметров
вычислительных программ и нейросетей.  Кроме того, возможна разработка
сторонних модулей для реализации нелинейных объектов управления и
регуляторов любых видов (например, нечетко-логических) и их
использования в среде моделирования САУ.

На основе программного пакета разработаны лабораторные работы для
использования в учебном курсе по изучению нейронных сетей по темам:
\begin{itemize}
\item Синтез нейросетевого оптимального регулятора для замены линейного.
\item Сравнительный анализ нейросетевого, винеровского и ПИД
  регуляторов.
\item Нейросетевое управление нестационарным объектом.
\end{itemize}
