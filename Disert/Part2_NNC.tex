% $Id: Part2_NNC.tex,v 1.3 2002-01-15 21:49:20 vlad Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Синтез нейросетевого регулятора}\label{nncsynthesis}

Задача обучения нейросетевого регулятора (НС--Р), как уже отмечалось в
п.~\ref{nnplearning}, состоит из двух этапов: получения копии
действующего регулятора вне контура управления и дообучения
функционирующего нейросетевого регулятора в контуре с использованием
инверсной модели объекта.  Будем считать, что в контуре управления
исходно функционирует какой-либо линейный регулятор, например, ПИД.

\subsubsection{Предварительное обучение нейросетевого регулятора}

ПИД регулятор представляет собой динамическую систему, обладающую
памятью (кроме простейшего пропорционального случая управления).
Первым этапом синтеза нейросетевого регулятора является его
предварительное обучение подобно исходному ПИД регулятору.  Главной
целью этого этапа является точность имитации, поскольку на следующем
этапе построенный нейросетевой регулятор будет управлять реальным
объектом в контуре.  Считая, что исходный регулятор обеспечивает
устойчивость и некоторое удовлетворительное качество управления, можно
ожидать, что достаточно точный имитатор будет управлять системой
подобно.

Качество обучения нейронной сети определяется выбором архитектуры,
обучающих данных и параметров методики обучения.  Исследуем влияние
перечисленных факторов на предварительное обучение нейросетевого
регулятора.

\subsubsection{Архитектура нейросетевого регулятора}

Сравнивая задачу предварительного обучения НС--Р с задачей синтеза
нейросетевой модели объекта следует при очевидном сходстве (имитация
некоторой линейной системы) отметить два фундаментальный различия.
Во-первых, НС--О может быть реализована как в виде автономной модели
поведения, так и в виде зависимой от объекта модели предсказания, в то
время как НС--Р должен полностью заменить исходный регулятор.
Во-вторых, назначение НС--О --- копирование поведения объекта
управления, а НС--Р должен быть сначала обучен подобно исходному
линейному регулятору, но потом в процессе дообучения в контуре
управления может изменить свои свойства сообразно задаче минимизации
среднеквадратичной ошибки управления.  Буквальное повторение свойств
линейного регулятора не является основной целью, а лишь предваряет ее,
поэтому не имеет смысла формировать архитектуру нейросетевого
регулятора только исходя из линейности исходного регулятора.

Как и в случае с синтезом НС--О возникает задача выбора между
статической и динамической (с обратными связями) архитектурами
нейронной сети.  Аргументом в пользу динамической нейронной сети
является наиболее очевидный путь имитации свойств линейной
динамической системы с помощью автономной модели.  Вместе с тем, у
динамической нейронной сети имеются как недостатки общего плана,
упомянутые в п.~\ref{nnp_inputs}, так и специфические, проявляющиеся
при использовании обратных связей в НС--Р:

\begin{enumerate}
\item эффект исчезающего градиента ({\em vanishing gradient}) при
      обучении по методу BPTT;
\item увеличение требований к ресурсам и усложнение алгоритма обучения
      в контуре, вызванное процедурой обращения времени;
\item усложнение анализа устойчивости системы за счет появления еще
      одного контура обратной связи.
\end{enumerate}

Применение статической нейронной сети для реализации НС--Р не имеет
перечисленных недостатков, кроме того, обучение статической нейросети
в целом осуществляется быстрее, чем динамической.  Однако, как и в
случае с нейросетевой моделью объекта управления, следует с помощью
надлежащего формирования структуры входов нейросети обеспечить
динамические свойства НС--Р, аналогичные имеющимся у ПИД регулятора в
контуре.

\subsubsection{Структура входов нейросети}

Рассмотрим несколько вариантов формирования вектора входных значений
для НС--Р.  Обязательно следует проверить вариант подключения,
аналогичный исходному регулятору.  В этом случае на вход подается
только значение ошибки в текущий момент времени $e_k$.  Как было
показано ранее при построении нейросетевой модели объекта, этот
вариант подключения статической нейронной сети не может обеспечить
адекватную имитацию свойств динамической системы.  Чтобы преодолеть
ограничение статического отображения надо искусственно организовать
память с помощью повторения прошлых входов $e_k\ldots e_{k-d}$.
Поэтому исследуем поведение НС--Р при различных значениях емкости
памяти: $0\le d\le 4$.

Рассмотрим также варианты подключения НС--Р с входами $e_k,\Delta e_k$
и $r_k,e_k$.  Последний представляет собой объединение концепций
управления по возмущению $r(t)$ и отклонению $e(t)$.

Для сравнения перечисленных вариантов формирования входного вектора
НС--Р была проведена серия экспериментов.  Ниже приводится постановка
и результаты одного из них.

% nn/dpid.new/contrp/...
Эксперимент проводился в условиях стохастической уставки при наличии
случайной аддитивной помехи в наблюдаемом выходе объекта управления.
Формирующие фильтры уставки $R^*(z)=\frac{0.625z}{z-0.779}$ и помехи
$N^*(z)=0.4$.  Объект $P^*(z)=\frac{z}{z-0.5}$ управлялся ПИД
регулятором $C^*(z)=0.4 + 0.5\frac{z}{z-1} +
0.05\frac{z^2-2z+1}{z(z-1)}$.  Регулятор был настроен на ступенчатом
возмущающем сигнале по критерию минимизации длительности переходного
процесса при максимальном перерегулировании в пределах 4\% амплитуды
возмущающего сигнала.

Нейронная сеть регулятора имела архитектуру $\mathcal{N}^p_{x,7,3,1}$,
где $x$ --- размерность входного вектора.  Обучение осуществлялось на
выборке длиной 200 в течение 400 эпох, а контрольная выборка имела
длину 500, причем если ошибка на контрольной выборке начинала
возрастать, то обучение досрочно прекращалось.  Критерием обучения
являлась минимизация среднеквадратичной ошибки воспроизведения.

\begin{table}[ht]
\caption{Сравнение точности имитации ПИД регулятора вне контура управления
         при различном способе формирования входного вектора НС--Р и
         различных параметрах уставки и помехи}
\label{tabl:nnc_pretr_input_vec}
\begin{tabular}{|c|l|c|c|c|c|}
\hline
\multicolumn{2}{|r|}{Эксперимент} & {\sf А} & {\sf Б} & {\sf В} & {\sf Г}\\
\hline
\multicolumn{2}{|r|}{Уставка} &
  \multicolumn{2}{|c|}{Стохастическая $R^*(z)$} & $\sin(t)$ & $0$ \\
\hline
\multicolumn{2}{|r|}{Помеха} & $N^*(z)=0.4$ & $N^*(z)=0.7$ & $N^*(z)=0.4$ & $N^*(z)=0.4$\\
\hline\hline
N   & Входной & \multicolumn{4}{|c|}{Среднеквадратичная ошибка} \\
пп. & вектор  & \multicolumn{4}{|c|}{на контрольной выборке}\\
\hline
1 & $e_k$                 & 0.3228 & 0.2906 & 0.1299 & 0.0027\\
2 & $e_k,e_{k-1}$         & 0.2993 & 0.2710 & 0.1291 & 0.0022\\
3 & $e_k\ldots e_{k-2}$   & 0.2709 & 0.2459 & 0.1270 & 0.0016\\
4 & $e_k\ldots e_{k-3}$   & 0.2482 & 0.2284 & 0.1240 & 0.0013\\
5 & $e_k\ldots e_{k-4}$   & 0.2385 & 0.2163 & 0.1188 & 0.0013\\
6 & $e_k,\Delta e_k$      & 0.2980 & 0.2738 & 0.1293 & 0.0023\\
7 & $r_k,e_k$             & 0.0388 & 0.0968 & 0.0039 & 0.0040\\
\hline
\end{tabular}
\end{table}

%% $e_k$     0.1296
%% $r_k,e_k$ 0.0037

В таблице~\ref{tabl:nnc_pretr_input_vec} результаты эксперимента
приведены в столбце {\sf А}.  Анализ значений среднеквадратичной
ошибки показывает, что увеличение емкости памяти прошлых входов
позволяет лишь незначительно уменьшить ошибку имитации (строки таблицы
1--5).  Вариант с первой разностью ошибки (строка 6) показывает
близкие результаты с вариантом $e_k,e_{k-1}$ (строка 2).  Очевидно,
что для НС--Р эти варианты информационно эквивалентны.  Наилучшее
качество имитации исходного регулятора было достигнуто НС--Р с входным
вектором $r_k,e_k$, причем достигнутый уровень ошибки в этом случае
оказался меньше почти на порядок, чем в остальных.

Эксперименты показали, что при увеличении мощности помехи
относительное преимущество НС--Р с входным вектором $r_k,e_k$
уменьшается (столбец {\sf Б} таблицы).  Таким образом, применение в
качестве входного вектора $e_k\ldots e_{k-d}$ может оказаться в
некоторых случаях оправданным.

Были также рассмотрены случаи предварительного обучения НС--Р по
детерминированной уставке различной формы.  По результатам
экспериментов наилучшим вариантом формирования входного вектора с
большим отрывом оказалось совмещенное управление по возмущению и
отклонению: $r_k,e_k$ (строка 6).  Оказалось также, что результирующий
уровень ошибки при периодической уставке практически не зависит от ее
формы.  В частности, числовые значения среднеквадратичной ошибки на
гармоническом сигнале (столбец {\sf В}
таблицы~\ref{tabl:nnc_pretr_input_vec}) и на меандре примерно
одинаковы.

Отдельно был рассмотрен случай задачи стабилизации, когда уставка
постоянна, например, равна 0 (столбец {\sf Г}
таблицы~\ref{tabl:nnc_pretr_input_vec}).  Нейросетевой регулятор с
входным вектором $r_k,e_k$ показал худший результат, чем любой из
вариантов с повторением прошлых значений ошибки.  Видно, что
отсутствие влияния уставки на нейронную сеть в данном случае делает
наличие входа $r_k$ не только бесполезным, но и вредным.

Проводились также эксперименты с объектом управления с чистым
запаздыванием и объектом управления второго порядка, анализ которых
обнаружил те же закономерности.

По результатам проведенных экспериментов можно сформулировать
некоторые рекомендации по формированию входного вектора нейросетевого
регулятора по критерию наилучшей имитации исходного ПИД регулятора:

\begin{itemize}
\item
В случае задачи стабилизации (постоянное значение уставки)
рекомендуется использовать один из вариантов с повторением прошлых
значений: $e_k\ldots e_{k-d}$.  При увеличении емкости памяти прошлых
значений (параметр $d$) качество имитации при наличии помехи будет
возрастать.

\item
В случае изменяющегося значения уставки предпочтительным является
совмещенное управление по возмущению и отклонению: $r_k,e_k$.  При
значительном уровне помехи улучшить качество имитации можно вводя и
увеличивая память прошлых состояний.  Входной вектор в этом случае
будет иметь вид $r_k,e_k\ldots e_{k-d}$
\end{itemize}

Испытание предварительно настроенного НС--Р в системы управления
вместо ПИД регулятора показало, что система успешно управляется
нейросетью.  Во всех проведенных экспериментах система с нейросетевым
регулятором в контуре не потеряла устойчивости.  Вместе с тем отмечен
ряд особенностей и недостатков, присущих нейросетевому управлению:

\begin{enumerate}

\item быстродействие нейросетевого регулятора не хуже ПИД, а время
наступления установившегося режима даже меньше, чем у ПИД регулятора
(\figref{fig:pid_npc_test}а);

\item при неизменной уставке (в том числе, при $r(t)=0$) в системе
с НС--Р может иметь место статическая ошибка (на примере со
ступенчатой уставкой перерегулирование составляет 6\% номинального
уровня);

\item при выходе уровня уставки за пределы диапазона обучающих данных
точность управления падает (\figref{fig:pid_npc_test}б).
\end{enumerate}

\begin{figure}[h]
\begin{tabular}{cc}
\hbox{\psfig{figure=pid_npc_step_test.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} &
\hbox{\psfig{figure=pid_npc_stoch_test.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} \\
а) & б)\\
\end{tabular}
\caption{Отклик системы на прямоугольное (а) и стохастическое (б)
         возмущающее воздействие при ПИД и НС регулировании ($r_k,e_k$).}
\label{fig:pid_npc_test}
\end{figure}

Устранить эффекты появления статической ошибки и резкого снижения
качества имитации при превышении входным сигналом некоторого уровня
можно надлежащим выбором обучающего множества.

\subsubsection{Требования к обучающей и контрольной выборкам}

Эффект статической ошибки был рассмотрен при обучении нейросетевой
модели объекта управления.  Для того, чтобы уменьшить это эффект
рекомендуется выбрать симметричный относительно нуля обучающий ряд
$r(t)$.

Снижение качества имитации при выходе сигнала за пределы обучающего
множества также рассматривалось в связи с синтезом нейросетевой модели
объекта управления (п.~\ref{nnp_map_uy}).  Специфика выбора обучающего  настройки НС--Р в
том, что


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Архитектура нейронной сети регулятора}

Расмотрим задачу выбора внутренней архитектуры нейронной сети
регулятора учитывая ее влияние как на качество имитации исходного
регулятора, так и на дальнейшее дообучение НС--Р в контуре управления.

По результатам нескольких имитационных экспериментов было выяснено,
что предварительное обучение НС--Р дает удовлетворительный результат
уже в случае использования простейшей архитектуры из одного нейрона с
линейной функцией активации и двумя входами $r_k$ и $e_k$.  Очевидно,
что функция такой сети имеет вид $w_0+w_1 r_k+w_2 e_k$.  Графическое
изображение такой функции --- плоскость в трехмерном пространстве с
осями $e(t), r(t), u(t)$.  Анализ показал, что множество обучающих
точек $(e_k, r_k, u_k)$, полученных при функционировании в контуре
исходного ПИД регулятора, имеет форму эллипсоида, сильно сжатого по
оси $u(t)$ и немного наклоненного.

Наилучшей поверхностью, аппроксимирующей облако такой формы будет
наклонная плоскость.  Это объясняет и выбор вектора входов $r_k,e_k$,
и простую архитектуру, необходимую для воспроизведения поведения ПИД
регулятора.

Тем не менее, следует учитывать, что предварительное обучение НС--Р
является только первым этапом синтеза нейросетевого регулятора.
Необходимо установить, какая архитектура НС--Р является достаточной
для последующего обучения в контуре.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Требования к обучающей выборке}








Были проведены эксперименты,

Однако следует 

Такое множество точек лучше всего аппроксимируется плоскостью 

позволил установить типичную форму



Исследуем в имитационном эксперименте влияние сложности архитектуры на
качество синтезируемого НС--Р.


Качество обучения НС--Р с различными входными векторами предлагается
оценить по 

Результаты обучения нейросетевых регуляторов одинаковой архитектуры с
перечисленными вариантами входных векторов приводятся ниже:


  ПИД регулятор
представляет собой динамическую систему $u_k=f(e_k)$ с памятью (кроме
простейшего пропорционального регулятора, не обладающего памятью).
%Как уже отмечалось (п.~\ref{nnp_inputs}), имитация памяти требует
%введения обратных связей.
Анализ зависимости $u_k$ от $e_k$ для ПИД регуляторов в различных
системах управления показывает недостаточность одного лишь значения
ошибки $e_k$ для аппроксимации нейросетью выхода $u_k$ ПИД регулятора.
Например, для системы управления с линейным объектом управления
инерционного типа в условиях стохастической уставки и случайной помехи
в канале наблюдения распределение точек $(u_k,e_k)$ на плоскости
приводится на \figref{fig:pid_eu}.

\begin{figure}[h]
\centerline{\hbox{\psfig{figure=pid_eu.ps,%
angle=270,width=0.8\textwidth,height=0.3\textheight}}}
\caption{Распределение точек $(u_k,e_k)$ для ПИД регулятора.}
\label{fig:pid_eu}
\end{figure}

Исследуем зависимость $u_k$ от $e_k$ для ПИД регулятора, включенного в
контур управления линейным объектом.  Анализ показывает, что влияние
динамической природы регулятора на 

Анализ зависимости $u_k$ от $e_k$ для ПИД регулятора в контуре системы
управления показывает значительное влияние памяти предыдущего
состояния регулятора (\figref{}).



Даже простейший анализ


Дифференциальная часть регулятора в дискретной форме
представляет собой 

Проанализируем возможность нейросетевой имитации ПИД закона
управления:

\begin{equation}\label{pid-continuous}
u(t)=K_P e(t)+K_I\int\limits_0^T e(t)dt+K_D\frac{de(t)}{dt}
\end{equation}

Первое слагаемое $K_P e(t)$ реализует пропорциональную зависимость
управления от ошибки в текущий момент времени.  Данная зависимость
легко реализуется нейронной сетью.

Второе слагаемое $K_I\int\limits_0^T e(t)dt$ усиливает управляющее
воздействие в случае наличия ошибки на протяжении некоторого времени.
Таким образом, память позволяет ускорить 

Третье слагаемое $K_D\frac{de(t)}{dt}$ определяет реакцию регулятора
на изменение ошибки.  В дискретном случае производная обычно
представляется разностью $\Delta e_k=e_k-e_{k-1}$.

Рассмотрим альтернативный способ реализации 

Из традиционной теории управления известны два способа реализации
регулирования: по возмущению и по отклонению.  В линейной ТАУ первый
способ в чистом виде практически не используется, так как в нем не
задействуется информация о фактическом состоянии объекта управления.
Неточность идентификации объекта управления, наличие неконтролируемых
возмущений и помех обычно приводят к неудовлетворительному качеству
управления по возмущению.  Нейросетевые регуляторы, основанные на этом
принципе (последовательная схема нейронного управления в обзоре
\cite{sigom00}), эксплуатируют возможность инверсии объекта
искусственной нейронной сетью после обучения.  Однако недостатки,
присущие принципу регулирования по возмущению остаются и в случае его
нейросетевой реализации.

Гораздо более распространено регулирование по отклонению.  В линейной
теории управления особое внимание уделяется специальному типу
регуляторов, которые реализуют суперпозицию пропорциональной,
дифференциальной или интегральной зависимости управляющего воздействия
от входной ошибки.  ПИД регуляторы широко используется в
промышленности, так как они позволяют решать задачи стабилизации и
слежения в хорошо линеаризуемых детерминированных линейных системах
управления.

\begin{equation}
u_k-u_{k-1}=\Delta u_k=K_P(e_k-e_{k-1})+K_I e_k+K_D(e_k-2e_{k-1}+e_{k-2})
\end{equation}


\begin{equation}\label{eq:reference}
R^*(z)=\displaystyle\frac{0.625z}{z-0.779}
\end{equation}

\begin{equation}\label{eq:noise}
N^*(z)=0.7
\end{equation}

\begin{equation}\label{eq:plant}
P^*(z)=\displaystyle\frac{z}{z-0.5}
\end{equation}

\begin{equation}\label{eq:contr-pid}
C_{PID}^*(z)=0.4 +
       0.5\displaystyle\frac{z}{z-1} +
       0.05\displaystyle\frac{z^2-2z+1}{z(z-1)}
\end{equation}

\begin{equation}\label{eq:contr-wiener}
C_W^*(z)=\displaystyle\frac{0.528z-0.264}{z-0.896}
\end{equation}


\subsubsection{Настройка нейросетевого регулятора}
\subbbsection{Предварительное обучение нейросети}
\subbbsection{Обучение нейросети в контуре управления}

\subsubsection{Влияние качества НС--О на скорость обучения НС--Р в контуре}
