% $Id: Part2_NNC.tex,v 1.4 2002-02-28 21:12:10 vlad Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Синтез нейросетевого регулятора}\label{nncsynthesis}

Задача обучения нейросетевого регулятора (НС--Р), как уже отмечалось в
п.~\ref{nnc_optimal_training}, состоит из двух этапов: получения копии
действующего регулятора вне контура управления и дообучения
функционирующего нейросетевого регулятора в контуре с использованием
инверсной модели объекта.  Будем считать, что в контуре управления
исходно функционирует какой-либо линейный регулятор, например, ПИД.

\subsubsection{Предварительное обучение нейросетевого регулятора}%
\label{nnc_pre}

ПИД регулятор представляет собой динамическую систему, обладающую
памятью (кроме простейшего пропорционального случая управления).
Первым этапом синтеза нейросетевого регулятора является его
предварительное обучение подобно исходному ПИД регулятору.  Главной
целью этого этапа является точность имитации, поскольку на следующем
этапе построенный нейросетевой регулятор будет управлять реальным
объектом в контуре.  Считая, что исходный регулятор обеспечивает
устойчивость и некоторое удовлетворительное качество управления, можно
ожидать, что достаточно точный имитатор будет управлять системой
подобно.

Качество обучения нейронной сети определяется выбором архитектуры,
обучающих данных и параметров методики обучения.  Исследуем влияние
перечисленных факторов на предварительное обучение нейросетевого
регулятора.

\subsubsection{Архитектура нейросетевого регулятора}

Сравнивая задачу предварительного обучения НС--Р с задачей синтеза
нейросетевой модели объекта следует при очевидном сходстве (имитация
некоторой линейной системы) отметить два фундаментальный различия.
Во-первых, НС--О может быть реализована как в виде автономной модели
поведения, так и в виде зависимой от объекта модели предсказания, в то
время как НС--Р должен полностью заменить исходный регулятор.
Во-вторых, назначение НС--О --- копирование поведения объекта
управления, а НС--Р должен быть сначала обучен подобно исходному
линейному регулятору, но потом в процессе дообучения в контуре
управления может изменить свои свойства сообразно задаче минимизации
среднеквадратичной ошибки управления.  Буквальное повторение свойств
линейного регулятора не является основной целью, а лишь предваряет ее,
поэтому не имеет смысла формировать архитектуру нейросетевого
регулятора только исходя из линейности исходного регулятора.

Как и в случае с синтезом НС--О возникает задача выбора между
статической и динамической (с обратными связями) архитектурами
нейронной сети.  Аргументом в пользу динамической нейронной сети
является наиболее очевидный путь имитации свойств линейной
динамической системы с помощью автономной модели.  Вместе с тем, у
динамической нейронной сети имеются как недостатки общего плана,
упомянутые в п.~\ref{nnp_inputs}, так и специфические, проявляющиеся
при использовании обратных связей в НС--Р:

\begin{enumerate}
\item эффект исчезающего градиента ({\em vanishing gradient}) при
      обучении по методу BPTT;
\item увеличение требований к ресурсам и усложнение алгоритма обучения
      в контуре, вызванное процедурой обращения времени;
\item усложнение анализа устойчивости системы за счет появления еще
      одного контура обратной связи с нелинейным элементом (нейросетью).
\end{enumerate}

Применение статической нейронной сети для реализации НС--Р не имеет
перечисленных недостатков, кроме того, обучение статической нейросети
в целом осуществляется быстрее, чем динамической.  Однако, как и в
случае с нейросетевой моделью объекта управления, следует с помощью
надлежащего формирования структуры входов нейросети обеспечить
динамические свойства НС--Р, аналогичные имеющимся у ПИД регулятора в
контуре.

\subsubsection{Структура входов нейросети}

Рассмотрим несколько вариантов формирования вектора входных значений
для НС--Р.  Обязательно следует проверить вариант подключения,
аналогичный исходному регулятору.  В этом случае на вход подается
только значение ошибки в текущий момент времени $e_k$.  Как было
показано ранее при построении нейросетевой модели объекта, этот
вариант подключения статической нейронной сети не может обеспечить
адекватную имитацию свойств динамической системы.  Чтобы преодолеть
ограничение статического отображения надо искусственно организовать
память с помощью повторения прошлых входов $e_k\ldots e_{k-d}$.
Поэтому исследуем поведение НС--Р при различных значениях емкости
памяти: $0\le d\le 4$.

Рассмотрим также варианты подключения НС--Р с входами $e_k,\Delta e_k$
и $r_k,e_k$.  Последний представляет собой объединение концепций
управления по возмущению $r(t)$ и отклонению $e(t)$.

Для сравнения перечисленных вариантов формирования входного вектора
НС--Р была проведена серия экспериментов.  Ниже приводится постановка
и результаты одного из них.

% nn/dpid.new/contrp/...
Эксперимент проводился в условиях стохастической уставки при наличии
случайной аддитивной помехи в наблюдаемом выходе объекта управления.
Формирующие фильтры уставки $R^*(z)=\frac{0.625z}{z-0.779}$ и помехи
$N^*(z)=0.4$.  Объект $P^*(z)=\frac{z}{z-0.5}$ управлялся ПИД
регулятором $C^*(z)=0.4 + 0.5\frac{z}{z-1} +
0.05\frac{z^2-2z+1}{z(z-1)}$.  Регулятор был настроен на ступенчатом
возмущающем сигнале по критерию минимизации длительности переходного
процесса при максимальном перерегулировании в пределах 4\% амплитуды
возмущающего сигнала.

Нейронная сеть регулятора имела архитектуру $\mathcal{N}^p_{x,7,3,1}$,
где $x$ --- размерность входного вектора.  Обучение осуществлялось на
выборке длиной 200 в течение 400 эпох, а контрольная выборка имела
длину 500, причем если ошибка на контрольной выборке начинала
возрастать, то обучение досрочно прекращалось.  Критерием обучения
являлась минимизация среднеквадратичной ошибки воспроизведения.

\begin{table}[ht]
\caption{Сравнение точности имитации ПИД регулятора вне контура управления
         при различном способе формирования входного вектора НС--Р и
         различных параметрах уставки и помехи}
\label{tabl:nnc_pretr_input_vec}
\begin{tabular}{|c|l|c|c|c|c|}
\hline
\multicolumn{2}{|r|}{Эксперимент} & {\sf А} & {\sf Б} & {\sf В} & {\sf Г}\\
\hline
\multicolumn{2}{|r|}{Уставка} &
  \multicolumn{2}{|c|}{Стохастическая $R^*(z)$} & $\sin(t)$ & $0$ \\
\hline
\multicolumn{2}{|r|}{Помеха} & $N^*(z)=0.4$ & $N^*(z)=0.7$ & $N^*(z)=0.4$ & $N^*(z)=0.4$\\
\hline\hline
N   & Входной & \multicolumn{4}{|c|}{Среднеквадратичная ошибка} \\
пп. & вектор  & \multicolumn{4}{|c|}{на контрольной выборке}\\
\hline
1 & $e_k$                 & 0.3228 & 0.2906 & 0.1299 & 0.0027\\
2 & $e_k,e_{k-1}$         & 0.2993 & 0.2710 & 0.1291 & 0.0022\\
3 & $e_k\ldots e_{k-2}$   & 0.2709 & 0.2459 & 0.1270 & 0.0016\\
4 & $e_k\ldots e_{k-3}$   & 0.2482 & 0.2284 & 0.1240 & 0.0013\\
5 & $e_k\ldots e_{k-4}$   & 0.2385 & 0.2163 & 0.1188 & 0.0013\\
6 & $e_k,\Delta e_k$      & 0.2980 & 0.2738 & 0.1293 & 0.0023\\
7 & $r_k,e_k$             & 0.0388 & 0.0968 & 0.0039 & 0.0040\\
\hline
\end{tabular}
\end{table}

%% $e_k$     0.1296
%% $r_k,e_k$ 0.0037

В таблице~\ref{tabl:nnc_pretr_input_vec} результаты эксперимента
приведены в столбце {\sf А}.  Анализ значений среднеквадратичной
ошибки показывает, что увеличение емкости памяти прошлых входов
позволяет лишь незначительно уменьшить ошибку имитации (строки таблицы
1--5).  Вариант с первой разностью ошибки (строка 6) показывает
близкие результаты с вариантом $e_k,e_{k-1}$ (строка 2).  Очевидно,
что для НС--Р эти варианты информационно эквивалентны.  Наилучшее
качество имитации исходного регулятора было достигнуто НС--Р с входным
вектором $r_k,e_k$, причем достигнутый уровень ошибки в этом случае
оказался меньше почти на порядок, чем в остальных.

Эксперименты показали, что при увеличении мощности помехи
относительное преимущество НС--Р с входным вектором $r_k,e_k$
уменьшается (столбец {\sf Б} таблицы).  Таким образом, применение в
качестве входного вектора $e_k\ldots e_{k-d}$ может оказаться в
некоторых случаях оправданным.

Были также рассмотрены случаи предварительного обучения НС--Р по
детерминированной уставке различной формы.  По результатам
экспериментов наилучшим вариантом формирования входного вектора с
большим отрывом оказалось совмещенное управление по возмущению и
отклонению: $r_k,e_k$ (строка 6).  Оказалось также, что результирующий
уровень ошибки при периодической уставке практически не зависит от ее
формы.  В частности, числовые значения среднеквадратичной ошибки на
гармоническом сигнале (столбец {\sf В}
таблицы~\ref{tabl:nnc_pretr_input_vec}) и на меандре примерно
одинаковы.

Отдельно был рассмотрен случай задачи стабилизации, когда уставка
постоянна, например, равна 0 (столбец {\sf Г}
таблицы~\ref{tabl:nnc_pretr_input_vec}).  Нейросетевой регулятор с
входным вектором $r_k,e_k$ показал худший результат, чем любой из
вариантов с повторением прошлых значений ошибки.  Видно, что
отсутствие влияния уставки на нейронную сеть в данном случае делает
наличие входа $r_k$ не только бесполезным, но и вредным.

Проводились также эксперименты с объектом управления с чистым
запаздыванием и объектом управления второго порядка, анализ которых
обнаружил те же закономерности.

По результатам проведенных экспериментов можно сформулировать
некоторые рекомендации по формированию входного вектора нейросетевого
регулятора по критерию наилучшей имитации исходного ПИД регулятора:

\begin{itemize}
\item
В случае задачи стабилизации (постоянное значение уставки)
рекомендуется использовать один из вариантов с повторением прошлых
значений: $e_k\ldots e_{k-d}$.  При увеличении емкости памяти прошлых
значений (параметр $d$) качество имитации при наличии помехи будет
возрастать.

\item
В случае изменяющегося значения уставки предпочтительным является
совмещенное управление по возмущению и отклонению: $r_k,e_k$.  При
значительном уровне помехи улучшить качество имитации можно вводя и
увеличивая память прошлых состояний.  Входной вектор в этом случае
будет иметь вид $r_k,e_k\ldots e_{k-d}$
\end{itemize}

Испытание предварительно настроенного НС--Р в системе управления
вместо ПИД регулятора показало, что система успешно управляется
нейросетью.  Во всех проведенных экспериментах система с нейросетевым
регулятором в контуре не потеряла устойчивости.  Вместе с тем отмечен
ряд особенностей и недостатков, присущих нейросетевому управлению:

\begin{enumerate}

\item быстродействие нейросетевого регулятора не хуже ПИД, а время
наступления установившегося режима даже меньше, чем у ПИД регулятора
(\figref{fig:pid_npc_test}а);

\item при неизменной уставке (в том числе, при $r(t)=0$) в системе
с НС--Р может иметь место статическая ошибка (на примере со
ступенчатой уставкой на \figref{fig:pid_npc_test}а видно, что
перерегулирование составляет 6\% номинального уровня);

\item при выходе уровня уставки за пределы диапазона обучающих данных
точность управления падает (\figref{fig:pid_npc_test}б).
\end{enumerate}

\begin{figure}[h]
\begin{tabular}{cc}
\hbox{\psfig{figure=pid_npc_step_test.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} &
\hbox{\psfig{figure=pid_npc_stoch_test.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} \\
а) & б)\\
\end{tabular}
\caption{Отклик системы на прямоугольное (а) и стохастическое (б)
         возмущающее воздействие при ПИД и НС регулировании ($r_k,e_k$).}
\label{fig:pid_npc_test}
\end{figure}

Рассмотрим значимость последних двух эффектов и способы их устранения.

\subsubsection{Статическая ошибка НС--Р}

Эффект статической ошибки был рассмотрен при обучении нейросетевой
модели объекта управления.  Он связан с различием формы обучающего и
контрольного сигнала.  В частности, статическая ошибка будет возникать
на ступенчатой уставке в том случае, если нейросетевой регулятор был
обучен на стохастическом сигнале уставки.  Эффект статической ошибки
нейронной сети, как отмечалось на \pgref{amplify-zero}, проявляет себя
на ступенчатом контрольном сигнале уставки усилением нуля и ошибочным
коэффициентом передачи.

Если условия нормальной эксплуатации регулятора в контуре управления
характеризуются кусочно-постоянной уставкой, рекомендуется для
настройки НС--Р взять обучающую выборку, имеющую подобный вид.  В этом
случае нейросетевая аппроксимация поведения ПИД регулятора будет более
качественной.  Однако полностью устранить этим способом эффект
статической ошибки не всегда удается.

Значительно лучший результат дает подход, основанный на предположении
о симметрии функций $u_{PID}(t)$ при симметрии функций $r(t)$, $e(t)$
относительно оси времени.  В этом случае задача аппроксимации для
нейронной сети упрощается, так как отпадает потребность в пороге ---
весовом коэффициенте $w_0$ (см. формулу \eqref{eq:neuron_output}), ---
предназначенном для смещения рабочей области функции активации.
Функционирование нейрона в этом случае определяется уравнением

\begin{equation}\label{eq:neuron_output_nobias}
y=\fa(\sum_{j=1}^nw_j x_j)
\end{equation}

После предварительного обучения НС--Р с нулевым порогом на
стохастическом обучающем множестве контрольная проверка на единичной
ступени показала уменьшение эффекта статической ошибки по сравнению со
случаем использования обычных нейронов со смещением $w_0$
(\figref{fig:npc_static_error}).  В частности, ошибка в имитации
коэффициента передачи уменьшилась с 6\% до 4.5\%, а эффект усиления
нуля уменьшился до исчезающе малых величин.

\begin{figure}[h]
\centering
\hbox{\psfig{figure=npc_nob_step_test.ps,angle=270,width=0.8\textwidth,%
             height=0.35\textheight}}
\caption{Эффекты статической ошибки НС--Р в случаях наличия смещения $w_0$ у
         нейронов сети и в случае его отсутствия.}
\label{fig:npc_static_error}
\end{figure}

Следует отметить, что эффект статической ошибки проявляет себя в
основном на участках постоянной уставки при полном отсутствии помех.
В случае наличия постоянных изменений на входах НС--Р, которые могут
быть вызваны изменениями уставки или шумом в канале наблюдения, эффект
статической ошибки себя не проявляет.  Это означает отсутствие
различий между исходным ПИД регулятором и предварительно обученным
нейросетевым.  Подобным может считаться случай синтеза Винеровского
оптимального регулятора вследствие наличия случайных помех и
стохастической природы уставки.

\subsubsection{Требования к обучающей и контрольной выборкам}

Снижение качества имитации при выходе сигнала за пределы обучающего
множества также уже рассматривалось в связи с синтезом нейросетевой
модели объекта управления (п.~\ref{nnp_map_uy}).  Для обозначения
границ, в пределах которых нейронная сеть функционирует с
эффективностью, полученной при обучении, на
\pgref{nnp_guarantee_quality_area} был введен термин области
гарантированного качества. Данное понятие легко обобщается на случай
обучения нейросетевого регулятора.

Специфика настройки НС--Р по сравнению с нейросетевой моделью
предсказания наблюдаемого выхода объекта заключается в автономности
нейросети регулятора.  Предсказанное с помощью НС--О значение может
значительно отличаться от наблюденного и это никак не скажется ни на
функционировании системы управления, ни на работоспособности самой
модели, поскольку на входах модели предсказания --- наблюденные
значения, которые могут быть лишь искажены шумами.  НС--Р представляет
собой автономную нейросеть, ошибочный выход которой влияет на систему
управления и на функционирование самого нейросетевого регулятора через
обратную связь.

Имитационные эксперименты показали преимущество стохастической уставки
перед детерминированной для получения обучающего множества для НС--Р с
входами ($r_k,e_k$).  Это объясняется прежде всего тем, что случайная
уставка в совокупности с ошибкой более равномерно покрывают плоскость
$r\times e$ обучающими парами $r_k,e_k$, чем аналогичная
детерминированная.  В целом, рекомендации по формированию обучающих
выборок для НС--Р аналогичны сформулированным для нейросетевой модели
объекта управления в п.~\ref{nnp_series_req}.

При условии недетерминированности уставки длина выборки, образующей
обучающее множество, определяется из условия покрытия области,
гарантирующей качество имитации ПИД регулятора в рабочем диапазоне
уставок и ошибок.  Если имеется возможность целенаправленно
формировать уставку, рекомендуется псевдослучайно образовать временной
ряд, многократно достигающий границ рабочего диапазона уставок.

Контрольная выборка должна быть получена в режиме штатного
функционирования контура управления с ПИД регулятором в контуре.  При
этом уставка должна иметь вид, наиболее типичный для рабочего режима
системы.

\subsubsection{Дообучение нейросетевого регулятора}%
\label{nnc_final_training}

Дообучение НС--Р в контуре управления представляет собой
оптимизационную процедуру с критерием минимизации среднеквадратичной
ошибки управления.  Настроенная на предыдущем этапе вне контура
нейросеть регулятора (п.~\ref{nnc_pre}), во-первых, является начальным
приближением для оптимизационного алгоритма, во-вторых, поддерживает
устойчивость в системе управления.  Оптимизация осуществляется с
помощью алгоритма обратного распространения через нейросетевую модель
объекта управления, функционирующую в процессе дообучения.  Алгоритм
оптимизации описан в п.~\ref{nnc_optimal_training}.  Нейросетевая
модель объекта управления должна быть заранее обучена вне контура
(п.~\ref{nnpsynthesis}).

В реальной системе управления дообучение осуществляется в процессе ее
штатной эксплуатации.  В каждый дискретный момент времени
рассчитываются величины коррекции весовых коэффициентов НС--Р.
Весовые коэффициенты корректируются на каждом шаге или с некоторым
периодом (пакетное обновление).  В последнем случае величины коррекции
каждого весового коэффициента за прошедшие в периоде моменты времени
суммируются и по окончании периода изменяют нейросеть куммулятивно.
Данная техника позволяет обновлять нейросеть регулятора статистически
устойчивыми на периоде величинами коррекции.  Это позволяет уменьшить
влияние помех на процесс обучения нейросетевого регулятора и сделать
его более устойчивым.

Процесс дообучения НС--Р в описанных условиях существенно зависит от
уставки и помехи в канале наблюдения.  Даже в том случае, если сделать
уставку периодичной с периодом обновления весовых коэффициентов НС--Р,
наличие случайной помехи придает процессу обучения стохастический
характер.  График среднеквадратичной ошибки в этом случае изобилует
участками с возрастанием и убыванием ошибки при общей тенденции к
уменьшению.  На \figref{fig:cerr_trace}а сплошной линией показан
график среднеквадратичной ошибки в процессе обучения, а пунктиром ---
приближение тренда экспонентой.

\begin{figure}[h]
\centering
\begin{tabular}{cc}
\hbox{\psfig{figure=cerr_trace_1000.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} &
\hbox{\psfig{figure=cerr_trace.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} \\
а) & б)\\
\end{tabular}
\caption{Примеры графиков среднеквадратичной ошибки при дообучении НС--Р
         в реальных (а) и стационарных (б) условиях.}
\label{fig:cerr_trace}
\end{figure}

Влияние случайных факторов затрудняет определение момента достижения
регулятором требуемого качества функционирования, что мешает
исследованию его свойств и проведению сравнительных испытаний с иными
регуляторами.  Поэтому целесообразно в рамках имитационного
эксперимента искусственно сделать процесс обучения стационарным и
рассмотреть свойства полученного в таких условиях нейросетевого
регулятора.

%\subsubsection{Дообучение в стационарных условиях}

{\it Стационарным обучением }назовем процесс настройки нейросетевого
регулятора с пакетным обновлением весовых коэффициентов при котором в
каждой эпохе повторяются одни и те же ряды уставки и помехи.  Как
показано на \figref{fig:ctrlloop}, эти два ряда полностью определяют
траекторию системы управления.  В реальных условиях ряд $n(t)$
недоступен не только для формирования, но даже для измерения.  Однако
в условиях имитационного эксперимента, проводимого на цифровом
компьютере, возможно сгенерировать и многократно использовать любой
псевдослучайный числовой ряд.  Пример графика среднеквадратичной
ошибки в процессе стационарного обучения приведен на
\figref{fig:cerr_trace}б.

График имеет характер убывающей экспоненты.  Он наглядно демонстрирует
недостижимость нулевой ошибки, поскольку асимптота графика
среднеквадратичной ошибки всегда больше нуля.  В силу отсутствия
исчерпывающего теоретического базиса трудно и даже невозможно
предсказать, какого значения ошибки удасться добиться в процессе
настройки искусственной нейронной сети данной архитектуры на заданном
обучающем множестве.  По этой причине критерием завершения
стационарного обучения нейросетевого регулятора наиболее логично
сделать достижение некоторого порога уменьшения дискретной производной
$\Delta\MSE(t)$.  Порог выбирается так, чтобы дальнейшее продолжение
обучения перестало значимо уменьшать $\MSE$.

\subsubsection{Влияние свойств нейросетевой модели на дообучение
               нейросетевого регулятора}%
\label{nnp_on_nnc_influence}

В условиях стационарного дообучения НС--Р становится возможным в
имитационном эксперименте исследовать, как влияет нейросетевая модель
объекта управления на скорость и качество дообучения.  Степень этого
влияния осталась нерешенным вопросом методики синтеза НС--О
(п.~\ref{nnp_criteria_and_goal}).

Серия имитационных экспериментов проводилась с предварительно
настроенными нейросетевыми регуляторами и нейросетевыми моделями
объекта управления.  Для исследования влияния сложности архитектуры
НС--О на обучение НС--Р были взяты нейросети $\mathcal{N}^o_{1+Dy,1}$,
$\mathcal{N}^o_{1+Dy,5,1}$, $\mathcal{N}^o_{1+Dy,5,3,1}$ с различным
количеством входов прошлых наблюдений объекта: $1\le D_y\le 3$.  В
экспериментах принимали участие нейросетевые регуляторы следующих
архитектур: $\mathcal{N}^p_{r+e,1}$, $\mathcal{N}^p_{r+e,5,1}$,
$\mathcal{N}^p_{r+e,5,3,1}$.

Эксперимент заключался в дообучении НС--Р в стационарных условиях по
одной из моделей.  Обучение завершалось при снижении скорости
уменьшения $\MSE$ ниже $10^{-5}$.  Длина эпохи (и обучающего временного
ряда) была равна 500.  Коэффициенты скорости обучения для скрытых и
выходных нейронов были взяты равными 0.005 и 0.0001 соответственно.

В качестве оценки скорости обучения НС--Р при различных НС--О было
взято количество эпох до завершения обучения.  Результаты приведены
на~\figref{fig:noc_epochs}.

\begin{figure}[h]
\centering
\hbox{\psfig{figure=noc_epochs.ps,angle=270,width=0.8\textwidth,%
             height=0.35\textheight}}
\caption{Длительность дообучения НС--Р различных архитектур при различных
         архитектурах НС--О, использовавшихся для инверсии объекта управления.}
\label{fig:noc_epochs}
\end{figure}

На~\figref{fig:noc_epochs} изображены три прозрачные поверхности,
$z$--координата которых показывает длительность обучения в эпохах
НС--Р некоторой архитектуры, заданной парой $(x, y)$.  На
горизональных осях отложены изменяемые параметры архитектуры НС--О ---
количество скрытых слоев (0, 1, 2) и количество прошлых наблюдений
$D_y$ (1, 2, 3), подаваемых на вход нейросетевой модели объекта
управления.  Данный график показывает следующие закономерности:

\begin{enumerate}

\item
количество прошлых наблюдений $D_y$, подаваемых на вход НС--О, не
оказывает влияния на скорость обучения НС--Р;

\item
для простейшей архитектуры НС--Р $\mathcal{N}^p_{r+e,1}$ скорость
обучения тем выше, чем проще архитектура НС--О;

\item
для более сложных архитектур НС--Р с одним или двумя скрытыми слоями
скорость обучения не зависит от сложности модели;

\item
более сложные архитектуры НС--Р обучаются быстрее, чем простые.

\end{enumerate}

Следует отметить, что в анализируемом графике приведены только данные
длительности обучения.  Как уже отмечалось, критерием завершения
обучения являлось не достижение некоторого желаемого уровня ошибки, а
снижение скорости сходимости оптимизационного алгоритма ниже заданного
порога.  Достигнутый же уровень ошибки в конце обучения на графике не
отражен.

Среднеквадратичные ошибки, достигнутые при обучении, приводятся в
таблице~\ref{tabl:noc_mse}.

\begin{table}[ht]
\caption{Качество дообучения НС--Р при различных НС--О.}
\label{tabl:noc_mse}
\begin{tabular}{|l|r|c|c|c|}
\hline
Нейросетевой & \multicolumn{4}{|l|}{ Нейросетевая модель } \\
\cline{3-5}
регулятор &  & $D_y=1$ & $D_y=2$ & $D_y=3$ \\[3pt]
\hline
          & $\mathcal{N}^o_{1+Dy,1}$    & 0.0029 & 0.0029 & 0.0029 \\
$\mathcal{N}^p_{r+e,1}$
          & $\mathcal{N}^o_{1+Dy,5,1}$  & 0.0029 & 0.0029 & 0.0029 \\
          & $\mathcal{N}^o_{1+Dy,5,3,1}$& 0.0029 & 0.0029 & 0.0029 \\[3pt]
\hline
          & $\mathcal{N}^o_{1+Dy,1}$    & 0.0068 & 0.0068 & 0.0068 \\
$\mathcal{N}^p_{r+e,5,1}$
          & $\mathcal{N}^o_{1+Dy,5,1}$  & 0.0068 & 0.0068 & 0.0068 \\
          & $\mathcal{N}^o_{1+Dy,5,3,1}$& 0.0068 & 0.0068 & 0.0068 \\[3pt]
\hline
          & $\mathcal{N}^o_{1+Dy,1}$    & 0.0155 & 0.0155 & 0.0155 \\
$\mathcal{N}^p_{r+e,5,3,1}$
          & $\mathcal{N}^o_{1+Dy,5,1}$  & 0.0155 & 0.0155 & 0.0155 \\
          & $\mathcal{N}^o_{1+Dy,5,3,1}$& 0.0155 & 0.0155 & 0.0155 \\[3pt]
\hline
\end{tabular}
\end{table}

Из данных, приведенных в таблице, видно, что достигаемый при
дообучении НС--Р уровень среднеквадратичной ошибки зависит только от
архитектуры самого нейросетевого регулятора.  Зависимость от
архитектуры НС--О в экспериментах не была обнаружена.

\subsubsection{Ошибка идентификации в процессе дообучения НС--Р}
\label{nnc_final_identif_error}

В экспериментах исследовалось поведение ошибки идентификации
нейросетевой модели объекта управления.  Один из полученных графиков
приведен на~\figref{fig:iderr_trace}.  Возрастание ошибки
идентификации является типичным.  Это явление объясняется тем, что в
процессе подстройки НС--Р изменяются условия, в которых была получена
нейросетевая модель объекта управления.

Если в течение первой обучающей эпохи поведение нейросетевого
регулятора было близким к исходному ПИД, то после каждого обновления
весовых коэффициентов поведение НС--Р все больше отдаляется от ПИД,
так как регулятор приобретает свойства оптимального.  Система
управления в нелинейным нейросетевым регулятором также является
нелинейной, а значит, в отличие от линейной, ее свойства зависят от
формы проходящего по ней сигнала.  Можно показать, что при каждом
обновлении весовых коэффициентов реакция НС--Р на один и тот же
входной вектор будет меняться, то есть форма сигнала управления при
дообучении постоянно изменяется, что и приводит к потере качества
предсказания выхода объекта нейросетевой моделью.

\begin{figure}[h]
\centering
\hbox{\psfig{figure=iderr_trace.ps,angle=270,width=0.8\textwidth,%
             height=0.35\textheight}}
\caption{График ошибки идентификации в процессе стационарного дообучения НС--Р.}
\label{fig:iderr_trace}
\end{figure}

Ухудшение качества функционирования модели в ходе проведенных
экспериментов ни разу не приводило к потере устойчивости в системе
из-за неадекватной коррекции весовых коэффициентов НС--Р.  Однако
вполне вероятно, что в некоторых случаях даже для линейных объектов
ухудшение качества предсказания может стать столь большим, что оценка
якобиана объекта, делаемая с помощью НС--О, будет слишком плохой.
Рациональным выходом из данной ситуации может стать дообучение модели
объекта управления в контуре по мере дообучения регулятора.

Проведенные эксперименты с одновременным обновлением весовых
коэффициентов НС--О и НС--Р продемонстрировали очень быструю потерю
устойчивости в контуре управления.  Для того, чтобы избежать этого,
следует обучать НС--Р и НС--О попеременно.  Например, в эпохи с
нечетными номерами обучается НС--Р, а в эпохи с четными -- НС--О.
Данный подход может оказаться плодотворным также в том случае, когда
ухудшение качества идентификации объективно вызвано изменением свойств
объекта, то есть, в нестационарных условиях.  Перспективной выглядит
также подстройка нейросетевой модели при настройке нейросетевого
управления нелинейным объектом.

\subsubsection{Длительность эпохи в процессе дообучения}

\label{nnc_final_epoch_length}%
Одним из важных параметров методики обучения искусственных нейронных
сетей является длительность эпохи, в течении которой изменения весовых
коэффициентов не вносятся в нейросеть, а накапливаются (суммируются).
Обновление осуществляется только в конце эпохи.  Особенности выбора
коэффициента скорости обучения и его связь с длиной эпохи обсуждались
в п.~\ref{batch_eta}.  Исследуем в имитационном эксперименте влияние
длительности эпохи на процесс дообучения нейросетевого регулятора в
случае стохастических $r(t)$ и $n(t)$.  Для этого были обучены НС--Р
при различных значениях длины эпохи $L$.  Сообразно длине эпохи были
выбраны коэффициенты скорости обучения в скрытых слоях $\eta_h=\eta/L$
и в выходном слое $\eta_o=\eta/2L$, причем базовое значение
коэффициента $\eta=1$ во всех сеансах обучения было взято одинаковым.

В случае проведения эксперимента в условиях, максимально приближенных
к реальным (постоянно изменяющиеся $r(t)$ и $n(t)$), выявить
устойчивые зависимости проблематично.  Для того, чтобы снизить влияние
случайных факторов, во-первых, эксперимент проводился в стационарных
условиях, во-вторых, каждый сеанс обучения повторялся при различных
выборках уставки и помехи 10 раз.

\label{nnc-final-case-cond}%
Условия проведения эксперимента:
\begin{itemize}
\item
Объект управления: $P^*(z)=\displaystyle\frac{z}{z-0.5}$

\item
Исходный регулятор: $C_{PID}^*(z)=0.4 +
		     0.5\displaystyle\frac{z}{z-1} +
		     0.05\displaystyle\frac{z^2-2z+1}{z(z-1)}$

\item
Формирующий фильтр уставки: $R^*(z)=\displaystyle\frac{0.625z}{z-0.779}$
\item
Помеха наблюдения: н.б.ш. \GaDi{0}{0.1}

\item
Архитектура НС--О: $\mathcal{N}^o_{1+1,1}$
\item
Архитектура НС--Р: $\mathcal{N}^p_{r+e,5,3,1}$

\item
Длительности эпохи: 5, 10, 25, 50, 100, 250, 500, 1000, 2500
\item
Длина тестовой выборки: 5000
\end{itemize}

Обучение проводилось с помощью одной и той же нейросетевой модели
объекта управления.  В качестве начального приближения был взят
предварительно настроенный вне контура подобно ПИД регулятору
нейросетевой.

Критерием завершения процесса обучения считалось уменьшение
среднеквадратичной ошибки управления за эпоху меньше чем на $10^{-5}$.
После завершения обучения все экземпляры НС--Р тестировались на одной
и той же тестовой выборке.

График финальной среднеквадратичной ошибки в зависимости от
длительности эпохи приведен на \figref{fig:noc_mse(epochlen)}а.  На
нем представлены среднее значение (сплошная линия) и стандартное
отклонение (пунктирная линия) среднеквадратичной ошибки управления
$\MSE_{final}$, на которой обучение было остановлено.  В силу малости
зафиксированного значения $\Delta\MSE<10^{-5}$ и экспоненциального
характера снижения ошибки дальнейшее обучение нецелесообразно, так как
оно уже не даст существенного улучшения качества управления.

На \figref{fig:noc_mse(epochlen)}б изображены графики среднего
значения (сплошная линия) и стандартного отклонения (пунктирная линия)
среднеквадратичной ошибки управления $\MSE_{test}$, полученные на
длинной тестовой выборке.

%то есть, чем короче эпоха, тем менее представительной она
%является для отражения качества настройки регулятора.

\begin{figure}[h]
\centering
\begin{tabular}{cc}
\hbox{\psfig{figure=noc_c_tr_mse_L.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} &
\hbox{\psfig{figure=noc_test_mse_L.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} \\
а) & б)\\
\end{tabular}
\caption{Зависимость $\MSE$ от длительности эпохи по завершении обучения (а)
         и на тестовой выборке (б).}
\label{fig:noc_mse(epochlen)}
\end{figure}

В условиях стационарного обучения и малого размера обучающей выборки
(размер равен длине эпохи $L$) нейронная сеть проявляет свойство
адаптации к конкретной обучающей выборке в противоположность
обобщающей способности.  Это проявляется в том, что при $L<20$ имеет
место $\MSE_{final}<\MSE_{test}$.  Адаптированность НС--Р к конкретной
реализации обучающей выборки также подчеркивается высоким значением
стандартного отклонения при малых длинах эпохи.

Рассматривая график стандартного отклонения $\MSE_{test}$, полученный
по 10 сеансам обучения, следует отметить, что с увеличением длины
эпохи статистическая устойчивость результата обучения НС--Р
увеличивается (стандартное отклонение уменьшается), в то время как
начиная с $L=200$ среднее значение ошибки стабилизируется.  Очевидно,
это минимальное значение ошибки управления которого можно добиться при
выбранной архитектуре НС--Р и заданных внешних условиях.  Критичным
параметром, влияющим на уровень ошибки нейросетевого управления,
является, очевидно уровень помехи.

Зависимость финальной ошибки идентификации от длины эпохи,
представленная на \figref{fig:id_err(epochlen)} средним значением и
стандартным отклонением, демонстрирует увеличение статистической
устойчивости нейросетевой идентификации с ростом $L$.  В целом,
большая длина эпохи способствует более точной оценке якобиана объекта
управления и, следовательно, более эффективному обучению НС--Р.
Однако, при увеличении $L$ больше 400 не наблюдается в среднем
улучшения качества идентификации.

\begin{figure}[h]
\centering
\hbox{\psfig{figure=noc_id_tr_mse_L.ps,angle=270,width=0.8\textwidth,%
             height=0.35\textheight}}
\caption{Зависимость ошибки идентификации в последней обучающей эпохе
         от длительности эпохи.}
\label{fig:id_err(epochlen)}
\end{figure}

Важной характеристикой процесса обучения является его суммарная
продолжительность.  На \figref{fig:training_dur(epochlen)}
представлена зависимость продолжительности обучения в дискретах
времени от длины эпохи.  Выявленный линейный характер зависимости
продолжительности (сплошная линия) от длины эпохи определяет временные
затраты на дообучение в среднем.  При $L=250$ линейный рост
стандартного отклонения (пунктирная линия), являющийся признаком
слабой статистической устойчивости, прекращается.  При продолжающемся
линейном росте среднего значения продолжительности это свидетельствует
о меньшем влиянии случайных факторов на процесс сходимости к
оптимальному нейросетевому управлению.

\begin{figure}[h]
\centering
\hbox{\psfig{figure=noc_tr_dur_L.ps,angle=270,width=0.8\textwidth,%
             height=0.35\textheight}}
\caption{Зависимость продолжительности обучения от длительности эпохи.}
\label{fig:training_dur(epochlen)}
\end{figure}

Подводя итоги проведенного эксперимента можно рекомендовать длину
эпохи при дообучении НС--Р в пределах от 200 до 500.  При меньших
значениях $L$ качество нейросетевого регулятора и статистическая
устойчивость его достижения оставляют желать лучшего.  При больших
значениях $L$ увеличение суммарной продолжительности обучения уже не
приводит к существенному улучшению получаемого в результате НС--Р.
Выявленные качественные зависимости позволяют подобрать оптимальное
значение длительности эпохи в каждом конкретном случае.

\subsubsection{Дообучение в реальных условиях}

Выбор параметров алгоритма обучения НС--Р в контуре управления
(длительность эпохи, коэффициент скорость обучения) обсуждался в
предыдущих параграфах.  Наиболее актуальными задачами, требующими
разрешения при дообучении НС--Р в реальных условиях, представляются:

\begin{itemize}

\item
исследование поведения среднеквадратичной ошибки управления и
идентификации в процессе дообучения с целью выяснения характера и
пределов их изменения;

\item
определение момента достижения нейросетевым регулятором наилучшего
качества управления с целью остановки процесса дообучения.

\end{itemize}

\subbbsection{Поведение среднеквадратичной ошибки}

Продолжим серию имитационных экспериментов в условиях, описанных на
с.~\pageref{nnc-final-case-cond}.  Теперь будем проводить дообучение
НС--Р в контуре управления.  В соответствии с выводами
п.~\ref{nnc_final_epoch_length} длительность эпохи обучения возьмем
равной 500 дискретным отсчетам времени.  Будем регистрировать
среднеквадратичную ошибку управления и идентификации, вычисляемые по
эпохе в процессе обучения.  Для проверки 


  В целью уменьшить влияние случайных факторов проведем 20
сеансов обучения.  Траектории средних значений среднеквадратичных
ошибок приведены на \figref{fig:avg_err_online_training}.

\begin{figure}[h]
\centering
\begin{tabular}{cc}
\hbox{\psfig{figure=noc_re_1_cerr_avg_online.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} &
\hbox{\psfig{figure=noc_re_1_iderr_avg_online.ps,angle=270,width=0.45\textwidth,%
             height=0.25\textheight}} \\
а) & б)\\
\end{tabular}
\caption{Усредненная на 20 сеансах траектория ошибки управления (а)
         и идентификации (б) в процессе дообучения НС--Р.}
\label{fig:avg_err_online_training}
\end{figure}

В дополнение к информации, представленной на графиках, следует
отметить, что дисперсия среднеквадратичных ошибок в течение сеанса
обучения оставалась постоянной, то есть, средние значения
действительно отражают тенденцию изменения величины всех 20 сеансов.

Представленные графики в целом отражают тенденции поведения
среднеквадратичных ошибок, предсказанные в п.~\ref{nnc_final_training}
и п.~\ref{nnc_final_identif_error} в условиях стационарного обучения.
Однако следует отметить факт прекращения роста среднеквадратичной
ошибки идентификации вскоре после прекращения спада ошибки управления.
Представляется очевидным, что изменение свойств нейросетевого
регулятора с линейных (унаследованных копированием поведения исходного
ПИД регулятора) на нелинейные, проявившиеся вследствие обучения в
контуре управления, приводит к ухудшению качества идентификации,
модель которой была построена в линейных условиях.




постоянная дисперсия траекторий среднеквадратичной ошибки управления.

Практически одновременное прекращение уменьшения ошибки управления и
роста ошибки идентификации.

Зависимость скорости спада ошибки управления от уровня помехи и
сложности архитектуры НС--О и НС--Р.

\begin{figure}[h]
\centering
\hbox{\psfig{figure=nnc_online_tr_test.ps,angle=270,width=0.8\textwidth,%
             height=0.35\textheight}}
\caption{Среднеквадратичная ошибка управления на тестовой выборке в процессе
         дообучения НС--Р разных архитектур.}
\label{fig:nnc_online_tr_test}
\end{figure}


\subsubsection{Критерий завершения дообучения в реальных условиях}


\subsubsection{Статистическая устойчивость дообучения}

Влияние коэффициентов скорости обучения и продолжительности периода на
устойчивость процесса обучения.

Б\'ольшая продолжительность периода делает процесс обучения более
устойчивым.  Неустойчивость дообучения НС--Р в контуре приводит к
потере устойчивости системой управления и в реальных условиях может
иметь разрушительные последствия.


\subsubsection{Влияние качества имитации на устойчивость контура}


\begin{equation}
u_k-u_{k-1}=\Delta u_k=K_P(e_k-e_{k-1})+K_I e_k+K_D(e_k-2e_{k-1}+e_{k-2})
\end{equation}


\begin{equation}\label{eq:reference}
R^*(z)=\displaystyle\frac{0.625z}{z-0.779}
\end{equation}

\begin{equation}\label{eq:noise}
N^*(z)=0.7
\end{equation}

\begin{equation}\label{eq:plant}
P^*(z)=\displaystyle\frac{z}{z-0.5}
\end{equation}

\begin{equation}\label{eq:contr-pid}
C_{PID}^*(z)=0.4 +
       0.5\displaystyle\frac{z}{z-1} +
       0.05\displaystyle\frac{z^2-2z+1}{z(z-1)}
\end{equation}

\begin{equation}\label{eq:contr-wiener}
C_W^*(z)=\displaystyle\frac{0.528z-0.264}{z-0.896}
\end{equation}
