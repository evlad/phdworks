% -*-coding: koi8-r;-*-
% $Id: Part2_NNC.tex,v 1.9 2005-02-10 20:58:07 evlad Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Синтез нейросетевого регулятора}%
\label{nncsynthesis}

Задача обучения нейросетевого регулятора (НС--Р), как уже отмечалось в
п.~\ref{nnc_optimal_training}, состоит из двух этапов: получения копии
действующего регулятора вне контура управления и дообучения
функционирующего нейросетевого регулятора в контуре с использованием
инверсной модели объекта.  Будем считать, что в контуре управления
исходно функционирует какой-либо линейный регулятор, например, ПИД.

\subsubsection{Предварительное обучение нейросетевого регулятора}%
\label{nnc_pre}

ПИД регулятор представляет собой динамическую систему, обладающую
памятью (кроме простейшего пропорционального случая управления).
Первым этапом синтеза нейросетевого регулятора является его
предварительное обучение подобно исходному ПИД регулятору.  Главной
целью этого этапа является точность имитации, поскольку на следующем
этапе построенный нейросетевой регулятор будет управлять реальным
объектом в контуре.  Считая, что исходный регулятор обеспечивает
устойчивость и некоторое удовлетворительное качество управления, можно
ожидать, что достаточно точный имитатор будет управлять системой
подобно.

Качество обучения нейронной сети определяется выбором архитектуры,
обучающих данных и параметров методики обучения.  Исследуем влияние
перечисленных факторов на предварительное обучение нейросетевого
регулятора.

\subsubsection{Архитектура нейросетевого регулятора}

Сравнивая задачу предварительного обучения НС--Р с задачей синтеза
нейросетевой модели объекта следует при очевидном сходстве (имитация
некоторой линейной системы) отметить два фундаментальный различия.
Во-первых, НС--О может быть реализована как в виде автономной модели
поведения, так и в виде зависимой от объекта модели предсказания, в то
время как НС--Р должен полностью заменить исходный регулятор.
Во-вторых, назначение НС--О --- копирование поведения объекта
управления, а НС--Р должен быть сначала обучен подобно исходному
линейному регулятору, но потом в процессе дообучения в контуре
управления может изменить свои свойства сообразно задаче минимизации
среднеквадратичной ошибки управления.  Буквальное повторение свойств
линейного регулятора не является основной целью, а лишь предваряет ее,
поэтому не имеет смысла формировать архитектуру нейросетевого
регулятора только исходя из линейности исходного регулятора.

Как и в случае с синтезом НС--О возникает задача выбора между
статической и динамической (с обратными связями) архитектурами
нейронной сети.  Аргументом в пользу динамической нейронной сети
является наиболее очевидный путь имитации свойств линейной
динамической системы с помощью автономной модели.  Вместе с тем, у
динамической нейронной сети имеются как недостатки общего плана,
упомянутые в п.~\ref{nnp_inputs}, так и специфические, проявляющиеся
при использовании обратных связей в НС--Р:

\begin{enumerate}
\item эффект исчезающего градиента ({\em vanishing gradient}) при
      обучении по методу BPTT;
\item увеличение требований к ресурсам и усложнение алгоритма обучения
      в контуре, вызванное процедурой обращения времени;
\item усложнение анализа устойчивости системы за счет появления еще
      одного контура обратной связи с нелинейным элементом (нейросетью).
\end{enumerate}

Применение статической нейронной сети для реализации НС--Р не имеет
перечисленных недостатков, кроме того, обучение статической нейросети
в целом осуществляется быстрее, чем динамической.  Однако, как и в
случае с нейросетевой моделью объекта управления, следует с помощью
надлежащего формирования структуры входов нейросети обеспечить
динамические свойства НС--Р, аналогичные имеющимся у ПИД регулятора в
контуре.

\subsubsection{Структура входов нейросети}

Рассмотрим несколько вариантов формирования вектора входных значений
для НС--Р.  Обязательно следует проверить вариант подключения,
аналогичный исходному регулятору.  В этом случае на вход подается
только значение ошибки в текущий момент времени $e_k$.  Как было
показано ранее при построении нейросетевой модели объекта, этот
вариант подключения статической нейронной сети не может обеспечить
адекватную имитацию свойств динамической системы.  Чтобы преодолеть
ограничение статического отображения надо искусственно организовать
память с помощью повторения прошлых входов $e_k\ldots e_{k-d}$.
Поэтому исследуем поведение НС--Р при различных значениях емкости
памяти: $0\le d\le 4$.

Рассмотрим также варианты подключения НС--Р с входами $e_k,\Delta e_k$
и $r_k,e_k$.  Последний представляет собой объединение концепций
управления по возмущению $r(t)$ и отклонению $e(t)$.

Для сравнения перечисленных вариантов формирования входного вектора
НС--Р была проведена серия экспериментов.  Ниже приводится постановка
и результаты одного из них.

% nn/dpid.new/contrp/...
Эксперимент проводился в условиях стохастической уставки при наличии
случайной аддитивной помехи в наблюдаемом выходе объекта управления.
Формирующие фильтры уставки $R^*(z)=\frac{0.625z}{z-0.779}$ и помехи
$N^*(z)=0.4$.  Объект $P^*(z)=\frac{z}{z-0.5}$ управлялся ПИД
регулятором $C^*(z)=0.4 + 0.5\frac{z}{z-1} +
0.05\frac{z^2-2z+1}{z(z-1)}$.  Регулятор был настроен на ступенчатом
возмущающем сигнале по критерию минимизации длительности переходного
процесса при максимальном перерегулировании в пределах 4\% амплитуды
возмущающего сигнала.

Нейронная сеть регулятора имела архитектуру $\NN^p_{x,7,3,1}$,
где $x$ --- размерность входного вектора.  Обучение осуществлялось на
выборке длиной 200 в течение 400 эпох, а контрольная выборка имела
длину 500, причем если ошибка на контрольной выборке начинала
возрастать, то обучение досрочно прекращалось.  Критерием обучения
являлась минимизация среднеквадратичной ошибки воспроизведения.

\begin{table}[ht]
\centering
\caption{Сравнение точности имитации ПИД регулятора вне контура управления
         при различном способе формирования входного вектора НС--Р и
         различных параметрах уставки и помехи}
\label{tabl:nnc_pretr_input_vec}
\begin{tabular}{|c|l|c|c|c|c|}
\hline
\multicolumn{2}{|r|}{Эксперимент} & {\sf А} & {\sf Б} & {\sf В} & {\sf Г}\\
\hline
\multicolumn{2}{|r|}{Уставка} &
  \multicolumn{2}{|c|}{Стохастическая $R^*(z)$} & $\sin(t)$ & $0$ \\
\hline
\multicolumn{2}{|r|}{Помеха} & $N^*(z)=0.4$ & $N^*(z)=0.7$ & $N^*(z)=0.4$ & $N^*(z)=0.4$\\
\hline\hline
N   & Входной & \multicolumn{4}{|c|}{Среднеквадратичная ошибка} \\
пп. & вектор  & \multicolumn{4}{|c|}{на контрольной выборке}\\
\hline
1 & $e_k$                 & 0.3228 & 0.2906 & 0.1299 & 0.0027\\
2 & $e_k,e_{k-1}$         & 0.2993 & 0.2710 & 0.1291 & 0.0022\\
3 & $e_k\ldots e_{k-2}$   & 0.2709 & 0.2459 & 0.1270 & 0.0016\\
4 & $e_k\ldots e_{k-3}$   & 0.2482 & 0.2284 & 0.1240 & 0.0013\\
5 & $e_k\ldots e_{k-4}$   & 0.2385 & 0.2163 & 0.1188 & 0.0013\\
6 & $e_k,\Delta e_k$      & 0.2980 & 0.2738 & 0.1293 & 0.0023\\
7 & $r_k,e_k$             & 0.0388 & 0.0968 & 0.0039 & 0.0040\\
\hline
\end{tabular}
\end{table}

%% $e_k$     0.1296
%% $r_k,e_k$ 0.0037

В \tablref{tabl:nnc_pretr_input_vec} результаты эксперимента приведены
в столбце {\sf А}.  Анализ значений среднеквадратичной ошибки
показывает, что увеличение емкости памяти прошлых входов позволяет
лишь незначительно уменьшить ошибку имитации (строки таблицы 1--5).
Вариант с первой разностью ошибки (строка 6) показывает близкие
результаты с вариантом $e_k,e_{k-1}$ (строка 2).  Очевидно, что для
НС--Р эти варианты информационно эквивалентны.  Наилучшее качество
имитации исходного регулятора было достигнуто НС--Р с входным вектором
$r_k,e_k$, причем достигнутый уровень ошибки в этом случае оказался
меньше почти на порядок, чем в остальных.

Эксперименты показали, что при увеличении мощности помехи
относительное преимущество НС--Р с входным вектором $r_k,e_k$
уменьшается (столбец {\sf Б} таблицы).  Таким образом, применение в
качестве входного вектора $e_k\ldots e_{k-d}$ может оказаться в
некоторых случаях оправданным.

Были также рассмотрены случаи предварительного обучения НС--Р по
детерминированной уставке различной формы.  По результатам
экспериментов наилучшим вариантом формирования входного вектора с
большим отрывом оказалось совмещенное управление по возмущению и
отклонению: $r_k,e_k$ (строка 6).  Оказалось также, что результирующий
уровень ошибки при периодической уставке практически не зависит от ее
формы.  В частности, числовые значения среднеквадратичной ошибки на
гармоническом сигнале (столбец {\sf В}
\tablref{tabl:nnc_pretr_input_vec}) и на меандре примерно одинаковы.

Отдельно был рассмотрен случай задачи стабилизации, когда уставка
постоянна, например, равна 0 (столбец {\sf Г}
\tablref{tabl:nnc_pretr_input_vec}).  Нейросетевой регулятор с
входным вектором $r_k,e_k$ показал худший результат, чем любой из
вариантов с повторением прошлых значений ошибки.  Видно, что
отсутствие влияния уставки на нейронную сеть в данном случае делает
наличие входа $r_k$ не только бесполезным, но и вредным.

Проводились также эксперименты с объектом управления с чистым
запаздыванием и объектом управления второго порядка, анализ которых
обнаружил те же закономерности.

По результатам проведенных экспериментов можно сформулировать
некоторые рекомендации по формированию входного вектора нейросетевого
регулятора по критерию наилучшей имитации исходного ПИД регулятора:

\begin{itemize}
\item
В случае задачи стабилизации (постоянное значение уставки)
рекомендуется использовать один из вариантов с повторением прошлых
значений: $e_k\ldots e_{k-d}$.  При увеличении емкости памяти прошлых
значений (параметр $d$) качество имитации при наличии помехи будет
возрастать.

\item
В случае изменяющегося значения уставки предпочтительным является
совмещенное управление по возмущению и отклонению: $r_k,e_k$.  При
значительном уровне помехи улучшить качество имитации можно вводя и
увеличивая память прошлых состояний.  Входной вектор в этом случае
будет иметь вид $r_k,e_k\ldots e_{k-d}$
\end{itemize}

Испытание предварительно настроенного НС--Р в системе управления
вместо ПИД регулятора показало, что система успешно управляется
нейросетью.  Во всех проведенных экспериментах система с нейросетевым
регулятором в контуре не потеряла устойчивости.  Вместе с тем отмечен
ряд особенностей и недостатков, присущих нейросетевому управлению:

\begin{enumerate}

\item быстродействие нейросетевого регулятора не хуже ПИД, а время
наступления установившегося режима даже меньше, чем у ПИД регулятора
(\figref{fig:pid_npc_test}а);

\item при неизменной уставке (в том числе, при $r(t)=0$) в системе
с НС--Р может иметь место статическая ошибка (на примере со
ступенчатой уставкой на \figref{fig:pid_npc_test}а видно, что
перерегулирование составляет 6\% номинального уровня);

\item при выходе уровня уставки за пределы диапазона обучающих данных
точность управления падает (\figref{fig:pid_npc_test}б).
\end{enumerate}

\begin{figure}[h]
\begin{tabular}{cc}
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{pid_npc_step_test.ps} &
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{pid_npc_stoch_test.ps} \\
а) & б)\\
\end{tabular}
\caption{Отклик системы на прямоугольное (а) и стохастическое (б)
         возмущающее воздействие при ПИД и НС регулировании ($r_k,e_k$).}
\label{fig:pid_npc_test}
\end{figure}

Рассмотрим значимость последних двух эффектов и способы их устранения.

\subsubsection{Статическая ошибка НС--Р}%
\label{nnc_static_error}

Эффект статической ошибки был рассмотрен при обучении нейросетевой
модели объекта управления.  Он связан с различием формы обучающего и
контрольного сигнала.  В частности, статическая ошибка будет возникать
на ступенчатой уставке в том случае, если нейросетевой регулятор был
обучен на стохастическом сигнале уставки.  Эффект статической ошибки
нейронной сети, как отмечалось на \pgref{amplify-zero}, проявляет себя
на ступенчатом контрольном сигнале уставки усилением нуля и ошибочным
коэффициентом передачи.  Отмечается, что для компенсации этого
нежелательного эффекта можно использовать параллельно с нейросетевым
линейный регулятор~\cite{steck96}.  Далее рассмотрим способы
устранения эффекта статической ошибки, не требующие в включения в
контур управления дополнительных узлов.

Если условия нормальной эксплуатации регулятора в контуре управления
характеризуются кусочно-постоянной уставкой, рекомендуется для
настройки НС--Р взять обучающую выборку, имеющую подобный вид.  В этом
случае нейросетевая аппроксимация поведения ПИД регулятора будет более
качественной.  Однако полностью устранить этим способом эффект
статической ошибки не всегда удается.

Значительно лучший результат дает подход, основанный на предположении
о симметрии функций $u_{PID}(t)$ при симметрии функций $r(t)$, $e(t)$
относительно оси времени.  В этом случае задача аппроксимации для
нейронной сети упрощается, так как отпадает потребность в пороге ---
весовом коэффициенте $w_0$ (см. формулу \eqref{eq:neuron_output}), ---
предназначенном для смещения рабочей области функции активации.
Функционирование нейрона в этом случае определяется уравнением

\begin{equation}\label{eq:neuron_output_nobias}
y=\fa(\sum_{j=1}^nw_j x_j)
\end{equation}

После предварительного обучения НС--Р с нулевым порогом на
стохастическом обучающем множестве контрольная проверка на единичной
ступени показала уменьшение эффекта статической ошибки по сравнению со
случаем использования обычных нейронов со смещением $w_0$
(\figref{fig:npc_static_error}).  В частности, ошибка в имитации
коэффициента передачи уменьшилась с 6\% до 4.5\%, а эффект усиления
нуля уменьшился до исчезающе малых величин.

\begin{figure}[h]
\centering
\includegraphics[angle=270,width=0.8\textwidth,%
             totalheight=0.35\textheight]{npc_nob_step_test.ps}
\caption{Эффекты статической ошибки НС--Р в случаях наличия смещения $w_0$ у
         нейронов сети и в случае его отсутствия.}
\label{fig:npc_static_error}
\end{figure}

Следует отметить, что эффект статической ошибки проявляет себя в
основном на участках постоянной уставки при полном отсутствии помех.
В случае наличия постоянных изменений на входах НС--Р, которые могут
быть вызваны изменениями уставки или шумом в канале наблюдения, эффект
статической ошибки себя не проявляет.  Это означает отсутствие
различий между исходным ПИД регулятором и предварительно обученным
нейросетевым.  Подобным может считаться случай синтеза Винеровского
оптимального регулятора вследствие наличия случайных помех и
стохастической природы уставки.

\subsubsection{Требования к обучающей и контрольной выборкам}

Снижение качества имитации при выходе сигнала за пределы обучающего
множества также уже рассматривалось в связи с синтезом нейросетевой
модели объекта управления (п.~\ref{nnp_map_uy}).  Для обозначения
границ, в пределах которых нейронная сеть функционирует с
эффективностью, полученной при обучении, на
\pgref{nnp_guarantee_quality_area} был введен термин области
гарантированного качества. Данное понятие легко обобщается на случай
обучения нейросетевого регулятора.

Специфика настройки НС--Р по сравнению с нейросетевой моделью
предсказания наблюдаемого выхода объекта заключается в автономности
нейросети регулятора.  Предсказанное с помощью НС--О значение может
значительно отличаться от наблюденного и это никак не скажется ни на
функционировании системы управления, ни на работоспособности самой
модели, поскольку на входах модели предсказания --- наблюденные
значения, которые могут быть лишь искажены шумами.  НС--Р представляет
собой автономную нейросеть, ошибочный выход которой влияет на систему
управления и на функционирование самого нейросетевого регулятора через
обратную связь.

Имитационные эксперименты показали преимущество стохастической уставки
перед детерминированной для получения обучающего множества для НС--Р с
входами ($r_k,e_k$).  Это объясняется прежде всего тем, что случайная
уставка в совокупности с ошибкой более равномерно покрывают плоскость
$r\times e$ обучающими парами $r_k,e_k$, чем аналогичная
детерминированная.  В целом, рекомендации по формированию обучающих
выборок для НС--Р аналогичны сформулированным для нейросетевой модели
объекта управления в п.~\ref{nnp_series_req}.

При условии недетерминированности уставки длина выборки, образующей
обучающее множество, определяется из условия покрытия области,
гарантирующей качество имитации ПИД регулятора в рабочем диапазоне
уставок и ошибок.  Если имеется возможность целенаправленно
формировать уставку, рекомендуется псевдослучайно образовать временной
ряд, многократно достигающий границ рабочего диапазона уставок.

Контрольная выборка должна быть получена в режиме штатного
функционирования контура управления с ПИД регулятором в контуре.  При
этом уставка должна иметь вид, наиболее типичный для рабочего режима
системы.

\subsubsection{Дообучение нейросетевого регулятора}%
\label{nnc_final_training}

Дообучение НС--Р в контуре управления представляет собой
оптимизационную процедуру с критерием минимизации среднеквадратичной
ошибки управления.  Настроенная на предыдущем этапе вне контура
нейросеть регулятора (п.~\ref{nnc_pre}), во-первых, является начальным
приближением для оптимизационного алгоритма, во-вторых, поддерживает
устойчивость в системе управления.  Оптимизация осуществляется с
помощью алгоритма обратного распространения через нейросетевую модель
объекта управления, функционирующую в процессе дообучения.  Алгоритм
оптимизации описан в п.~\ref{nnc_optimal_training}.  Нейросетевая
модель объекта управления должна быть заранее обучена вне контура
(п.~\ref{nnpsynthesis}).

В реальной системе управления дообучение осуществляется в процессе ее
штатной эксплуатации.  В каждый дискретный момент времени
рассчитываются величины коррекции весовых коэффициентов НС--Р.
Весовые коэффициенты корректируются на каждом шаге или с некоторым
периодом (пакетное обновление).  В последнем случае величины коррекции
каждого весового коэффициента за прошедшие в периоде моменты времени
суммируются и по окончании периода изменяют нейросеть куммулятивно.
Данная техника позволяет обновлять нейросеть регулятора статистически
устойчивыми на периоде величинами коррекции.  Это позволяет уменьшить
влияние помех на процесс обучения нейросетевого регулятора и сделать
его более устойчивым.

Процесс дообучения НС--Р в описанных условиях существенно зависит от
уставки и помехи в канале наблюдения.  Даже в том случае, если сделать
уставку периодичной с периодом обновления весовых коэффициентов НС--Р,
наличие случайной помехи придает процессу обучения стохастический
характер.  График среднеквадратичной ошибки в этом случае изобилует
участками с возрастанием и убыванием ошибки при общей тенденции к
уменьшению.  На \figref{fig:cerr_trace}а сплошной линией показан
график среднеквадратичной ошибки в процессе обучения, а пунктиром ---
приближение тренда экспонентой.

\begin{figure}[h]
\centering
\begin{tabular}{cc}
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{cerr_trace_1000.ps} &
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{cerr_trace.ps} \\
а) & б)\\
\end{tabular}
\caption{Примеры графиков среднеквадратичной ошибки при дообучении НС--Р
         в реальных (а) и стационарных (б) условиях.}
\label{fig:cerr_trace}
\end{figure}

Влияние случайных факторов затрудняет определение момента достижения
регулятором требуемого качества функционирования, что мешает
исследованию его свойств и проведению сравнительных испытаний с иными
регуляторами.  Поэтому целесообразно в рамках имитационного
эксперимента искусственно сделать процесс обучения стационарным и
рассмотреть свойства полученного в таких условиях нейросетевого
регулятора.

%\subsubsection{Дообучение в стационарных условиях}

{\it Стационарным обучением }назовем процесс настройки нейросетевого
регулятора с пакетным обновлением весовых коэффициентов при котором в
каждой эпохе повторяются одни и те же ряды уставки и помехи.  Как
показано на \figref{fig:ctrlloop}, эти два ряда полностью определяют
траекторию системы управления.  В реальных условиях ряд $n(t)$
недоступен не только для формирования, но даже для измерения.  Однако
в условиях имитационного эксперимента, проводимого на цифровом
компьютере, возможно сгенерировать и многократно использовать любой
псевдослучайный числовой ряд.  Пример графика среднеквадратичной
ошибки в процессе стационарного обучения приведен на
\figref{fig:cerr_trace}б.

График имеет характер убывающей экспоненты.  Он наглядно демонстрирует
недостижимость нулевой ошибки, поскольку асимптота графика
среднеквадратичной ошибки всегда больше нуля.  В силу отсутствия
исчерпывающего теоретического базиса трудно и даже невозможно
предсказать, какого значения ошибки удасться добиться в процессе
настройки искусственной нейронной сети данной архитектуры на заданном
обучающем множестве.  По этой причине критерием завершения
стационарного обучения нейросетевого регулятора наиболее логично
сделать достижение некоторого порога уменьшения дискретной производной
$\Delta\MSE(t)$.  Порог выбирается так, чтобы дальнейшее продолжение
обучения перестало значимо уменьшать $\MSE$.

\subsubsection{Влияние свойств нейросетевой модели на дообучение
               нейросетевого регулятора}%
\label{nnp_on_nnc_influence}

В условиях стационарного дообучения НС--Р становится возможным в
имитационном эксперименте исследовать, как влияет нейросетевая модель
объекта управления на скорость и качество дообучения.  Степень этого
влияния осталась нерешенным вопросом методики синтеза НС--О
(п.~\ref{nnp_criteria_and_goal}).

Серия имитационных экспериментов проводилась с предварительно
настроенными нейросетевыми регуляторами и нейросетевыми моделями
объекта управления.  Для исследования влияния сложности архитектуры
НС--О на обучение НС--Р были взяты нейросети $\NN^o_{1+Dy,1}$,
$\NN^o_{1+Dy,5,1}$, $\NN^o_{1+Dy,5,3,1}$ с различным
количеством входов прошлых наблюдений объекта: $1\le D_y\le 3$.  В
экспериментах принимали участие нейросетевые регуляторы следующих
архитектур: $\NN^p_{r+e,1}$, $\NN^p_{r+e,5,1}$,
$\NN^p_{r+e,5,3,1}$.

Эксперимент заключался в дообучении НС--Р в стационарных условиях по
одной из моделей.  Обучение завершалось при снижении скорости
уменьшения $\MSE$ ниже $10^{-5}$.  Длина эпохи (и обучающего временного
ряда) была равна 500.  Коэффициенты скорости обучения для скрытых и
выходных нейронов были взяты равными 0.005 и 0.0001 соответственно.

В качестве оценки скорости обучения НС--Р при различных НС--О было
взято количество эпох до завершения обучения.  Результаты представлены
на~\figref{fig:noc_epochs} в виде трех прозрачных поверхностей,
координата $z$ которых показывает длительность обучения в эпохах НС--Р
некоторой архитектуры, заданной парой $(x, y)$.  На горизональных осях
отложены изменяемые параметры архитектуры НС--О --- количество скрытых
слоев (0, 1, 2) и количество прошлых наблюдений $D_y$ (1, 2, 3),
подаваемых на вход нейросетевой модели объекта управления.  Данный
график показывает следующие закономерности:

\begin{figure}[h]
\centering
\includegraphics[angle=270,width=0.8\textwidth,%
             totalheight=0.35\textheight]{noc_epochs.ps}
\caption{Длительность дообучения НС--Р различных архитектур при различных
         архитектурах НС--О, использовавшихся для инверсии объекта управления.}
\label{fig:noc_epochs}
\end{figure}

\begin{enumerate}

\item
количество прошлых наблюдений $D_y$, подаваемых на вход НС--О, не
оказывает влияния на скорость обучения НС--Р;

\item
для простейшей архитектуры НС--Р $\NN^p_{r+e,1}$ скорость
обучения тем выше, чем проще архитектура НС--О;

\item
для более сложных архитектур НС--Р с одним или двумя скрытыми слоями
скорость обучения не зависит от сложности модели;

\item
более сложные архитектуры НС--Р обучаются быстрее, чем простые.

\end{enumerate}

Следует отметить, что в анализируемом графике приведены только данные
длительности обучения.  Как уже отмечалось, критерием завершения
обучения являлось не достижение некоторого желаемого уровня ошибки, а
снижение скорости сходимости оптимизационного алгоритма ниже заданного
порога.  Достигнутый же уровень ошибки в конце обучения на графике не
отражен.

Среднеквадратичные ошибки, достигнутые при обучении, приводятся в
\tablref{tabl:noc_mse}.

\begin{table}[ht]
\centering
\caption{Качество дообучения НС--Р при различных НС--О.}
\label{tabl:noc_mse}
\begin{tabular}{|l|r|c|c|c|}
\hline
Нейросетевой & \multicolumn{4}{|l|}{ Нейросетевая модель } \\
\cline{3-5}
регулятор &  & $D_y=1$ & $D_y=2$ & $D_y=3$ \\[3pt]
\hline
          & $\NN^o_{1+Dy,1}$    & 0.0029 & 0.0029 & 0.0029 \\
$\NN^p_{r+e,1}$
          & $\NN^o_{1+Dy,5,1}$  & 0.0029 & 0.0029 & 0.0029 \\
          & $\NN^o_{1+Dy,5,3,1}$& 0.0029 & 0.0029 & 0.0029 \\[3pt]
\hline
          & $\NN^o_{1+Dy,1}$    & 0.0068 & 0.0068 & 0.0068 \\
$\NN^p_{r+e,5,1}$
          & $\NN^o_{1+Dy,5,1}$  & 0.0068 & 0.0068 & 0.0068 \\
          & $\NN^o_{1+Dy,5,3,1}$& 0.0068 & 0.0068 & 0.0068 \\[3pt]
\hline
          & $\NN^o_{1+Dy,1}$    & 0.0155 & 0.0155 & 0.0155 \\
$\NN^p_{r+e,5,3,1}$
          & $\NN^o_{1+Dy,5,1}$  & 0.0155 & 0.0155 & 0.0155 \\
          & $\NN^o_{1+Dy,5,3,1}$& 0.0155 & 0.0155 & 0.0155 \\[3pt]
\hline
\end{tabular}
\end{table}

Из данных, приведенных в таблице, видно, что достигаемый при
дообучении НС--Р уровень среднеквадратичной ошибки зависит только от
архитектуры самого нейросетевого регулятора.  Зависимость от
архитектуры НС--О в экспериментах не была обнаружена.


\subsubsection{Длительность эпохи в процессе дообучения}

\label{nnc_final_epoch_length}%
Одним из важных параметров методики обучения искусственных нейронных
сетей является длительность эпохи, в течении которой изменения весовых
коэффициентов не вносятся в нейросеть, а накапливаются (суммируются).
Обновление осуществляется только в конце эпохи.  Особенности выбора
коэффициента скорости обучения и его связь с длиной эпохи обсуждались
в п.~\ref{batch_eta}.  Исследуем в имитационном эксперименте влияние
длительности эпохи на процесс дообучения нейросетевого регулятора в
случае стохастических $r(t)$ и $n(t)$.  Для этого были обучены НС--Р
при различных значениях длины эпохи $L$.  Сообразно длине эпохи были
выбраны коэффициенты скорости обучения в скрытых слоях $\eta_h=\eta/L$
и в выходном слое $\eta_o=\eta/2L$, причем базовое значение
коэффициента $\eta=1$ во всех сеансах обучения было взято одинаковым.

В случае проведения эксперимента в условиях, максимально приближенных
к реальным (постоянно изменяющиеся $r(t)$ и $n(t)$), выявить
устойчивые зависимости проблематично.  Для того, чтобы снизить влияние
случайных факторов, во-первых, эксперимент проводился в стационарных
условиях, во-вторых, каждый сеанс обучения повторялся при различных
выборках уставки и помехи 10 раз.

\label{nnc-final-case-cond}%
Условия проведения эксперимента:
\begin{itemize}
\item
Объект управления: $P^*(z)=\displaystyle\frac{z}{z-0.5}$

\item
Исходный регулятор: $C_{PID}^*(z)=0.4 +
		     0.5\displaystyle\frac{z}{z-1} +
		     0.05\displaystyle\frac{z^2-2z+1}{z(z-1)}$

\item
Формирующий фильтр уставки: $R^*(z)=\displaystyle\frac{0.625z}{z-0.779}$
\item
Помеха наблюдения: н.б.ш. \GaDi{0}{0.1}

\item
Архитектура НС--О: $\NN^o_{1+1,1}$
\item
Архитектура НС--Р: $\NN^p_{r+e,5,3,1}$

\item
Длительности эпохи: 5, 10, 25, 50, 100, 250, 500, 1000, 2500
\item
Длина тестовой выборки: 5000
\end{itemize}

Обучение проводилось с помощью одной и той же нейросетевой модели
объекта управления.  В качестве начального приближения был взят
предварительно настроенный вне контура подобно ПИД регулятору
нейросетевой.

Критерием завершения процесса обучения считалось уменьшение
среднеквадратичной ошибки управления за эпоху меньше чем на $10^{-5}$.
После завершения обучения все экземпляры НС--Р тестировались на одной
и той же тестовой выборке.

График финальной среднеквадратичной ошибки в зависимости от
длительности эпохи приведен на \figref{fig:noc_mse(epochlen)}а.  На
нем представлены среднее значение (сплошная линия) и стандартное
отклонение (пунктирная линия) среднеквадратичной ошибки управления
$\MSE_{final}$, на которой обучение было остановлено.  В силу малости
зафиксированного значения $\Delta\MSE<10^{-5}$ и экспоненциального
характера снижения ошибки дальнейшее обучение нецелесообразно, так как
оно уже не даст существенного улучшения качества управления.

На \figref{fig:noc_mse(epochlen)}б изображены графики среднего
значения (сплошная линия) и стандартного отклонения (пунктирная линия)
среднеквадратичной ошибки управления $\MSE_{test}$, полученные на
длинной тестовой выборке.

%то есть, чем короче эпоха, тем менее представительной она
%является для отражения качества настройки регулятора.

\begin{figure}[h]
\centering
\begin{tabular}{cc}
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{noc_c_tr_mse_L.ps} &
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{noc_test_mse_L.ps} \\
а) & б)\\
\end{tabular}
\caption{Зависимость $\MSE$ от длительности эпохи по завершении обучения (а)
         и на тестовой выборке (б).}
\label{fig:noc_mse(epochlen)}
\end{figure}

В условиях стационарного обучения и малого размера обучающей выборки
(размер равен длине эпохи $L$) нейронная сеть проявляет свойство
адаптации к конкретной обучающей выборке в противоположность
обобщающей способности.  Это проявляется в том, что при $L<20$ имеет
место $\MSE_{final}<\MSE_{test}$.  Адаптированность НС--Р к конкретной
реализации обучающей выборки также подчеркивается высоким значением
стандартного отклонения при малых длинах эпохи.

Рассматривая график стандартного отклонения $\MSE_{test}$, полученный
по 10 сеансам обучения, следует отметить, что с увеличением длины
эпохи статистическая устойчивость результата обучения НС--Р
увеличивается (стандартное отклонение уменьшается), в то время как
начиная с $L=200$ среднее значение ошибки стабилизируется.  Очевидно,
это минимальное значение ошибки управления которого можно добиться при
выбранной архитектуре НС--Р и заданных внешних условиях.  Критичным
параметром, влияющим на уровень ошибки нейросетевого управления,
является, очевидно уровень помехи.

Зависимость финальной ошибки идентификации от длины эпохи,
представленная на \figref{fig:id_err(epochlen)} средним значением и
стандартным отклонением, демонстрирует увеличение статистической
устойчивости нейросетевой идентификации с ростом $L$.  В целом,
большая длина эпохи способствует более точной оценке якобиана объекта
управления и, следовательно, более эффективному обучению НС--Р.
Однако, при увеличении $L$ больше 400 не наблюдается в среднем
улучшения качества идентификации.

\begin{figure}[h]
\centering
\includegraphics[angle=270,width=0.8\textwidth,%
             totalheight=0.35\textheight]{noc_id_tr_mse_L.ps}
\caption{Зависимость ошибки идентификации в последней обучающей эпохе
         от длительности эпохи.}
\label{fig:id_err(epochlen)}
\end{figure}

Важной характеристикой процесса обучения является его суммарная
продолжительность.  На \figref{fig:training_dur(epochlen)}
представлена зависимость продолжительности обучения в дискретах
времени от длины эпохи.  Выявленный линейный характер зависимости
продолжительности (сплошная линия) от длины эпохи определяет временные
затраты на дообучение в среднем.  При $L=250$ линейный рост
стандартного отклонения (пунктирная линия), являющийся признаком
слабой статистической устойчивости, прекращается.  При продолжающемся
линейном росте среднего значения продолжительности это свидетельствует
о меньшем влиянии случайных факторов на процесс сходимости к
оптимальному нейросетевому управлению.

\begin{figure}[h]
\centering
\includegraphics[angle=270,width=0.8\textwidth,%
             totalheight=0.35\textheight]{noc_tr_dur_L.ps}
\caption{Зависимость продолжительности обучения от длительности эпохи.}
\label{fig:training_dur(epochlen)}
\end{figure}

Подводя итоги проведенного эксперимента можно рекомендовать длину
эпохи при дообучении НС--Р в пределах от 200 до 500.  При меньших
значениях $L$ качество нейросетевого регулятора и статистическая
устойчивость его достижения оставляют желать лучшего.  При больших
значениях $L$ увеличение суммарной продолжительности обучения уже не
приводит к существенному улучшению получаемого в результате НС--Р.
Выявленные качественные зависимости позволяют подобрать оптимальное
значение длительности эпохи в каждом конкретном случае.

\subsubsection{Дообучение в реальных условиях}

Выбор параметров алгоритма обучения НС--Р в контуре управления
(длительность эпохи, коэффициент скорость обучения) обсуждался в
предыдущих параграфах.  Наиболее актуальными задачами, требующими
разрешения при дообучении НС--Р в реальных условиях, представляются:

\begin{itemize}

\item
исследование поведения среднеквадратичной ошибки управления и
идентификации в процессе дообучения с целью выяснения характера и
пределов их изменения;

\item
зависимость качества управления НС--Р после дообучения от качества
управления исходного ПИД регулятора.

\item
определение момента достижения нейросетевым регулятором наилучшего
качества управления с целью остановки процесса дообучения.

\end{itemize}

%\subbbsection{Поведение среднеквадратичной ошибки}%
\subsubsection{Поведение среднеквадратичной ошибки}%
\label{noc_cmse_online}

Продолжим серию имитационных экспериментов в условиях, описанных на
\pgref{nnc-final-case-cond}.  Теперь будем проводить дообучение
НС--Р в контуре управления в реальных условиях, то есть, при постоянно
изменяющихся в соответствии с условленными спектрами сигналах уставки
и помехи.  В соответствии с выводами п.~\ref{nnc_final_epoch_length}
длительность эпохи обучения возьмем равной 500 дискретным отсчетам
времени.  Используя возможности, имеющиеся в имитационном, но
недоступные в физическом эксперименте, по окончании каждой эпохи
обучения будем проверять качество управления на одной и той же
достаточно длинной тестовой выборке (5000 дискретных отсчетов
времени).

Учитывая отличие в способности к обучению нейросетевых архитектур
различной сложности, обнаруженное при настройке НС--О и НС--Р вне
контура управления, будем проводить имитационные эксперименты с
нейросетевыми регуляторами $\NN^p_{r+e,1}$,
$\NN^p_{r+e,5,1}$, $\NN^p_{r+e,5,3,1}$.

Предварительное обучение НС--Р вне контура управления будем проводить
по двум исходным ПИД регуляторам с заведомо различным качеством
управления.  Первый ПИД регулятор $C^*_{PID_1}$ имеет параметры,
подобранные для минимизации времени переходного процесса и
перерегулирования.  Второй ПИД регулятор $C^*_{PID_2}$, напротив,
приводит к длительному переходному процессу со значительным
перерегулированием.  Параметры этих регуляторов приводятся ниже:

$$
C^*_{PID_1}(z)=0.4 + 0.5\displaystyle\frac{z}{z-1} +
               0.05\displaystyle\frac{z^2-2z+1}{z(z-1)}
$$

$$
C^*_{PID_2}(z)=0.5 + 0.8\displaystyle\frac{z}{z-1} +
               0.1\displaystyle\frac{z^2-2z+1}{z(z-1)}
$$

Траектории среднеквадратичной ошибки управления, характеризующие
процесс дообучения НС--Р в течение 200 эпох ($200\times500=10^5$
дискретных отсчетов времени), представлены на
\figref{fig:noc_cerr_online_training}.  Слева показаны графики для
НС--Р, предварительно настроенного по $C^*_{PID_1}$, справа --- по
$C^*_{PID_2}$.  На каждом из графиков горизонтальная линия обозначает
уровень $\MSEmin=0.00975$, обеспечиваемый оптимальным Винеровским
регулятором.

\begin{figure}[h]
\centering
\begin{tabular}{cc}
%\multicolumn{2}{c}{Среднеквадартичная ошибка на эпохе обучения ($L=500$)} \\
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_ol_cerr_train.ps} &
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_bad_ol_cerr_train.ps} \\
а) & б)\\
%\multicolumn{2}{c}{Среднеквадартичная ошибка на тестовой выборке (длина 5000)} \\
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_ol_cerr_test.ps} &
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_bad_ol_cerr_test.ps} \\
в) & г)\\
\end{tabular}
\caption{Траектории среднеквадратичной ошибки управления при дообучении НС--Р
         различных архитектур и двух исходных ПИД регуляторах:
         субоптимальном $C^*_{PID_1}$ (а,в), заведомо неоптимальном
         $C^*_{PID_2}$ (б,г).}
\label{fig:noc_cerr_online_training}
\end{figure}

На верхних графиках \figref{fig:noc_cerr_online_training} представлены
траектории среднеквадратичной ошибки на эпохе ($\MSE_{epoch}(t)$).
Случайный характер траекторий объясняется случайным сигналом уставки и
помехи.  Каждая эпоха представляет собой новое обучающее множество, по
которому алгоритм обучения рассчитывает коррекцию весовых
коэффициентов.  Траектория $\MSE_{epoch}(t)$ может быть получена в
физическом эксперименте.

На нижних графиках \figref{fig:noc_cerr_online_training} изображены
траектории среднеквадратичной ошибки ($\MSE_{test}(t)$), рассчитанной
по длинной тестовой выборке $(r_k,n_k)_N$ после обновления весовых
коэффициентов в конце эпохи.  Для этого пары значений $r_k,n_k$
последовательно подаются на вход независимой копии контура управления
с актуальными весовыми коэффициентами НС--Р.  Ввиду того, что тестовый
набор данных один и тот же, траектория среднеквадратичной ошибки не
имеет заметных случайных флуктуаций.  Данная траектория не может быть
получена в физическом эксперименте.  Она отражает качество
функционирования НС--Р в том случае, если бы дообучение было
прекращено в эпоху $t$.

Анализ процесса дообучения НС--Р в реальных условиях позволяет сделать
следующие выводы:

\begin{enumerate}

\item
Нейросетевой регулятор в входами $r_k,e_k$ может обеспечить лучшее
качество управления, чем линейный оптимальный регулятор, дополняющий
контур управления до Винеровского фильтра.  Архитектура нейронной сети
регулятора может быть как очень простой ($\NN^p_{r+e,1}$), так
и достаточно сложной ($\NN^p_{r+e,5,3,1}$).

\item
Значение среднеквадратичной ошибки на эпохе $\MSE_{epoch}(t)$ в
процессе дообучения не дает представления о качестве управления,
реализуемым текущим состоянием НС--Р.

\item
Время достижения заданного уровня $\MSE$ при дообучении НС--Р тем
больше, чем сложнее архитектура нейронной сети регулятора.

\item
Чем ближе исходный линейный регулятор к оптимальному Винеровскому, тем
менее заметен процесс дообучения НС--Р на траектории
$\MSE_{epoch}(t)$.  В частности, в приведенном на
\figref{fig:noc_cerr_online_training}а примере, тренд уменьшения
$\MSE_{epoch}(t)$ совсем незаметен, так как исходный ПИД регулятор
имеет параметры, близкие к оптимальным.

\item
Скорость уменьшения $\MSE_{test}(t)$ ниже определенного значения
становится незаметной на траектории $\MSE_{epoch}(t)$.

\end{enumerate}

Траектории среднеквадратичной ошибки идентификации в процессе
дообучения НС--Р приводятся на
~\figref{fig:noc_iderr_online_training}.  Очевидна связь с
траекториями $\MSE_{epoch}(t)$, так как уменьшение среднеквадратичной
ошибки идентификации происходит одновременно с уменьшением
$\MSE_{epoch}(t)$.  Аналогично, фаза дообучения, характеризующаяся
статистически постоянным уровнем $\MSE_{epoch}(t)$, имеет постоянную в
среднем величину среднеквадратичной ошибки идентификации
(\figref{fig:noc_cerr_online_training}а,б).

\begin{figure}[h]
\centering
\begin{tabular}{cc}
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_ol_iderr_train.ps} &
\includegraphics[angle=270,width=0.45\textwidth,%
             totalheight=0.25\textheight]{nnc_bad_ol_iderr_train.ps} \\
а) & б)\\
\end{tabular}
\caption{Траектории среднеквадратичной ошибки идентификации при дообучении НС--Р
         различных архитектур и двух исходных ПИД регуляторах:
         субоптимальном $C^*_{PID_1}$(а), заведомо неоптимальном
         $C^*_{PID_2}$(б).}
\label{fig:noc_iderr_online_training}
\end{figure}

%\subbbsection{Влияние качества предварительно настроенного НС--Р на
%              процесс дообучения}
\subsubsection{Влияние качества предварительно настроенного НС--Р на
       	       процесс дообучения}

Обобщение результатов проведенных экспериментов с различными исходными
ПИД регуляторами и различными архитектурами НС--Р позволяет сделать
вывод о значительном влиянии качества предварительной настройки
нейросетевого регулятора как на скорость дообучения, так и на качество
обученного НС--Р.  В частности, отмечено, что близость исходного
регулятора к Винеровскому оптимальному позволяет отказаться от этапа
дообучения НС--Р с простой архитектурой (варианты
$\NN^p_{r+e,1}$ и $\NN^p_{r+e,5,1}$).  Дообучение в
этих случаях лишь незначительно улучшает качество управления системой.

В то же время, нейросетевой регулятор со сложной трехслойной
архитектурой (вариант $\NN^p_{r+e,5,3,1}$) требует дообучения,
так как после этапа предварительного обучения качество нейросетевого
управления может оказаться все еще хуже Винеровского
(\figref{fig:noc_cerr_online_training}в).  Предварительно настроенный
по почти оптимальному линейному, нейросетевой регулятор демонстрирует
медленную сходимость.  Это вызвано тем, что начальная точка в
пространстве весовых коэффициентов, соответствующая имитации исходного
регулятора, оказывается далеко от минимума, достижимого нейронной
сетью в процессе дообучения.  Основной причиной эффекта плохой
дообучаемости НС--Р начиная с линейного субоптимального решения
является различие между линейным и нейросетевым оптимальным решением
задачи управления в одних и тех же условиях.

В случае значительной неоптимальности исходного регулятора, очевидно,
качество нейросетевого управления после этапа предварительно обучения
оставляет желать лучшего (\figref{fig:noc_cerr_online_training}г).
Однако, полученная нейронная сеть за достаточно короткое время,
зависящее от сложности архитектуры, достигает качества управления
Винеровского регулятора.  Нейросетевые регуляторы с простой
архитектурой достаточно быстро достигают того же уровня ошибки
управления, что и НС--Р, обучавшиеся с имитации оптимального ПИД
регулятора.  НС--Р трехслойной архитектуры закономерно обучается
медленнее простых нейросетей, но, сравнивая траектории
$\MSE_{test}(t)$ в случаях $C^*_{PID_1}$ и $C^*_{PID_2}$, видно, что
во втором случае скорость сходимости выше, чем в первом.

Опираясь на результаты проведенных имитационных экспериментов, а
также, анализируя обучение нейросетевого регулятора в контуре
управления мобильным роботом (Глава~\ref{mobile-robot})
\marginpar{ссылка на соответствующую главу}, можно утверждать, что
оптимальное линейное управление или близкое к нему является худшим
стартом для дообучения нейросетевого регулятора, чем управление
значительно худшего качества.  Данное утверждение обосновывает
приоритетное применение нейросетевого управления именно в тех случаях,
когда объект управляется по закону, далекому от оптимального.

%\subbbsection{Критерий завершения дообучения в реальных условиях}
\subsubsection{Критерий завершения дообучения в реальных условиях}

Естественным критерием завершения процесса дообучения НС--Р является
достижение заданного качества регулирования, то есть,
среднеквадратичной ошибки.  Однако, как уже отмечалось, траекторию
$\MSE_{test}(t)$, дающую представление об актуальном качестве
управления нейросетевого регулятора, в физическом эксперименте
получить невозможно.  Доступная в физических условиях траектория
$\MSE_{epoch}(t)$ не дает представления о достигнутом нейросетевым
регулятором качестве управления.  Тем не менее, результаты
имитационного исследования позволяют сформулировать рациональный
критерий завершения процесса дообучения.

Перечислим некоторые априорные соображения, дополняющие эмпирические
гипотезы.
Во-первых, отметим, что априорно заданная целевая среднеквадратичная
ошибка нейросетевого управления может оказаться недостижимой в силу
высокого уровня помех.  Аналитический расчет минимально достигаемого
значения ошибки для произвольно взятой архитектуры НС--Р невозможен
из-за неразвитости теоретического базиса нейросетевого и нелинейного
стохастического управления.  Поэтому, наиболее реалистичной
постановкой задачи нейросетевого оптимального управления в Винеровских
условиях является {\it улучшение} качества управления {\it до
возможного предела} без числовой конкретизации требуемых результатов.

Во-вторых, учитывая экспоненциальный характер траектории эффективной
среднеквадратичной ошибки $\MSE_{test}(t)$, стремление к
асимптотическому значению потребует бесконечно длительного обучения.
Поэтому разумно остановить дообучение тогда, когда его продолжение не
даст значительного снижения уровеня ошибки.

Обобщая выявленные в п.~\ref{noc_cmse_online} эмпирические зависимости
и приведенные выше соображения, предлагается использовать в качестве
критерия завершения обучения НС--Р в контуре управления постоянство
среднего значения $\MSE_{epoch}(t)$ на некотором интервале обучающих
эпох.

Траектория $\MSE_{epoch}(t)$ рассматривается как временной ряд.  В
основе предложенного критерия лежит гипотеза о том, что этот ряд
образован аддитивным влиянием двух факторов: долговременного и
случайного.  Экспоненциально убывающий характер среднеквадратичной
ошибки управления в процессе обучения НС--Р является долговременным
фактором, которым можно пренебречь в случае приближения эффективной
$\MSE$ к ассимптотическому значению.  При отсутствии заметного тренда
среднее значение $\MSE_{epoch}(t)$ станет постоянным.

Для проверки гипотезы $H_{const}$ постоянства среднего значения
временного ряда можно воспользоваться любым из методов, предлагаемых в
литературе по данному вопросу (например, \cite{jenkwatts71},
\cite{aivmhit98}).  Рассмотрим применение изложенного критерия для
примера, приведенного в п.~\ref{noc_cmse_online}.  Проверим гипотезу
$H_{const}$ с помощью приближенного критерия серий, основанного на
медиане (\cite[с.~797--799]{aivmhit98}).  Уровень значимости критерия
$\alpha$ (вероятность отвергнуть верную гипотезу) возьмем равным 5\%.

% также \cite[с.~108--109]{jenkwatts71}

Оценку постоянства среднего значения $\MSE_{epoch}(t)$ следует
проводить на интервале последовательных эпох обучения.  Очевидно, чем
длиннее этот интервал, тем меньше вероятность ошибочного принятия
гипотезы.  Однако, более длительный интервал может привести к
малоэффективному обучению вблизи к ассимптотического значения ошибки.

Возьмем длину интервала равной 50 эпохам.  Таким образом, общая
длительность процесса обучения, описанного в п.~\ref{noc_cmse_online},
делится на 4 интервала.  В \tablref{tabl:nnc_finish_criteria}
приведены результаты проверки гипотезы о постоянстве среднего значения
$\MSE_{epoch}(t)$ для всех трех нейросетевых архитектур и обоих
исходных регуляторов.  Работоспособность метода оценки момента
завершения обучения будем проверять по известным траекториям
$\MSE_{test}(t)$.

\begin{table}[h]
\centering
\caption{Проверка гипотезы о постоянстве среднего значения $\MSE_{epoch}(t)$
         на интервалах обучающих эпох.}
\label{tabl:nnc_finish_criteria}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Исходный & НС--Р &\multicolumn{4}{|c|}{$H_{const}$ в интервалах эпох обучения} \\
\cline{3-6}
регулятор &      & 1\dots50 & 51\dots100 & 101\dots150 & 151\dots200 \\
\hline
   & $\NN^p_{r+e,1}$ & верна & - & - & - \\
$C^*_{PID_1}$ & $\NN^p_{r+e,5,1}$ & верна & - & - & - \\
   & $\NN^p_{r+e,5,3,1}$ & не верна & не верна & не верна & верна \\
\hline
   & $\NN^p_{r+e,1}$ & не верна & не верна & верна & - \\
$C^*_{PID_2}$ & $\NN^p_{r+e,5,1}$ & не верна & не верна & не верна & не верна \\
   & $\NN^p_{r+e,5,3,1}$ & не верна & не верна & не верна & не верна \\
\hline
\end{tabular}
\end{table}

Возвращаясь к \figref{fig:noc_cerr_online_training}, видим, что
гипотеза оказалась верной уже в первом интервале эпох для исходного
регулятора $C^*_{PID_1}$, близкого к оптимальному, и НС--Р простой
одно- и двухслойной архитектуры.  Статистический критерий подтверждает
слабую обучаемость НС--Р в этом случае.  В случае сложной трехслойной
архитектуры гипотеза $H_{const}$ оказалась верной только на четвертом
интервале эпох обучения.

В случае неоптимального исходного регулятора $C^*_{PID_2}$
предложенный критерий указал на достаточность обучения в третьем
интервале для однослойного НС--Р.  Более сложные нейросетевые
регуляторы следует обучать дальше, так как на траектории
$\MSE_{epoch}(t)$ имеется малозаметный тренд.

Отметим случаи НС--Р $\NN^p_{r+e,5,3,1}$ при различных исходных
регуляторах.  Опираясь на знание траекторий $\MSE_{test}(t)$ можно
было бы сделать вывод о предпочтительности обучения в случае исходного
$C^*_{PID_1}$, так как ошибка управления все еще велика.  Однако, не
следует забывать, что траектория $\MSE_{test}(t)$ получена по одной
выборке и не дает точного значения качества нейросетевого управления
$\MSE$ на всей генеральной совокупности.  Не исключено, что в случае
иной тестовой выборки скорость уменьшения ошибки $\NN^p_{r+e,5,3,1}$
для $C^*_{PID_1}$ окажется значительно меньше, чем оказалось на
\figref{fig:noc_cerr_online_training}в, а значит, столь незначительный
спад становится уже статистически незаметным на наблюдаемой траектории
$\MSE_{epoch}(t)$.

Проверка предложенного критерия в нескольких подобных имитационных
экспериментах с различными параметрами исходной системы управления
подтвердила эффективность определения момента уменьшения производной
ошибки $\MSE_{test}(t)$ по наблюдаемой траектории $\MSE_{epoch}(t)$.

% End of file
